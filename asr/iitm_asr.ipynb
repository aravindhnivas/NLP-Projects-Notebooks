{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aravindhnivas/anaconda3/envs/aipy39/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "from pathlib import Path as pt\n",
    "# import torchaudio\n",
    "# import sys\n",
    "import torch\n",
    "import fairseq\n",
    "import soundfile\n",
    "import torch.nn.functional as F\n",
    "import torchaudio.sox_effects as ta_sox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " [PosixPath('/Users/aravindhnivas/Downloads/NeonAI/ASR/SPRING_INX_data2vec_aqc_Tamil.pt'),\n",
       "  PosixPath('/Users/aravindhnivas/Downloads/NeonAI/ASR/SPRING_INX_data2vec_aqc_Hindi.pt'),\n",
       "  PosixPath('/Users/aravindhnivas/Downloads/NeonAI/ASR/SPRING_INX_data2vec_aqc_Bengali.pt')])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_loc = pt(\"/Users/aravindhnivas/Downloads/NeonAI/ASR\")\n",
    "file_loc.exists(), list(file_loc.glob(\"*.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = file_loc / \"SPRING_INX_data2vec_aqc_Hindi.pt\"\n",
    "checkpoint_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the checkpoint\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'args': None,\n",
       " 'cfg': {'_name': None,\n",
       "  'common': {'_name': None,\n",
       "   'no_progress_bar': False,\n",
       "   'log_interval': 200,\n",
       "   'log_format': 'json',\n",
       "   'log_file': None,\n",
       "   'aim_repo': None,\n",
       "   'aim_run_hash': None,\n",
       "   'tensorboard_logdir': None,\n",
       "   'wandb_project': None,\n",
       "   'azureml_logging': False,\n",
       "   'seed': 1,\n",
       "   'cpu': False,\n",
       "   'tpu': False,\n",
       "   'bf16': False,\n",
       "   'memory_efficient_bf16': False,\n",
       "   'fp16': True,\n",
       "   'memory_efficient_fp16': False,\n",
       "   'fp16_no_flatten_grads': False,\n",
       "   'fp16_init_scale': 128,\n",
       "   'fp16_scale_window': None,\n",
       "   'fp16_scale_tolerance': 0.0,\n",
       "   'on_cpu_convert_precision': False,\n",
       "   'min_loss_scale': 0.0001,\n",
       "   'threshold_loss_scale': None,\n",
       "   'amp': False,\n",
       "   'amp_batch_retries': 2,\n",
       "   'amp_init_scale': 128,\n",
       "   'amp_scale_window': None,\n",
       "   'user_dir': '/nlsasfs/home/nltm-pilot/vasistal/data2vec_expts/ind_aqc/data2vec-aqc/examples/data2vec',\n",
       "   'empty_cache_freq': 0,\n",
       "   'all_gather_list_size': 16384,\n",
       "   'model_parallel_size': 1,\n",
       "   'quantization_config_path': None,\n",
       "   'profile': False,\n",
       "   'reset_logging': False,\n",
       "   'suppress_crashes': False,\n",
       "   'use_plasma_view': False,\n",
       "   'plasma_path': '/tmp/plasma'},\n",
       "  'common_eval': {'_name': None,\n",
       "   'path': None,\n",
       "   'post_process': None,\n",
       "   'quiet': False,\n",
       "   'model_overrides': '{}',\n",
       "   'results_path': None},\n",
       "  'distributed_training': {'_name': None,\n",
       "   'distributed_world_size': 4,\n",
       "   'distributed_num_procs': 4,\n",
       "   'distributed_rank': 0,\n",
       "   'distributed_backend': 'nccl',\n",
       "   'distributed_init_method': 'tcp://localhost:18143',\n",
       "   'distributed_port': -1,\n",
       "   'device_id': 0,\n",
       "   'distributed_no_spawn': False,\n",
       "   'ddp_backend': 'legacy_ddp',\n",
       "   'ddp_comm_hook': 'none',\n",
       "   'bucket_cap_mb': 25,\n",
       "   'fix_batches_to_gpus': False,\n",
       "   'find_unused_parameters': False,\n",
       "   'gradient_as_bucket_view': False,\n",
       "   'fast_stat_sync': False,\n",
       "   'heartbeat_timeout': -1,\n",
       "   'broadcast_buffers': False,\n",
       "   'slowmo_momentum': None,\n",
       "   'slowmo_base_algorithm': 'localsgd',\n",
       "   'localsgd_frequency': 3,\n",
       "   'nprocs_per_node': 4,\n",
       "   'pipeline_model_parallel': False,\n",
       "   'pipeline_balance': None,\n",
       "   'pipeline_devices': None,\n",
       "   'pipeline_chunks': 0,\n",
       "   'pipeline_encoder_balance': None,\n",
       "   'pipeline_encoder_devices': None,\n",
       "   'pipeline_decoder_balance': None,\n",
       "   'pipeline_decoder_devices': None,\n",
       "   'pipeline_checkpoint': 'never',\n",
       "   'zero_sharding': 'none',\n",
       "   'fp16': True,\n",
       "   'memory_efficient_fp16': False,\n",
       "   'tpu': False,\n",
       "   'no_reshard_after_forward': False,\n",
       "   'fp32_reduce_scatter': False,\n",
       "   'cpu_offload': False,\n",
       "   'use_sharded_state': False,\n",
       "   'not_fsdp_flatten_parameters': False},\n",
       "  'dataset': {'_name': None,\n",
       "   'num_workers': 6,\n",
       "   'skip_invalid_size_inputs_valid_test': True,\n",
       "   'max_tokens': 1280000,\n",
       "   'batch_size': None,\n",
       "   'required_batch_size_multiple': 8,\n",
       "   'required_seq_len_multiple': 1,\n",
       "   'dataset_impl': None,\n",
       "   'data_buffer_size': 10,\n",
       "   'train_subset': 'train',\n",
       "   'valid_subset': 'valid',\n",
       "   'combine_valid_subsets': None,\n",
       "   'ignore_unused_valid_subsets': False,\n",
       "   'validate_interval': 1,\n",
       "   'validate_interval_updates': 0,\n",
       "   'validate_after_updates': 0,\n",
       "   'fixed_validation_seed': None,\n",
       "   'disable_validation': False,\n",
       "   'max_tokens_valid': 1280000,\n",
       "   'batch_size_valid': None,\n",
       "   'max_valid_steps': None,\n",
       "   'curriculum': 0,\n",
       "   'gen_subset': 'test',\n",
       "   'num_shards': 1,\n",
       "   'shard_id': 0,\n",
       "   'grouped_shuffling': False,\n",
       "   'update_epoch_batch_itr': False,\n",
       "   'update_ordered_indices_seed': False},\n",
       "  'optimization': {'_name': None,\n",
       "   'max_epoch': 0,\n",
       "   'max_update': 320000,\n",
       "   'stop_time_hours': 0.0,\n",
       "   'clip_norm': 0.0,\n",
       "   'sentence_avg': True,\n",
       "   'update_freq': [6],\n",
       "   'lr': [3e-05],\n",
       "   'stop_min_lr': -1.0,\n",
       "   'use_bmuf': False,\n",
       "   'skip_remainder_batch': False},\n",
       "  'checkpoint': {'_name': None,\n",
       "   'save_dir': '/nlsasfs/home/nltm-pilot/malavika/abhishek/finetune_ssl_indian_langs/ckpts_lang/hindi_no_nptel/aqc_large',\n",
       "   'restore_file': 'checkpoint_last.pt',\n",
       "   'continue_once': None,\n",
       "   'finetune_from_model': None,\n",
       "   'reset_dataloader': False,\n",
       "   'reset_lr_scheduler': False,\n",
       "   'reset_meters': False,\n",
       "   'reset_optimizer': False,\n",
       "   'optimizer_overrides': '{}',\n",
       "   'save_interval': 1,\n",
       "   'save_interval_updates': 0,\n",
       "   'keep_interval_updates': -1,\n",
       "   'keep_interval_updates_pattern': -1,\n",
       "   'keep_last_epochs': -1,\n",
       "   'keep_best_checkpoints': 1,\n",
       "   'no_save': False,\n",
       "   'no_epoch_checkpoints': True,\n",
       "   'no_last_checkpoints': False,\n",
       "   'no_save_optimizer_state': False,\n",
       "   'best_checkpoint_metric': 'wer',\n",
       "   'maximize_best_checkpoint_metric': False,\n",
       "   'patience': -1,\n",
       "   'checkpoint_suffix': '',\n",
       "   'checkpoint_shard_count': 1,\n",
       "   'load_checkpoint_on_all_dp_ranks': False,\n",
       "   'write_checkpoints_asynchronously': False,\n",
       "   'model_parallel_size': 1},\n",
       "  'bmuf': {'_name': None,\n",
       "   'block_lr': 1.0,\n",
       "   'block_momentum': 0.875,\n",
       "   'global_sync_iter': 50,\n",
       "   'warmup_iterations': 500,\n",
       "   'use_nbm': False,\n",
       "   'average_sync': False,\n",
       "   'distributed_world_size': 4},\n",
       "  'generation': {'_name': None,\n",
       "   'beam': 5,\n",
       "   'nbest': 1,\n",
       "   'max_len_a': 0.0,\n",
       "   'max_len_b': 200,\n",
       "   'min_len': 1,\n",
       "   'match_source_len': False,\n",
       "   'unnormalized': False,\n",
       "   'no_early_stop': False,\n",
       "   'no_beamable_mm': False,\n",
       "   'lenpen': 1.0,\n",
       "   'unkpen': 0.0,\n",
       "   'replace_unk': None,\n",
       "   'sacrebleu': False,\n",
       "   'score_reference': False,\n",
       "   'prefix_size': 0,\n",
       "   'no_repeat_ngram_size': 0,\n",
       "   'sampling': False,\n",
       "   'sampling_topk': -1,\n",
       "   'sampling_topp': -1.0,\n",
       "   'constraints': None,\n",
       "   'temperature': 1.0,\n",
       "   'diverse_beam_groups': -1,\n",
       "   'diverse_beam_strength': 0.5,\n",
       "   'diversity_rate': -1.0,\n",
       "   'print_alignment': None,\n",
       "   'print_step': False,\n",
       "   'lm_path': None,\n",
       "   'lm_weight': 0.0,\n",
       "   'iter_decode_eos_penalty': 0.0,\n",
       "   'iter_decode_max_iter': 10,\n",
       "   'iter_decode_force_max_iter': False,\n",
       "   'iter_decode_with_beam': 1,\n",
       "   'iter_decode_with_external_reranker': False,\n",
       "   'retain_iter_history': False,\n",
       "   'retain_dropout': False,\n",
       "   'retain_dropout_modules': None,\n",
       "   'decoding_format': None,\n",
       "   'no_seed_provided': False,\n",
       "   'eos_token': None},\n",
       "  'eval_lm': {'_name': None,\n",
       "   'output_word_probs': False,\n",
       "   'output_word_stats': False,\n",
       "   'context_window': 0,\n",
       "   'softmax_batch': 9223372036854775807},\n",
       "  'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'},\n",
       "  'model': {'_name': 'wav2vec_ctc',\n",
       "   'w2v_path': '/nlsasfs/home/nltm-pilot/vasistal/superb_ckpts/30k_pt/d2v_aqc_large/best.pt',\n",
       "   'no_pretrained_weights': False,\n",
       "   'dropout_input': 0.0,\n",
       "   'final_dropout': 0.0,\n",
       "   'dropout': 0.0,\n",
       "   'attention_dropout': 0.0,\n",
       "   'activation_dropout': 0.1,\n",
       "   'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]',\n",
       "   'encoder_embed_dim': 768,\n",
       "   'apply_mask': True,\n",
       "   'mask_length': 10,\n",
       "   'mask_prob': 0.5,\n",
       "   'mask_selection': 'static',\n",
       "   'mask_other': 0.0,\n",
       "   'no_mask_overlap': False,\n",
       "   'mask_min_space': 1,\n",
       "   'require_same_masks': True,\n",
       "   'mask_dropout': 0.0,\n",
       "   'mask_channel_length': 64,\n",
       "   'mask_channel_prob': 0.25,\n",
       "   'mask_channel_selection': 'static',\n",
       "   'mask_channel_other': 0.0,\n",
       "   'no_mask_channel_overlap': False,\n",
       "   'freeze_finetune_updates': 10000,\n",
       "   'feature_grad_mult': 0.0,\n",
       "   'layerdrop': 0.1,\n",
       "   'mask_channel_min_space': 1,\n",
       "   'mask_channel_before': False,\n",
       "   'normalize': True,\n",
       "   'data': '/nlsasfs/home/nltm-pilot/malavika/abhishek/finetune_ssl_indian_langs/fairseq_data/hindi/hindi_no_nptel',\n",
       "   'w2v_args': {'_name': None,\n",
       "    'common': {'_name': None,\n",
       "     'no_progress_bar': False,\n",
       "     'log_interval': 200,\n",
       "     'log_format': 'json',\n",
       "     'log_file': None,\n",
       "     'aim_repo': None,\n",
       "     'aim_run_hash': None,\n",
       "     'tensorboard_logdir': '/nlsasfs/home/nltm-pilot/vasistal/data2vec_expts/aqc_large/data2vec-aqc/examples/data2vec/large_plots',\n",
       "     'wandb_project': None,\n",
       "     'azureml_logging': False,\n",
       "     'seed': 1,\n",
       "     'cpu': False,\n",
       "     'tpu': False,\n",
       "     'bf16': False,\n",
       "     'memory_efficient_bf16': False,\n",
       "     'fp16': True,\n",
       "     'memory_efficient_fp16': False,\n",
       "     'fp16_no_flatten_grads': False,\n",
       "     'fp16_init_scale': 128,\n",
       "     'fp16_scale_window': None,\n",
       "     'fp16_scale_tolerance': 0.0,\n",
       "     'on_cpu_convert_precision': False,\n",
       "     'min_loss_scale': 1e-07,\n",
       "     'threshold_loss_scale': None,\n",
       "     'amp': False,\n",
       "     'amp_batch_retries': 2,\n",
       "     'amp_init_scale': 128,\n",
       "     'amp_scale_window': None,\n",
       "     'user_dir': '/nlsasfs/home/nltm-pilot/vasistal/data2vec_expts/aqc_large/data2vec-aqc/examples/data2vec',\n",
       "     'empty_cache_freq': 0,\n",
       "     'all_gather_list_size': 16384,\n",
       "     'model_parallel_size': 1,\n",
       "     'quantization_config_path': None,\n",
       "     'profile': False,\n",
       "     'reset_logging': False,\n",
       "     'suppress_crashes': False,\n",
       "     'use_plasma_view': False,\n",
       "     'plasma_path': '/tmp/plasma'},\n",
       "    'common_eval': {'_name': None,\n",
       "     'path': None,\n",
       "     'post_process': None,\n",
       "     'quiet': False,\n",
       "     'model_overrides': '{}',\n",
       "     'results_path': None},\n",
       "    'distributed_training': {'_name': None,\n",
       "     'distributed_world_size': 64,\n",
       "     'distributed_num_procs': 8,\n",
       "     'distributed_rank': 0,\n",
       "     'distributed_backend': 'nccl',\n",
       "     'distributed_init_method': 'tcp://scn10-100g:14130',\n",
       "     'distributed_port': 14130,\n",
       "     'device_id': 0,\n",
       "     'distributed_no_spawn': False,\n",
       "     'ddp_backend': 'legacy_ddp',\n",
       "     'ddp_comm_hook': 'none',\n",
       "     'bucket_cap_mb': 25,\n",
       "     'fix_batches_to_gpus': False,\n",
       "     'find_unused_parameters': False,\n",
       "     'gradient_as_bucket_view': False,\n",
       "     'fast_stat_sync': False,\n",
       "     'heartbeat_timeout': -1,\n",
       "     'broadcast_buffers': False,\n",
       "     'slowmo_momentum': None,\n",
       "     'slowmo_base_algorithm': 'localsgd',\n",
       "     'localsgd_frequency': 3,\n",
       "     'nprocs_per_node': 8,\n",
       "     'pipeline_model_parallel': False,\n",
       "     'pipeline_balance': None,\n",
       "     'pipeline_devices': None,\n",
       "     'pipeline_chunks': 0,\n",
       "     'pipeline_encoder_balance': None,\n",
       "     'pipeline_encoder_devices': None,\n",
       "     'pipeline_decoder_balance': None,\n",
       "     'pipeline_decoder_devices': None,\n",
       "     'pipeline_checkpoint': 'never',\n",
       "     'zero_sharding': 'none',\n",
       "     'fp16': True,\n",
       "     'memory_efficient_fp16': False,\n",
       "     'tpu': False,\n",
       "     'no_reshard_after_forward': False,\n",
       "     'fp32_reduce_scatter': False,\n",
       "     'cpu_offload': False,\n",
       "     'use_sharded_state': False,\n",
       "     'not_fsdp_flatten_parameters': False},\n",
       "    'dataset': {'_name': None,\n",
       "     'num_workers': 8,\n",
       "     'skip_invalid_size_inputs_valid_test': True,\n",
       "     'max_tokens': 1200000,\n",
       "     'batch_size': None,\n",
       "     'required_batch_size_multiple': 1,\n",
       "     'required_seq_len_multiple': 1,\n",
       "     'dataset_impl': None,\n",
       "     'data_buffer_size': 10,\n",
       "     'train_subset': 'train',\n",
       "     'valid_subset': 'valid',\n",
       "     'combine_valid_subsets': None,\n",
       "     'ignore_unused_valid_subsets': False,\n",
       "     'validate_interval': 5,\n",
       "     'validate_interval_updates': 0,\n",
       "     'validate_after_updates': 0,\n",
       "     'fixed_validation_seed': None,\n",
       "     'disable_validation': False,\n",
       "     'max_tokens_valid': 1200000,\n",
       "     'batch_size_valid': None,\n",
       "     'max_valid_steps': None,\n",
       "     'curriculum': 0,\n",
       "     'gen_subset': 'test',\n",
       "     'num_shards': 1,\n",
       "     'shard_id': 0,\n",
       "     'grouped_shuffling': False,\n",
       "     'update_epoch_batch_itr': False,\n",
       "     'update_ordered_indices_seed': False},\n",
       "    'optimization': {'_name': None,\n",
       "     'max_epoch': 0,\n",
       "     'max_update': 750000,\n",
       "     'stop_time_hours': 0.0,\n",
       "     'clip_norm': 0.0,\n",
       "     'sentence_avg': False,\n",
       "     'update_freq': [1],\n",
       "     'lr': [0.0003],\n",
       "     'stop_min_lr': -1.0,\n",
       "     'use_bmuf': False,\n",
       "     'skip_remainder_batch': False},\n",
       "    'checkpoint': {'_name': None,\n",
       "     'save_dir': '/nlsasfs/home/nltm-pilot/vasistal/data2vec_expts/aqc_large/data2vec-aqc/examples/data2vec/large_ind_aqc_ckpts',\n",
       "     'restore_file': '/nlsasfs/home/nltm-pilot/vasistal/data2vec_expts/aqc_large/data2vec-aqc/examples/data2vec/large_ind_aqc_ckpts/checkpoint_last.pt',\n",
       "     'continue_once': None,\n",
       "     'finetune_from_model': None,\n",
       "     'reset_dataloader': False,\n",
       "     'reset_lr_scheduler': False,\n",
       "     'reset_meters': False,\n",
       "     'reset_optimizer': False,\n",
       "     'optimizer_overrides': '{}',\n",
       "     'save_interval': 1,\n",
       "     'save_interval_updates': 0,\n",
       "     'keep_interval_updates': 1,\n",
       "     'keep_interval_updates_pattern': -1,\n",
       "     'keep_last_epochs': -1,\n",
       "     'keep_best_checkpoints': 3,\n",
       "     'no_save': False,\n",
       "     'no_epoch_checkpoints': True,\n",
       "     'no_last_checkpoints': False,\n",
       "     'no_save_optimizer_state': False,\n",
       "     'best_checkpoint_metric': 'loss',\n",
       "     'maximize_best_checkpoint_metric': False,\n",
       "     'patience': -1,\n",
       "     'checkpoint_suffix': '',\n",
       "     'checkpoint_shard_count': 1,\n",
       "     'load_checkpoint_on_all_dp_ranks': False,\n",
       "     'write_checkpoints_asynchronously': False,\n",
       "     'model_parallel_size': 1},\n",
       "    'bmuf': {'_name': None,\n",
       "     'block_lr': 1.0,\n",
       "     'block_momentum': 0.875,\n",
       "     'global_sync_iter': 50,\n",
       "     'warmup_iterations': 500,\n",
       "     'use_nbm': False,\n",
       "     'average_sync': False,\n",
       "     'distributed_world_size': 64},\n",
       "    'generation': {'_name': None,\n",
       "     'beam': 5,\n",
       "     'nbest': 1,\n",
       "     'max_len_a': 0.0,\n",
       "     'max_len_b': 200,\n",
       "     'min_len': 1,\n",
       "     'match_source_len': False,\n",
       "     'unnormalized': False,\n",
       "     'no_early_stop': False,\n",
       "     'no_beamable_mm': False,\n",
       "     'lenpen': 1.0,\n",
       "     'unkpen': 0.0,\n",
       "     'replace_unk': None,\n",
       "     'sacrebleu': False,\n",
       "     'score_reference': False,\n",
       "     'prefix_size': 0,\n",
       "     'no_repeat_ngram_size': 0,\n",
       "     'sampling': False,\n",
       "     'sampling_topk': -1,\n",
       "     'sampling_topp': -1.0,\n",
       "     'constraints': None,\n",
       "     'temperature': 1.0,\n",
       "     'diverse_beam_groups': -1,\n",
       "     'diverse_beam_strength': 0.5,\n",
       "     'diversity_rate': -1.0,\n",
       "     'print_alignment': None,\n",
       "     'print_step': False,\n",
       "     'lm_path': None,\n",
       "     'lm_weight': 0.0,\n",
       "     'iter_decode_eos_penalty': 0.0,\n",
       "     'iter_decode_max_iter': 10,\n",
       "     'iter_decode_force_max_iter': False,\n",
       "     'iter_decode_with_beam': 1,\n",
       "     'iter_decode_with_external_reranker': False,\n",
       "     'retain_iter_history': False,\n",
       "     'retain_dropout': False,\n",
       "     'retain_dropout_modules': None,\n",
       "     'decoding_format': None,\n",
       "     'no_seed_provided': False,\n",
       "     'eos_token': None},\n",
       "    'eval_lm': {'_name': None,\n",
       "     'output_word_probs': False,\n",
       "     'output_word_stats': False,\n",
       "     'context_window': 0,\n",
       "     'softmax_batch': 9223372036854775807},\n",
       "    'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'},\n",
       "    'model': {'_name': 'data2vec_audio',\n",
       "     'extractor_mode': 'layer_norm',\n",
       "     'encoder_layers': 24,\n",
       "     'encoder_embed_dim': 1024,\n",
       "     'encoder_ffn_embed_dim': 4096,\n",
       "     'encoder_attention_heads': 16,\n",
       "     'activation_fn': 'gelu',\n",
       "     'layer_type': 'transformer',\n",
       "     'dropout': 0.0,\n",
       "     'attention_dropout': 0.0,\n",
       "     'activation_dropout': 0.1,\n",
       "     'encoder_layerdrop': 0.1,\n",
       "     'dropout_input': 0.0,\n",
       "     'dropout_features': 0.0,\n",
       "     'final_dim': 0,\n",
       "     'layer_norm_first': False,\n",
       "     'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]',\n",
       "     'conv_bias': False,\n",
       "     'logit_temp': 0.1,\n",
       "     'quantize_targets': False,\n",
       "     'quantize_input': False,\n",
       "     'same_quantizer': False,\n",
       "     'target_glu': False,\n",
       "     'feature_grad_mult': 0.0,\n",
       "     'quantizer_depth': 1,\n",
       "     'quantizer_factor': 3,\n",
       "     'latent_vars': 320,\n",
       "     'latent_groups': 2,\n",
       "     'latent_dim': 0,\n",
       "     'final_proj_dim': 768,\n",
       "     'mask_length': 10,\n",
       "     'mask_prob': 0.5,\n",
       "     'mask_selection': 'static',\n",
       "     'mask_other': 0.0,\n",
       "     'no_mask_overlap': False,\n",
       "     'mask_min_space': 1,\n",
       "     'require_same_masks': True,\n",
       "     'mask_dropout': 0.0,\n",
       "     'mask_channel_length': 64,\n",
       "     'mask_channel_prob': 0.25,\n",
       "     'mask_channel_before': False,\n",
       "     'mask_channel_selection': 'static',\n",
       "     'mask_channel_other': 0.0,\n",
       "     'no_mask_channel_overlap': False,\n",
       "     'mask_channel_min_space': 1,\n",
       "     'num_negatives': 100,\n",
       "     'negatives_from_everywhere': False,\n",
       "     'cross_sample_negatives': 0,\n",
       "     'codebook_negatives': 0,\n",
       "     'conv_pos': 95,\n",
       "     'conv_pos_groups': 16,\n",
       "     'pos_conv_depth': 5,\n",
       "     'latent_temp': [2.0, 0.5, 0.999995],\n",
       "     'max_positions': 100000,\n",
       "     'checkpoint_activations': False,\n",
       "     'required_seq_len_multiple': 2,\n",
       "     'crop_seq_to_multiple': 1,\n",
       "     'depthwise_conv_kernel_size': 31,\n",
       "     'attn_type': '',\n",
       "     'pos_enc_type': 'abs',\n",
       "     'fp16': False,\n",
       "     'cluster_factor': 16,\n",
       "     'scale_factor': 0.3,\n",
       "     'loss_beta': 0.0,\n",
       "     'loss_scale': None,\n",
       "     'average_top_k_layers': 10,\n",
       "     'layer_norm_target_layer': False,\n",
       "     'instance_norm_target_layer': True,\n",
       "     'instance_norm_targets': False,\n",
       "     'layer_norm_targets': False,\n",
       "     'batch_norm_target_layer': False,\n",
       "     'group_norm_target_layer': False,\n",
       "     'ema_decay': 0.999,\n",
       "     'ema_end_decay': 0.9999,\n",
       "     'ema_anneal_end_step': 400000,\n",
       "     'ema_transformer_only': True,\n",
       "     'ema_layers_only': True,\n",
       "     'max_update': 750000,\n",
       "     'min_target_var': 0.1,\n",
       "     'min_pred_var': 0.01},\n",
       "    'task': {'_name': 'audio_pretraining',\n",
       "     'data': '/nlsasfs/home/nltm-pilot/vasistal/Database/data_combine_for_pt/w2v_files',\n",
       "     'labels': None,\n",
       "     'binarized_dataset': False,\n",
       "     'sample_rate': 16000,\n",
       "     'normalize': True,\n",
       "     'enable_padding': False,\n",
       "     'max_sample_size': 320000,\n",
       "     'min_sample_size': 32000,\n",
       "     'num_batch_buckets': 0,\n",
       "     'precompute_mask_indices': False,\n",
       "     'inferred_w2v_config': None,\n",
       "     'tpu': False,\n",
       "     'text_compression_level': 'none'},\n",
       "    'criterion': None,\n",
       "    'optimizer': {'_name': 'adam',\n",
       "     'adam_betas': '(0.9,0.98)',\n",
       "     'adam_eps': 1e-06,\n",
       "     'weight_decay': 0.01,\n",
       "     'use_old_adam': False,\n",
       "     'fp16_adam_stats': False,\n",
       "     'tpu': False,\n",
       "     'lr': [0.0003]},\n",
       "    'lr_scheduler': None,\n",
       "    'scoring': None,\n",
       "    'bpe': None,\n",
       "    'tokenizer': None,\n",
       "    'ema': {'_name': None,\n",
       "     'store_ema': False,\n",
       "     'ema_decay': 0.9999,\n",
       "     'ema_start_update': 0,\n",
       "     'ema_seed_model': None,\n",
       "     'ema_update_freq': 1,\n",
       "     'ema_fp32': False},\n",
       "    'job_logging_cfg': {'version': 1,\n",
       "     'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}},\n",
       "     'handlers': {'console': {'class': 'logging.StreamHandler',\n",
       "       'formatter': 'simple',\n",
       "       'stream': 'ext://sys.stdout'},\n",
       "      'file': {'class': 'logging.FileHandler',\n",
       "       'formatter': 'simple',\n",
       "       'filename': 'hydra_train.log'}},\n",
       "     'root': {'level': 'INFO', 'handlers': ['console', 'file']},\n",
       "     'disable_existing_loggers': False}},\n",
       "   'offload_activations': False,\n",
       "   'min_params_to_wrap': 100000000,\n",
       "   'checkpoint_activations': False,\n",
       "   'ddp_backend': 'legacy_ddp',\n",
       "   'blank_weight': 0.0,\n",
       "   'blank_mode': 'add'},\n",
       "  'task': {'_name': 'audio_finetuning',\n",
       "   'data': '/nlsasfs/home/nltm-pilot/malavika/abhishek/finetune_ssl_indian_langs/fairseq_data/hindi/hindi_no_nptel',\n",
       "   'labels': 'ltr',\n",
       "   'binarized_dataset': False,\n",
       "   'sample_rate': 16000,\n",
       "   'normalize': True,\n",
       "   'enable_padding': False,\n",
       "   'max_sample_size': 480000,\n",
       "   'min_sample_size': 16000,\n",
       "   'num_batch_buckets': 0,\n",
       "   'precompute_mask_indices': False,\n",
       "   'inferred_w2v_config': None,\n",
       "   'tpu': False,\n",
       "   'text_compression_level': 'none',\n",
       "   'eval_wer': False,\n",
       "   'eval_wer_config': {'_name': None,\n",
       "    'beam': 5,\n",
       "    'nbest': 1,\n",
       "    'max_len_a': 0.0,\n",
       "    'max_len_b': 200,\n",
       "    'min_len': 1,\n",
       "    'match_source_len': False,\n",
       "    'unnormalized': False,\n",
       "    'no_early_stop': False,\n",
       "    'no_beamable_mm': False,\n",
       "    'lenpen': 1.0,\n",
       "    'unkpen': 0.0,\n",
       "    'replace_unk': None,\n",
       "    'sacrebleu': False,\n",
       "    'score_reference': False,\n",
       "    'prefix_size': 0,\n",
       "    'no_repeat_ngram_size': 0,\n",
       "    'sampling': False,\n",
       "    'sampling_topk': -1,\n",
       "    'sampling_topp': -1.0,\n",
       "    'constraints': None,\n",
       "    'temperature': 1.0,\n",
       "    'diverse_beam_groups': -1,\n",
       "    'diverse_beam_strength': 0.5,\n",
       "    'diversity_rate': -1.0,\n",
       "    'print_alignment': None,\n",
       "    'print_step': False,\n",
       "    'lm_path': None,\n",
       "    'lm_weight': 0.0,\n",
       "    'iter_decode_eos_penalty': 0.0,\n",
       "    'iter_decode_max_iter': 10,\n",
       "    'iter_decode_force_max_iter': False,\n",
       "    'iter_decode_with_beam': 1,\n",
       "    'iter_decode_with_external_reranker': False,\n",
       "    'retain_iter_history': False,\n",
       "    'retain_dropout': False,\n",
       "    'retain_dropout_modules': None,\n",
       "    'decoding_format': None,\n",
       "    'no_seed_provided': False,\n",
       "    'eos_token': None},\n",
       "   'eval_wer_tokenizer': None,\n",
       "   'eval_wer_post_process': 'letter',\n",
       "   'eval_bleu': False,\n",
       "   'eval_bleu_detok': None,\n",
       "   'eval_bleu_detok_args': '{}',\n",
       "   'eval_tokenized_bleu': False,\n",
       "   'eval_bleu_remove_bpe': None,\n",
       "   'eval_bleu_args': '{}',\n",
       "   'eval_bleu_print_samples': False,\n",
       "   'autoregressive': False},\n",
       "  'criterion': {'_name': 'ctc',\n",
       "   'zero_infinity': True,\n",
       "   'sentence_avg': True,\n",
       "   'post_process': 'letter',\n",
       "   'wer_kenlm_model': None,\n",
       "   'wer_lexicon': None,\n",
       "   'wer_lm_weight': 2.0,\n",
       "   'wer_word_score': -1.0,\n",
       "   'wer_args': None},\n",
       "  'optimizer': {'_name': 'adam',\n",
       "   'adam_betas': '(0.9,0.98)',\n",
       "   'adam_eps': 1e-08,\n",
       "   'weight_decay': 0.0,\n",
       "   'use_old_adam': False,\n",
       "   'fp16_adam_stats': False,\n",
       "   'tpu': False,\n",
       "   'lr': [3e-05]},\n",
       "  'lr_scheduler': {'_name': 'tri_stage',\n",
       "   'warmup_steps': 0,\n",
       "   'hold_steps': 0,\n",
       "   'decay_steps': 0,\n",
       "   'phase_ratio': [0.2, 0.3, 0.5],\n",
       "   'init_lr_scale': 0.01,\n",
       "   'final_lr_scale': 0.05,\n",
       "   'max_update': 320000.0,\n",
       "   'lr': [3e-05]},\n",
       "  'scoring': None,\n",
       "  'bpe': None,\n",
       "  'tokenizer': None,\n",
       "  'ema': {'_name': None,\n",
       "   'store_ema': False,\n",
       "   'ema_decay': 0.9999,\n",
       "   'ema_start_update': 0,\n",
       "   'ema_seed_model': None,\n",
       "   'ema_update_freq': 1,\n",
       "   'ema_fp32': False},\n",
       "  'job_logging_cfg': {'version': 1,\n",
       "   'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}},\n",
       "   'handlers': {'console': {'class': 'logging.StreamHandler',\n",
       "     'formatter': 'simple',\n",
       "     'stream': 'ext://sys.stdout'},\n",
       "    'file': {'class': 'logging.FileHandler',\n",
       "     'formatter': 'simple',\n",
       "     'filename': 'hydra_train.log'}},\n",
       "   'root': {'level': 'INFO', 'handlers': ['console', 'file']},\n",
       "   'disable_existing_loggers': False}},\n",
       " 'model': OrderedDict([('w2v_encoder.w2v_model.mask_emb',\n",
       "               tensor([0.1469, 0.1348, 0.0891,  ..., 0.0409, 0.1334, 0.1464])),\n",
       "              ('w2v_encoder.w2v_model.feature_extractor.conv_layers.0.0.weight',\n",
       "               tensor([[[ 0.0053, -0.0389,  0.0270,  ..., -0.0712,  0.2252, -0.1517]],\n",
       "               \n",
       "                       [[-0.0369,  0.0096,  0.0853,  ...,  0.0805, -0.1343,  0.0927]],\n",
       "               \n",
       "                       [[ 0.0281, -0.0148, -0.1193,  ..., -0.0066,  0.0494, -0.0347]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[-0.0059, -0.0156,  0.0246,  ...,  0.0336, -0.0092,  0.0075]],\n",
       "               \n",
       "                       [[ 0.0647, -0.0399, -0.0693,  ..., -0.2009,  0.2007, -0.0105]],\n",
       "               \n",
       "                       [[ 0.0186, -0.0297, -0.0309,  ...,  0.0648,  0.0740, -0.0563]]])),\n",
       "              ('w2v_encoder.w2v_model.feature_extractor.conv_layers.0.2.1.weight',\n",
       "               tensor([0.3965, 0.2715, 0.3076, 0.3274, 0.3201, 0.3567, 0.2959, 0.3306, 0.3198,\n",
       "                       0.2917, 0.3232, 0.3110, 0.3860, 0.4819, 0.3289, 0.3091, 0.2993, 0.3223,\n",
       "                       0.3201, 0.3132, 0.2979, 0.3074, 0.2825, 0.3274, 0.3254, 0.3335, 0.3423,\n",
       "                       0.3169, 0.4639, 0.2598, 0.2930, 0.3154, 0.3157, 0.6201, 0.2983, 0.2910,\n",
       "                       0.3513, 0.3059, 0.3181, 0.4087, 0.5996, 0.3015, 0.3171, 0.3203, 0.3428,\n",
       "                       0.3113, 0.3118, 0.3040, 0.2981, 0.3567, 0.3032, 0.2981, 0.3242, 0.3228,\n",
       "                       0.3247, 0.3247, 0.4495, 0.3010, 0.3489, 0.2834, 0.4148, 0.2732, 0.3093,\n",
       "                       0.3574, 0.3030, 0.3096, 0.3169, 0.3364, 0.3022, 0.2798, 0.3276, 0.3372,\n",
       "                       0.3250, 0.3176, 0.3401, 0.3445, 0.3013, 0.3215, 0.3215, 0.3010, 0.3198,\n",
       "                       0.3083, 0.3418, 0.3374, 0.3647, 0.2808, 0.3513, 0.3340, 0.3035, 0.3064,\n",
       "                       0.2988, 0.3140, 0.3748, 0.3164, 0.3276, 0.3191, 0.3103, 0.3167, 0.2939,\n",
       "                       0.3176, 0.4268, 0.3030, 0.3186, 0.3167, 0.4976, 0.3533, 0.5396, 0.4097,\n",
       "                       0.3313, 0.3091, 0.3330, 0.3269, 0.3340, 0.2991, 0.2837, 0.3091, 0.3293,\n",
       "                       0.3113, 0.3916, 0.3091, 0.3528, 0.3052, 0.3372, 0.3262, 0.3054, 0.3186,\n",
       "                       0.3264, 0.2983, 0.2969, 0.3076, 0.4595, 0.3333, 0.3149, 0.5195, 0.3640,\n",
       "                       0.3127, 0.3098, 0.3215, 0.2930, 0.2969, 0.5996, 0.3818, 0.3223, 0.3101,\n",
       "                       0.3071, 0.3188, 0.3132, 0.3101, 0.3174, 0.3052, 0.5029, 0.3452, 0.3240,\n",
       "                       0.3228, 0.3953, 0.3052, 0.3162, 0.2925, 0.3201, 0.3225, 0.3301, 0.3284,\n",
       "                       0.3235, 0.4177, 0.3552, 0.2391, 0.3867, 0.3020, 0.3899, 0.3262, 0.3394,\n",
       "                       0.3293, 0.2822, 0.3054, 0.3340, 0.3257, 0.3262, 0.4182, 0.5068, 0.3276,\n",
       "                       0.3257, 0.3306, 0.3040, 0.3247, 0.3101, 0.3735, 0.3237, 0.3113, 0.3291,\n",
       "                       0.3455, 0.3203, 0.2742, 0.2817, 0.2920, 0.3289, 0.4441, 0.2991, 0.4185,\n",
       "                       0.3467, 0.3669, 0.2830, 0.3279, 0.3027, 0.3259, 0.4426, 0.3269, 0.3213,\n",
       "                       0.3389, 0.2961, 0.3452, 0.3555, 0.3140, 0.3252, 0.3003, 0.2393, 0.3452,\n",
       "                       0.2935, 0.3665, 0.3120, 0.2783, 0.3269, 0.2986, 0.2922, 0.3284, 0.3074,\n",
       "                       0.3369, 0.3579, 0.3953, 0.3240, 0.3196, 0.3257, 0.3301, 0.4177, 0.3613,\n",
       "                       0.3882, 0.3613, 0.3079, 0.3601, 0.2986, 0.3032, 0.6309, 0.3052, 0.3789,\n",
       "                       0.3994, 0.3523, 0.3105, 0.3516, 0.3403, 0.3530, 0.2742, 0.3862, 0.4434,\n",
       "                       0.3354, 0.3054, 0.3293, 0.3535, 0.2871, 0.3020, 0.3264, 0.3237, 0.3179,\n",
       "                       0.3315, 0.3259, 0.3513, 0.2898, 0.3210, 0.3127, 0.3491, 0.3564, 0.4084,\n",
       "                       0.3066, 0.3186, 0.2776, 0.3301, 0.3079, 0.2798, 0.3328, 0.3711, 0.2844,\n",
       "                       0.3132, 0.3586, 0.3423, 0.3174, 0.3071, 0.3030, 0.2988, 0.3574, 0.3752,\n",
       "                       0.3284, 0.3484, 0.3257, 0.3315, 0.3499, 0.3049, 0.3250, 0.3147, 0.3230,\n",
       "                       0.4006, 0.3867, 0.3154, 0.3030, 0.3396, 0.3220, 0.3765, 0.3079, 0.3245,\n",
       "                       0.2756, 0.3643, 0.2839, 0.3140, 0.3076, 0.3049, 0.3218, 0.3030, 0.2988,\n",
       "                       0.3391, 0.3416, 0.3669, 0.2976, 0.3608, 0.2908, 0.3811, 0.3276, 0.3030,\n",
       "                       0.3240, 0.2961, 0.3218, 0.3086, 0.2864, 0.3215, 0.4202, 0.4253, 0.3447,\n",
       "                       0.3120, 0.2900, 0.5029, 0.3733, 0.3647, 0.3054, 0.3623, 0.3726, 0.3242,\n",
       "                       0.2900, 0.2861, 0.3167, 0.3447, 0.2878, 0.2942, 0.3315, 0.3303, 0.3696,\n",
       "                       0.3032, 0.2983, 0.3308, 0.3491, 0.2922, 0.3179, 0.3237, 0.3413, 0.2678,\n",
       "                       0.3743, 0.3213, 0.3711, 0.4678, 0.3503, 0.2920, 0.2930, 0.3179, 0.2913,\n",
       "                       0.2896, 0.3271, 0.3855, 0.3467, 0.3149, 0.3574, 0.3313, 0.3369, 0.3413,\n",
       "                       0.3257, 0.2966, 0.3162, 0.3416, 0.3450, 0.3271, 0.5708, 0.3645, 0.3013,\n",
       "                       0.3220, 0.6260, 0.3113, 0.3101, 0.3484, 0.2986, 0.3040, 0.3018, 0.4292,\n",
       "                       0.5010, 0.3040, 0.3359, 0.3198, 0.4673, 0.3267, 0.2925, 0.3491, 0.3252,\n",
       "                       0.3306, 0.3281, 0.4548, 0.3369, 0.3918, 0.3083, 0.3271, 0.3367, 0.2881,\n",
       "                       0.3044, 0.3777, 0.3262, 0.3333, 0.2258, 0.4514, 0.3005, 0.2974, 0.2935,\n",
       "                       0.3884, 0.2979, 0.3228, 0.3032, 0.3015, 0.2859, 0.3296, 0.3093, 0.2546,\n",
       "                       0.4038, 0.3184, 0.3323, 0.2886, 0.3076, 0.3616, 0.3857, 0.3337, 0.3286,\n",
       "                       0.2925, 0.3169, 0.3777, 0.2576, 0.4021, 0.3059, 0.3313, 0.3525, 0.3184,\n",
       "                       0.3257, 0.3816, 0.3137, 0.4023, 0.3523, 0.3030, 0.3413, 0.3140, 0.3760,\n",
       "                       0.3057, 0.3052, 0.3372, 0.3572, 0.3821, 0.3799, 0.2932, 0.2988, 0.3291,\n",
       "                       0.3167, 0.3235, 0.3403, 0.2988, 0.2827, 0.3232, 0.3132, 0.3411, 0.4211,\n",
       "                       0.2277, 0.3289, 0.3689, 0.4219, 0.3345, 0.2881, 0.3396, 0.4011, 0.3103,\n",
       "                       0.3118, 0.3262, 0.3098, 0.3892, 0.3003, 0.4285, 0.2920, 0.4224, 0.3113,\n",
       "                       0.2886, 0.3457, 0.3235, 0.3103, 0.2273, 0.3359, 0.3364, 0.3044, 0.3125,\n",
       "                       0.5015, 0.3391, 0.3679, 0.3215, 0.3210, 0.3384, 0.3276, 0.3057])),\n",
       "              ('w2v_encoder.w2v_model.feature_extractor.conv_layers.0.2.1.bias',\n",
       "               tensor([-0.0664, -0.0781, -0.1121, -0.0869, -0.1221, -0.0732, -0.1227, -0.0522,\n",
       "                       -0.0764, -0.1257, -0.0985, -0.1355, -0.0191,  0.0211, -0.0595, -0.1357,\n",
       "                       -0.0777, -0.1009, -0.0517, -0.1106, -0.0655, -0.0857, -0.1116, -0.0765,\n",
       "                       -0.1008, -0.1366, -0.0846, -0.0837,  0.0021, -0.1565, -0.1255, -0.0830,\n",
       "                       -0.1410,  0.0354, -0.0725, -0.0805, -0.0400, -0.1007, -0.0734, -0.0602,\n",
       "                       -0.0148, -0.0712, -0.1062, -0.1282, -0.1087, -0.1169, -0.1240, -0.0932,\n",
       "                       -0.1357, -0.0717, -0.0992, -0.0916, -0.0528, -0.0480, -0.1066, -0.1161,\n",
       "                       -0.0416, -0.0680, -0.0436, -0.1329, -0.0018, -0.1317, -0.1149, -0.1191,\n",
       "                       -0.1153, -0.1017, -0.0841, -0.0705, -0.0708, -0.1311, -0.1080, -0.0268,\n",
       "                       -0.1158, -0.0958, -0.0959, -0.0546, -0.0507, -0.1235, -0.1013, -0.0823,\n",
       "                       -0.1213, -0.1232, -0.0917, -0.0624, -0.0793, -0.1454, -0.0780, -0.0596,\n",
       "                       -0.0901, -0.1205, -0.0411, -0.0620, -0.0158, -0.0667, -0.1290, -0.1206,\n",
       "                       -0.0970, -0.0814, -0.0956, -0.1188, -0.0419, -0.1217, -0.0864, -0.0535,\n",
       "                        0.0012, -0.0963, -0.0320, -0.0428, -0.0536, -0.0949, -0.0845, -0.0897,\n",
       "                       -0.0926, -0.1014, -0.0938, -0.1083, -0.0942, -0.1169, -0.0665, -0.0483,\n",
       "                       -0.0806, -0.1012, -0.0712, -0.0618, -0.0938, -0.1138, -0.0775, -0.1299,\n",
       "                       -0.0573, -0.1265, -0.0088, -0.0815, -0.1116, -0.0076, -0.0471, -0.0858,\n",
       "                       -0.1365, -0.0999, -0.1414, -0.1361, -0.0336, -0.0520, -0.0716, -0.0617,\n",
       "                       -0.0602, -0.0638, -0.1208, -0.0199, -0.0727, -0.1241, -0.0089, -0.1188,\n",
       "                       -0.1267, -0.0907, -0.0894, -0.0968, -0.1059, -0.0653, -0.0906, -0.1083,\n",
       "                       -0.0979, -0.0831, -0.0727, -0.0486, -0.0309, -0.1484, -0.0769, -0.1383,\n",
       "                       -0.0495, -0.0670, -0.0822, -0.0798, -0.0950, -0.0562, -0.0039, -0.0172,\n",
       "                       -0.1023,  0.0527, -0.0302, -0.0672, -0.0726, -0.0186, -0.1385, -0.1048,\n",
       "                       -0.1390, -0.0714, -0.1041, -0.0863, -0.0762, -0.0626, -0.0490, -0.1084,\n",
       "                       -0.1328, -0.0484, -0.1316, -0.0410, -0.0974,  0.0112, -0.0774, -0.0941,\n",
       "                       -0.0982, -0.0598, -0.1150, -0.0596, -0.0451, -0.1063, -0.1105, -0.1175,\n",
       "                       -0.1432, -0.0759, -0.0811, -0.0580, -0.1183, -0.1032, -0.0779, -0.0874,\n",
       "                       -0.0942, -0.0870, -0.0908, -0.1163, -0.0827, -0.1345, -0.0551, -0.1066,\n",
       "                       -0.0885, -0.0793, -0.0891, -0.0483, -0.1018, -0.0765, -0.0576, -0.1011,\n",
       "                       -0.0383, -0.0954, -0.0564, -0.0635, -0.0384, -0.0638, -0.1013, -0.1301,\n",
       "                        0.0051, -0.1072, -0.0844, -0.0275, -0.0401, -0.0812, -0.0794, -0.0967,\n",
       "                       -0.0836, -0.1205, -0.0568, -0.0723, -0.0594, -0.1278, -0.0721, -0.0611,\n",
       "                       -0.1157, -0.0923, -0.0632, -0.0929, -0.1076, -0.0573, -0.1081, -0.0442,\n",
       "                       -0.1064, -0.0720, -0.0670, -0.0859, -0.0994, -0.0142, -0.1447, -0.1298,\n",
       "                       -0.1332, -0.1032, -0.1121, -0.0845, -0.1144, -0.0588, -0.0486, -0.1072,\n",
       "                       -0.0751, -0.0459, -0.0842, -0.1219, -0.1278, -0.1049, -0.0454, -0.0661,\n",
       "                       -0.0823, -0.0841, -0.0717, -0.0992, -0.0556, -0.1115, -0.1080, -0.1268,\n",
       "                       -0.1113, -0.0449, -0.0296, -0.0994, -0.0863, -0.0988, -0.1205, -0.0606,\n",
       "                       -0.1323, -0.1061, -0.1016, -0.0589, -0.0618, -0.1220, -0.0653, -0.0999,\n",
       "                       -0.0553, -0.0929, -0.0914, -0.1056, -0.0799, -0.0976, -0.1459, -0.0408,\n",
       "                       -0.1272, -0.0657, -0.1222, -0.1255, -0.0708, -0.0638, -0.1008, -0.0816,\n",
       "                       -0.0881, -0.0840, -0.0536, -0.0600, -0.1135, -0.0923, -0.1193,  0.0635,\n",
       "                       -0.0623, -0.0517, -0.0822, -0.0950, -0.0293, -0.0666, -0.1287, -0.1106,\n",
       "                       -0.1346, -0.1045, -0.1097, -0.1255, -0.0770, -0.0357, -0.0299, -0.0638,\n",
       "                       -0.1182, -0.0732, -0.0696, -0.1488, -0.1047, -0.0853, -0.0814, -0.1151,\n",
       "                       -0.0732, -0.1230, -0.0277, -0.0347, -0.0911, -0.0357, -0.0898, -0.1055,\n",
       "                       -0.0463, -0.0837, -0.0898, -0.0898, -0.0751, -0.1146, -0.0893, -0.0807,\n",
       "                       -0.0815, -0.0726, -0.0565, -0.0847, -0.0948, -0.0347, -0.1171, -0.0861,\n",
       "                       -0.0325, -0.0482,  0.0178, -0.1023,  0.0794, -0.1257, -0.1251, -0.0794,\n",
       "                       -0.0961, -0.1110, -0.1085, -0.0207,  0.0511, -0.1329, -0.0734, -0.0658,\n",
       "                        0.0229, -0.0790, -0.0591, -0.0898, -0.1174, -0.0551, -0.1155,  0.0103,\n",
       "                       -0.1367, -0.0435, -0.0531, -0.1203, -0.0782, -0.1270, -0.1138, -0.0618,\n",
       "                       -0.0698, -0.0723, -0.0984, -0.0415, -0.0691, -0.0969, -0.0754, -0.0422,\n",
       "                       -0.1193, -0.0878, -0.0717, -0.0974, -0.1024, -0.1237, -0.1367, -0.1481,\n",
       "                        0.0269, -0.0940, -0.0671, -0.1002, -0.1326, -0.0984, -0.0548, -0.1315,\n",
       "                       -0.0901, -0.0592, -0.1001, -0.0706, -0.0291,  0.0074, -0.0977, -0.0793,\n",
       "                       -0.0610, -0.1385, -0.1010, -0.0663, -0.0552, -0.0290, -0.0863, -0.1188,\n",
       "                       -0.0650, -0.1065, -0.0605, -0.0994, -0.0664, -0.1003, -0.0682, -0.0216,\n",
       "                        0.0205, -0.1024, -0.1273, -0.0734, -0.1282, -0.0818, -0.0829, -0.0356,\n",
       "                       -0.0883, -0.0947, -0.0552, -0.0797, -0.0262, -0.1010, -0.0411, -0.0473,\n",
       "                       -0.0484, -0.0632, -0.0489, -0.0912,  0.0161, -0.0861, -0.0793, -0.0883,\n",
       "                       -0.0585, -0.0628, -0.0895, -0.0477, -0.0743, -0.0559, -0.1221, -0.1409,\n",
       "                       -0.0914, -0.1187, -0.0629, -0.1066, -0.1287, -0.1013, -0.1272, -0.0903,\n",
       "                        0.0889, -0.1065, -0.0804, -0.1026, -0.0634, -0.0693, -0.0978, -0.0720])),\n",
       "              ('w2v_encoder.w2v_model.feature_extractor.conv_layers.1.0.weight',\n",
       "               tensor([[[-1.2415e-01, -3.0365e-02, -1.3824e-02],\n",
       "                        [ 5.6976e-02,  1.9012e-02,  1.9485e-02],\n",
       "                        [ 3.7804e-03,  3.1464e-02, -3.4698e-02],\n",
       "                        ...,\n",
       "                        [-3.0380e-02, -6.0486e-02, -8.0139e-02],\n",
       "                        [-3.7781e-02, -7.2021e-02, -6.1920e-02],\n",
       "                        [-6.1218e-02,  2.5742e-02, -4.1809e-03]],\n",
       "               \n",
       "                       [[ 2.3666e-02,  1.7444e-01, -6.6772e-02],\n",
       "                        [-1.9806e-02, -5.6305e-02,  6.4331e-02],\n",
       "                        [-1.6983e-02,  2.9709e-02,  6.8787e-02],\n",
       "                        ...,\n",
       "                        [ 1.5961e-02,  6.5689e-03,  1.2573e-02],\n",
       "                        [-6.0120e-02,  4.2816e-02,  1.3354e-01],\n",
       "                        [-9.0408e-03, -1.3809e-02,  1.9722e-03]],\n",
       "               \n",
       "                       [[-2.3071e-02, -2.3499e-02, -6.4819e-02],\n",
       "                        [-2.1631e-01, -1.9495e-01, -4.1534e-02],\n",
       "                        [-1.1353e-01, -5.0476e-02, -1.3523e-03],\n",
       "                        ...,\n",
       "                        [ 9.8724e-03,  8.9340e-03, -9.4757e-03],\n",
       "                        [ 2.2064e-02, -3.9459e-02, -1.2794e-02],\n",
       "                        [-1.3954e-02, -2.5803e-02, -5.0110e-02]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[-2.3651e-02,  8.9874e-03,  1.7700e-02],\n",
       "                        [-4.6112e-02, -3.0914e-02, -6.2134e-02],\n",
       "                        [-8.4778e-02, -3.0762e-02,  4.8950e-02],\n",
       "                        ...,\n",
       "                        [-8.2642e-02, -5.1544e-02,  9.4070e-03],\n",
       "                        [-6.9275e-02, -3.7506e-02,  2.8534e-03],\n",
       "                        [-4.9591e-02, -3.7903e-02,  2.5421e-02]],\n",
       "               \n",
       "                       [[ 2.9190e-02,  1.9373e-01, -9.3262e-02],\n",
       "                        [-1.8478e-02,  3.7262e-02, -1.4328e-02],\n",
       "                        [-3.8177e-02,  3.9597e-03,  2.0615e-02],\n",
       "                        ...,\n",
       "                        [-8.7830e-02, -7.1289e-02, -4.8370e-02],\n",
       "                        [-2.6093e-02, -1.9385e-01, -1.0669e-01],\n",
       "                        [-1.7288e-02,  5.5027e-04,  3.5370e-02]],\n",
       "               \n",
       "                       [[ 3.4576e-02, -1.0010e-02,  3.0716e-02],\n",
       "                        [ 5.4199e-02, -1.0056e-02,  4.2847e-02],\n",
       "                        [ 7.6355e-02,  2.8091e-02,  2.3603e-05],\n",
       "                        ...,\n",
       "                        [ 4.4373e-02,  4.0710e-02,  2.8763e-02],\n",
       "                        [ 1.0077e-01,  8.1238e-02,  2.4429e-02],\n",
       "                        [ 3.7842e-02,  7.0374e-02, -2.8442e-02]]])),\n",
       "              ('w2v_encoder.w2v_model.feature_extractor.conv_layers.1.2.1.weight',\n",
       "               tensor([1.0146, 1.1670, 0.8296, 0.9180, 1.0576, 0.1294, 0.2791, 0.7612, 0.6841,\n",
       "                       0.6235, 0.1443, 0.4961, 0.1941, 0.2135, 0.6992, 0.6885, 0.6860, 0.7183,\n",
       "                       0.1776, 0.3391, 0.5747, 0.4719, 0.2925, 0.6772, 0.1694, 0.3525, 0.1344,\n",
       "                       0.2856, 0.3030, 0.5391, 0.5303, 0.2869, 0.0985, 0.2649, 0.1558, 0.5479,\n",
       "                       0.8267, 0.2115, 0.7212, 0.1411, 0.1498, 1.2109, 0.6782, 0.0931, 0.7378,\n",
       "                       0.1844, 0.1613, 0.3923, 0.5142, 0.2654, 0.1874, 0.8540, 0.4531, 0.5693,\n",
       "                       0.4727, 0.5376, 1.0605, 0.2372, 0.0973, 0.1300, 1.2695, 0.2152, 0.4988,\n",
       "                       0.8105, 0.6587, 0.2083, 0.7271, 0.1942, 1.0312, 0.3425, 0.4670, 0.5327,\n",
       "                       0.6523, 0.6406, 0.5205, 0.2002, 0.5225, 0.5098, 0.7871, 0.5073, 0.4607,\n",
       "                       1.1699, 0.6035, 0.0954, 0.1406, 0.3054, 0.2673, 0.8735, 0.4636, 0.4673,\n",
       "                       0.7017, 0.4600, 0.1656, 0.2639, 0.4438, 0.4580, 0.4858, 0.5928, 0.8101,\n",
       "                       0.2605, 0.2206, 1.0527, 0.1328, 0.5825, 0.1382, 1.5234, 0.6001, 0.7031,\n",
       "                       0.6201, 0.8867, 0.6724, 0.1986, 0.2922, 0.1694, 0.9678, 0.4795, 0.2255,\n",
       "                       0.7017, 0.8989, 0.6870, 1.0723, 0.4272, 0.4277, 0.6870, 0.3301, 0.8276,\n",
       "                       0.7495, 0.7686, 0.6025, 0.1750, 0.4189, 0.2859, 0.8105, 0.3574, 0.1080,\n",
       "                       0.5386, 1.3164, 0.6294, 0.5088, 0.6230, 0.6616, 0.2363, 0.4624, 0.2639,\n",
       "                       0.1109, 0.6191, 0.2059, 0.3484, 0.1150, 0.7593, 0.6865, 0.5645, 0.1312,\n",
       "                       0.2537, 0.6914, 0.5107, 0.4321, 1.8789, 0.5352, 0.5942, 0.2167, 0.5967,\n",
       "                       0.2352, 0.7500, 1.0215, 0.9600, 0.1534, 0.7148, 1.1104, 0.1692, 0.4275,\n",
       "                       1.3945, 0.2407, 0.5210, 0.2510, 0.1805, 0.7578, 0.6060, 0.6895, 0.8555,\n",
       "                       0.0956, 0.4731, 0.1272, 0.8320, 0.4558, 0.2166, 0.6367, 0.2003, 0.4421,\n",
       "                       0.6328, 0.1045, 0.6025, 1.2314, 0.1209, 0.2008, 0.9180, 0.1626, 0.7246,\n",
       "                       0.1132, 0.5908, 0.6372, 0.1947, 0.4849, 0.7734, 0.5830, 0.1357, 0.2306,\n",
       "                       0.6426, 0.4084, 0.8115, 0.3708, 0.3403, 0.1759, 2.0762, 0.1627, 0.6411,\n",
       "                       0.3982, 0.5537, 0.1426, 1.0820, 0.3108, 0.9170, 0.3594, 0.4656, 0.4023,\n",
       "                       0.4702, 0.6895, 0.4434, 1.1113, 0.1593, 0.4211, 0.5103, 0.7544, 0.5923,\n",
       "                       0.5054, 0.4946, 0.7109, 0.4607, 0.1575, 0.1378, 0.1470, 0.1663, 0.5249,\n",
       "                       0.6353, 0.4248, 0.5317, 0.2461, 0.3574, 0.7109, 0.1937, 0.5884, 0.7373,\n",
       "                       0.6631, 0.2384, 0.6206, 0.5830, 0.4995, 0.5454, 0.5381, 0.6343, 0.7036,\n",
       "                       0.7207, 0.1528, 0.1103, 0.5742, 0.3328, 1.2275, 0.8413, 0.1349, 0.3079,\n",
       "                       0.2452, 0.3162, 0.6279, 0.4355, 0.3577, 0.3911, 0.6997, 0.3118, 0.2021,\n",
       "                       0.2469, 0.8262, 0.8931, 0.4270, 0.0740, 0.4712, 0.7725, 1.4463, 0.1479,\n",
       "                       0.6167, 0.3711, 0.9189, 0.6348, 1.1270, 0.5869, 0.5786, 0.2236, 0.1179,\n",
       "                       1.0908, 0.5273, 0.2283, 0.8442, 0.5171, 0.1820, 0.1519, 0.3687, 0.1431,\n",
       "                       0.5747, 0.5288, 0.3311, 0.9722, 0.6191, 0.5474, 0.3066, 0.4976, 0.1865,\n",
       "                       0.1738, 0.6655, 0.1052, 0.2815, 0.5854, 0.1876, 0.3025, 0.3174, 0.1632,\n",
       "                       0.4839, 0.0458, 0.8179, 0.1886, 0.6362, 0.2003, 0.4731, 0.2190, 0.3730,\n",
       "                       0.4146, 1.0537, 0.3071, 0.2345, 0.1515, 0.9004, 0.1816, 1.7451, 0.6694,\n",
       "                       0.2344, 0.1464, 0.6362, 0.6279, 0.8247, 0.7622, 0.3806, 0.3818, 0.5518,\n",
       "                       0.5156, 0.9902, 0.6660, 1.0469, 0.1002, 0.0865, 0.5537, 0.6499, 0.6318,\n",
       "                       0.4878, 0.1378, 0.8223, 0.5522, 0.6143, 0.2544, 0.3984, 0.4143, 1.2725,\n",
       "                       0.1595, 0.1516, 0.1232, 0.5684, 0.7974, 0.6963, 0.9990, 0.4194, 2.2148,\n",
       "                       0.7910, 0.2766, 0.5303, 0.5903, 1.3574, 0.3665, 0.4678, 0.8721, 0.3071,\n",
       "                       0.7095, 0.6255, 0.1581, 0.3628, 0.8979, 0.1548, 0.5327, 0.4104, 0.1471,\n",
       "                       0.7822, 0.9375, 0.9907, 0.2554, 0.6636, 0.7607, 0.1818, 1.2100, 0.6021,\n",
       "                       0.4580, 0.8735, 0.4116, 0.6934, 0.2034, 0.6357, 0.7910, 0.1829, 0.2069,\n",
       "                       0.0925, 0.6299, 0.3091, 0.8042, 0.7866, 0.1736, 0.5098, 0.5137, 0.1378,\n",
       "                       1.9395, 0.2512, 0.1252, 0.1987, 0.7842, 0.2177, 0.8638, 0.6250, 0.9907,\n",
       "                       0.5474, 0.5220, 0.2354, 0.5615, 1.2256, 0.7993, 0.1981, 0.7959, 0.6865,\n",
       "                       0.2742, 0.1168, 0.2542, 0.7363, 0.2505, 0.1361, 0.6587, 0.4558, 0.5142,\n",
       "                       0.3765, 1.0273, 0.7666, 0.6235, 0.9482, 0.4714, 0.4360, 0.2734, 0.3254,\n",
       "                       0.1702, 0.3691, 0.8306, 0.5396, 0.1976, 1.3154, 1.3877, 0.1647, 0.3909,\n",
       "                       0.6650, 0.7427, 0.5454, 1.3643, 0.1605, 1.5723, 0.7388, 1.0381, 0.1530,\n",
       "                       0.7080, 0.1501, 0.2793, 0.3608, 0.3682, 0.7124, 0.5210, 0.8267, 0.8311,\n",
       "                       0.5386, 0.7056, 0.6963, 0.3369, 1.1113, 0.6177, 0.4478, 0.6680, 0.4485,\n",
       "                       0.9102, 0.2788, 0.6226, 1.1025, 0.8848, 1.1562, 0.1599, 0.3892, 0.9492,\n",
       "                       0.1116, 0.6841, 0.7637, 0.1017, 0.2008, 0.2986, 0.6631, 0.2493])),\n",
       "              ('w2v_encoder.w2v_model.feature_extractor.conv_layers.1.2.1.bias',\n",
       "               tensor([-0.2054, -0.4155, -0.1683, -0.0810, -0.1389, -0.0299, -0.0825, -0.2102,\n",
       "                       -0.0710, -0.2181, -0.1437, -0.3372, -0.0817, -0.1250, -0.4470, -0.1503,\n",
       "                       -0.0745, -0.1242, -0.1333, -0.0910, -0.0767, -0.1163, -0.1827, -0.1697,\n",
       "                       -0.0682, -0.0821, -0.1017, -0.1162, -0.0706, -0.0583, -0.0073, -0.1031,\n",
       "                       -0.0081, -0.1082, -0.0517, -0.2169, -0.2358, -0.1142, -0.1969, -0.0348,\n",
       "                       -0.0880, -0.1455, -0.0834, -0.0903, -0.2302, -0.1013, -0.1186, -0.1700,\n",
       "                       -0.0505, -0.1232, -0.0688, -0.1639, -0.2642, -0.1652,  0.0090, -0.2324,\n",
       "                       -0.1287, -0.1044, -0.0369, -0.0938, -0.1179, -0.1521, -0.2094, -0.2323,\n",
       "                        0.0123, -0.1218, -0.3179, -0.0862, -0.2778, -0.1427,  0.0235, -0.0036,\n",
       "                       -0.0117, -0.2284, -0.2369, -0.1409, -0.3035, -0.1633, -0.1844, -0.3816,\n",
       "                       -0.0850, -0.3872, -0.2295, -0.0731, -0.1207, -0.0537, -0.0460, -0.1567,\n",
       "                       -0.0933,  0.0367, -0.1575, -0.1589, -0.0416, -0.0873, -0.2681, -0.3059,\n",
       "                       -0.1104, -0.1420, -0.2434, -0.0873, -0.0925, -0.1696, -0.0984, -0.2910,\n",
       "                       -0.0944, -0.4927, -0.2898, -0.0118, -0.0621, -0.1478, -0.2935,  0.0045,\n",
       "                       -0.0554, -0.1482, -0.2249, -0.0236, -0.1987, -0.1719, -0.2725, -0.0492,\n",
       "                       -0.1699, -0.0668, -0.2527, -0.0773, -0.1093, -0.0174,  0.0304, -0.3328,\n",
       "                       -0.2147, -0.0707, -0.2303, -0.1322,  0.0089, -0.0958, -0.1008, -0.0374,\n",
       "                       -0.0975, -0.0504, -0.0235, -0.0600, -0.0476, -0.0649, -0.1897, -0.0491,\n",
       "                       -0.1171, -0.2479, -0.1293, -0.0384, -0.1244,  0.0797, -0.2483,  0.0390,\n",
       "                       -0.0488, -0.0945, -0.2408, -0.1772, -0.0294, -0.2152, -0.1367, -0.0117,\n",
       "                       -0.1038, -0.1597, -0.1131, -0.2159, -0.2386, -0.0230, -0.1139, -0.2886,\n",
       "                       -0.0287, -0.0645, -0.0961, -0.2344, -0.0518, -0.0818, -0.1235, -0.0843,\n",
       "                       -0.4805, -0.1564, -0.1982, -0.3389, -0.0168, -0.1530, -0.1043,  0.0282,\n",
       "                       -0.1642, -0.1180, -0.2023, -0.0564, -0.0670, -0.0416, -0.0164, -0.1482,\n",
       "                       -0.1833, -0.0972, -0.1230, -0.0224, -0.0910,  0.0043, -0.0955,  0.0154,\n",
       "                       -0.1932, -0.1051,  0.0142, -0.2573,  0.0404, -0.1239, -0.0285, -0.1492,\n",
       "                       -0.2065, -0.3352, -0.0544, -0.0620, -0.1288,  0.0537, -0.1082, -0.2810,\n",
       "                       -0.2302, -0.2273, -0.0224, -0.1570, -0.1285, -0.2959, -0.0277, -0.0826,\n",
       "                       -0.0291, -0.0294, -0.1534, -0.3315, -0.0824, -0.0649, -0.2761, -0.1135,\n",
       "                       -0.2444, -0.0674, -0.3628, -0.2920, -0.2279, -0.0707, -0.1208, -0.1188,\n",
       "                       -0.0493, -0.0899, -0.0458, -0.1737, -0.1533, -0.1453, -0.1631, -0.0571,\n",
       "                       -0.3589, -0.1121,  0.0115, -0.0747, -0.2391,  0.0079, -0.0558, -0.0195,\n",
       "                       -0.1810, -0.1694, -0.4604,  0.0063, -0.1873, -0.0007, -0.1137, -0.1080,\n",
       "                       -0.1694, -0.0895, -0.0995, -0.2441, -0.1148, -0.0661, -0.1132, -0.0962,\n",
       "                       -0.3137, -0.1631, -0.1610,  0.0273, -0.2405, -0.1343, -0.0745, -0.1227,\n",
       "                       -0.1322, -0.1396, -0.1028, -0.0528, -0.3127, -0.0318, -0.4597, -0.1335,\n",
       "                       -0.0659, -0.0553, -0.2281, -0.2104, -0.0635, -0.2452, -0.1619, -0.1426,\n",
       "                       -0.0192, -0.1682, -0.1005, -0.0619, -0.2825, -0.1678, -0.1525, -0.0387,\n",
       "                       -0.0095, -0.1063, -0.2379,  0.0410, -0.1228, -0.1501, -0.0260, -0.1655,\n",
       "                       -0.1298, -0.3728, -0.0782, -0.1240, -0.1655, -0.0379, -0.0561, -0.1812,\n",
       "                       -0.1147, -0.0862, -0.1903, -0.1331, -0.1715, -0.0190, -0.1580, -0.0958,\n",
       "                       -0.4329, -0.1185, -0.2009, -0.0781, -0.0403, -0.0377, -0.3923, -0.1393,\n",
       "                       -0.2004, -0.0061, -0.3225, -0.0493, -0.1737, -0.0455, -0.1925, -0.0550,\n",
       "                       -0.1539, -0.1547, -0.1387,  0.0203, -0.1267, -0.1242, -0.2155, -0.2385,\n",
       "                       -0.2001, -0.0362, -0.1122, -0.0705, -0.0540, -0.0026, -0.1558,  0.0010,\n",
       "                       -0.3540, -0.0318, -0.2157, -0.0713, -0.2164, -0.2032, -0.2600, -0.1794,\n",
       "                       -0.1676, -0.1106, -0.1334, -0.1412, -0.1267, -0.0035,  0.0182, -0.2322,\n",
       "                       -0.1584, -0.0087, -0.1121, -0.1694, -0.1936, -0.1416, -0.1741, -0.1925,\n",
       "                       -0.0969, -0.2510, -0.1218, -0.2283, -0.1630, -0.0886, -0.0897, -0.0319,\n",
       "                       -0.1041, -0.3020, -0.0833, -0.0640, -0.2781, -0.2253, -0.0945, -0.1228,\n",
       "                       -0.1631, -0.1853, -0.1025, -0.0831, -0.2175, -0.0290, -0.2377, -0.0389,\n",
       "                       -0.0303, -0.0847, -0.1199, -0.1653, -0.0950, -0.1271, -0.0933,  0.0069,\n",
       "                       -0.0327, -0.2581, -0.1981, -0.0795, -0.0565, -0.1885, -0.0933, -0.1584,\n",
       "                       -0.1049, -0.0380, -0.0901,  0.0047, -0.0651, -0.1508, -0.0787, -0.2386,\n",
       "                       -0.3203, -0.3623, -0.1207, -0.1382, -0.3267, -0.1809, -0.1292,  0.0836,\n",
       "                       -0.1028, -0.1348, -0.1180, -0.0992, -0.1793, -0.0849, -0.1501, -0.1671,\n",
       "                       -0.0301, -0.0908, -0.1604, -0.2908, -0.2255, -0.2922, -0.0266, -0.3091,\n",
       "                       -0.2252, -0.0490, -0.2517, -0.0765, -0.1298, -0.1923, -0.0131, -0.1130,\n",
       "                       -0.3203, -0.3293, -0.1049,  0.0174, -0.3198, -0.0071, -0.0632, -0.1908,\n",
       "                       -0.1039,  0.0027, -0.3386, -0.4102, -0.0037, -0.1614, -0.1302, -0.0778,\n",
       "                       -0.1263, -0.1948, -0.0758, -0.2050, -0.2349, -0.2260,  0.0219, -0.2268,\n",
       "                       -0.3630, -0.0630, -0.2761, -0.0589, -0.1759, -0.2405, -0.1860, -0.2634,\n",
       "                       -0.0321, -0.3525, -0.3625, -0.1364, -0.4082, -0.1361, -0.0074, -0.1987,\n",
       "                        0.0137, -0.2399, -0.0889, -0.0765, -0.1231, -0.1232, -0.3037, -0.0735])),\n",
       "              ('w2v_encoder.w2v_model.feature_extractor.conv_layers.2.0.weight',\n",
       "               tensor([[[-0.0154,  0.0317,  0.1307],\n",
       "                        [-0.1536,  0.0499, -0.0991],\n",
       "                        [-0.0667,  0.0116,  0.0262],\n",
       "                        ...,\n",
       "                        [ 0.0454, -0.0010,  0.0707],\n",
       "                        [-0.0706,  0.0909,  0.1209],\n",
       "                        [-0.0720,  0.0952,  0.0241]],\n",
       "               \n",
       "                       [[-0.1868,  0.1744, -0.0258],\n",
       "                        [-0.0555, -0.0451, -0.2922],\n",
       "                        [ 0.0590,  0.1009,  0.1283],\n",
       "                        ...,\n",
       "                        [ 0.0833,  0.1328,  0.0539],\n",
       "                        [-0.2170, -0.1284, -0.0948],\n",
       "                        [-0.0382,  0.0379, -0.1102]],\n",
       "               \n",
       "                       [[ 0.1133,  0.0296, -0.0565],\n",
       "                        [ 0.0605,  0.0611, -0.0288],\n",
       "                        [-0.0892, -0.0797,  0.1206],\n",
       "                        ...,\n",
       "                        [-0.0010,  0.0060,  0.0834],\n",
       "                        [ 0.0243, -0.0191, -0.0332],\n",
       "                        [-0.0540, -0.1081, -0.1956]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[ 0.1213, -0.0599,  0.1023],\n",
       "                        [-0.0643, -0.0531,  0.1838],\n",
       "                        [ 0.0190,  0.0425, -0.0408],\n",
       "                        ...,\n",
       "                        [-0.0710,  0.0602, -0.0600],\n",
       "                        [ 0.0593, -0.0500,  0.0776],\n",
       "                        [-0.0608,  0.0520,  0.0049]],\n",
       "               \n",
       "                       [[ 0.0109,  0.0055,  0.0797],\n",
       "                        [ 0.0847, -0.5903, -0.0691],\n",
       "                        [ 0.2345, -0.0083, -0.0601],\n",
       "                        ...,\n",
       "                        [ 0.0320,  0.0067,  0.0823],\n",
       "                        [ 0.0321, -0.0167, -0.0793],\n",
       "                        [ 0.0115, -0.1766, -0.0169]],\n",
       "               \n",
       "                       [[ 0.0797, -0.1407,  0.2073],\n",
       "                        [ 0.1116,  0.0498,  0.0169],\n",
       "                        [-0.0130, -0.0459, -0.0050],\n",
       "                        ...,\n",
       "                        [ 0.0303, -0.0081, -0.0236],\n",
       "                        [-0.0795,  0.0475, -0.2546],\n",
       "                        [-0.0141,  0.0383,  0.0703]]])),\n",
       "              ('w2v_encoder.w2v_model.feature_extractor.conv_layers.2.2.1.weight',\n",
       "               tensor([0.8730, 0.8271, 0.4739, 1.1230, 0.5986, 1.3525, 1.3057, 0.5283, 0.7617,\n",
       "                       3.1738, 0.3232, 0.5342, 0.4504, 1.2422, 1.1045, 0.4490, 0.4075, 0.3540,\n",
       "                       0.2292, 0.9346, 1.2393, 1.1064, 0.6875, 0.6987, 0.8862, 0.6172, 0.6831,\n",
       "                       0.7842, 0.3010, 0.9927, 0.7842, 0.1610, 0.2498, 0.7842, 0.4873, 0.3010,\n",
       "                       0.7285, 0.5732, 0.8848, 0.5986, 1.9873, 0.4646, 0.8872, 0.6924, 0.3984,\n",
       "                       0.9126, 0.3643, 0.1447, 0.7554, 0.6680, 0.2671, 0.5938, 0.6211, 0.9194,\n",
       "                       0.6792, 0.2244, 0.7437, 0.6157, 1.0674, 0.2341, 1.3867, 0.4385, 0.6943,\n",
       "                       0.1368, 0.2272, 0.2893, 1.0029, 0.9897, 0.8643, 0.6812, 0.4294, 1.2764,\n",
       "                       0.7974, 0.5972, 0.6421, 0.5986, 0.2467, 0.8242, 0.9663, 0.6279, 0.3223,\n",
       "                       0.8706, 0.5098, 0.4766, 0.5435, 0.4875, 0.6934, 0.8350, 0.4968, 1.1201,\n",
       "                       0.6675, 0.3894, 0.7480, 0.9966, 0.5029, 0.7617, 0.9785, 0.7183, 0.4807,\n",
       "                       0.9224, 0.7090, 0.7881, 0.3662, 0.8486, 0.6489, 0.5420, 0.4424, 0.5723,\n",
       "                       0.2075, 0.8730, 0.9424, 0.2673, 0.2847, 1.0088, 0.2654, 0.4199, 0.7422,\n",
       "                       0.8628, 0.7236, 1.1436, 0.3723, 0.8770, 0.4121, 1.2500, 1.0137, 0.7183,\n",
       "                       0.6694, 0.8394, 0.4756, 0.6396, 0.6626, 0.8306, 0.5767, 0.3235, 0.5278,\n",
       "                       0.8423, 1.0244, 0.2764, 0.3015, 0.7661, 0.8506, 0.8887, 0.9121, 0.4954,\n",
       "                       0.6816, 0.1866, 0.6558, 1.0283, 0.6772, 0.7539, 2.0137, 0.6963, 0.8428,\n",
       "                       0.7944, 0.5005, 1.2373, 0.7012, 0.7729, 0.5215, 0.5488, 0.3413, 0.3101,\n",
       "                       0.7305, 0.6484, 0.9663, 0.5776, 0.6768, 0.5718, 0.5352, 0.6753, 1.3779,\n",
       "                       0.6328, 0.1226, 0.6416, 0.6318, 0.4937, 0.7124, 0.4512, 0.8691, 0.5205,\n",
       "                       0.4290, 0.4685, 1.1475, 0.4851, 0.5376, 0.6289, 0.7612, 0.6118, 0.9082,\n",
       "                       0.4565, 1.0986, 0.5459, 0.3738, 0.4309, 0.6426, 0.7866, 0.6934, 0.3269,\n",
       "                       0.7715, 0.6353, 0.7344, 0.8198, 1.0439, 0.6128, 0.6602, 0.7778, 1.1758,\n",
       "                       0.5845, 0.9756, 0.4724, 0.6079, 0.3301, 1.0771, 0.4773, 0.2896, 0.2598,\n",
       "                       0.7788, 0.6348, 0.6089, 0.3511, 0.7437, 0.4243, 0.3499, 1.1641, 1.0400,\n",
       "                       0.2351, 0.5234, 0.3374, 0.5898, 0.2783, 0.4941, 0.7480, 0.4521, 0.5850,\n",
       "                       0.6343, 0.4175, 0.4941, 0.2281, 1.1279, 0.7339, 0.8984, 1.3789, 0.3911,\n",
       "                       0.3987, 0.4780, 0.5771, 0.6606, 0.9180, 0.2362, 1.0029, 1.0625, 0.5708,\n",
       "                       0.5059, 0.4839, 0.9629, 0.5156, 0.6426, 0.7383, 0.6494, 1.4980, 0.9912,\n",
       "                       0.9082, 0.5522, 0.4695, 1.7617, 0.6509, 0.6792, 0.4670, 0.3923, 0.1642,\n",
       "                       1.1309, 0.8901, 0.8433, 0.8213, 0.2512, 0.9771, 0.7329, 0.4099, 0.3030,\n",
       "                       1.1885, 0.5347, 0.4758, 0.7847, 0.8438, 0.3525, 0.9233, 0.8706, 0.3965,\n",
       "                       0.8457, 0.7754, 0.7476, 0.7964, 0.9282, 1.3125, 0.6187, 0.9736, 0.4587,\n",
       "                       1.4834, 1.2295, 0.4944, 0.5635, 0.6387, 1.0137, 0.2856, 0.6997, 0.5493,\n",
       "                       0.7974, 0.2898, 0.3860, 0.6470, 0.3115, 0.5039, 0.2932, 0.7637, 0.5596,\n",
       "                       0.3992, 0.7285, 0.7617, 0.6807, 1.1377, 0.7275, 0.7583, 0.7690, 0.5483,\n",
       "                       1.3418, 0.5415, 0.9385, 0.4548, 0.6255, 0.5151, 0.3523, 0.4290, 0.7983,\n",
       "                       0.8960, 0.6665, 0.4250, 0.5371, 1.2354, 0.4021, 0.6064, 1.0811, 1.3232,\n",
       "                       1.0459, 0.8076, 0.6011, 0.3796, 0.5522, 0.4185, 0.7544, 0.2849, 1.3164,\n",
       "                       0.5068, 0.6738, 0.7246, 0.9424, 0.7144, 0.6313, 0.8271, 1.0908, 0.9478,\n",
       "                       0.4695, 0.4194, 0.2476, 0.5728, 0.3713, 0.6987, 0.5781, 0.5176, 0.3159,\n",
       "                       1.2236, 0.6802, 0.3115, 0.8066, 1.2441, 0.5615, 0.3579, 0.6548, 0.2859,\n",
       "                       1.8174, 0.4688, 0.8467, 0.6738, 0.6387, 0.6533, 0.6304, 0.5400, 0.3135,\n",
       "                       0.3701, 0.6372, 0.1489, 0.7432, 0.3169, 0.3950, 0.6304, 0.5444, 0.6807,\n",
       "                       1.0732, 0.8242, 0.5659, 1.0039, 0.3098, 0.5991, 0.5142, 0.6392, 0.7998,\n",
       "                       0.7256, 0.6221, 0.7124, 0.7783, 0.9199, 0.2194, 0.9927, 0.7969, 0.7876,\n",
       "                       0.7227, 0.7822, 0.9404, 0.3291, 0.4731, 0.9727, 0.6831, 0.3362, 0.3459,\n",
       "                       0.7456, 0.2981, 0.7256, 0.3960, 1.5898, 0.3579, 0.9331, 0.5815, 0.7344,\n",
       "                       0.2333, 1.4746, 0.7471, 0.9570, 0.3484, 1.3008, 0.7007, 0.8950, 0.8550,\n",
       "                       0.7627, 0.2756, 0.8672, 1.2383, 0.4390, 0.5103, 0.7373, 0.7749, 0.4116,\n",
       "                       0.3916, 1.2656, 0.7397, 0.5371, 0.6333, 0.7935, 1.0430, 1.4512, 0.8794,\n",
       "                       0.6343, 0.6460, 0.4741, 0.6846, 0.6123, 0.6104, 0.9170, 0.4385, 0.5312,\n",
       "                       0.5474, 0.7622, 0.1571, 0.8569, 0.5591, 0.6733, 0.3887, 0.9624, 0.2544,\n",
       "                       0.7158, 0.5767, 1.0850, 1.1309, 1.0449, 0.9302, 0.4763, 0.0871, 0.4478,\n",
       "                       0.2725, 0.3645, 0.8892, 0.6445, 0.4399, 0.8657, 0.8857, 0.7173, 0.5049,\n",
       "                       0.9634, 0.7744, 0.5698, 0.7998, 0.7524, 0.7070, 0.7241, 0.7725, 1.1465,\n",
       "                       0.2983, 0.7104, 0.5659, 0.4260, 0.8540, 0.1742, 0.5791, 0.6133])),\n",
       "              ('w2v_encoder.w2v_model.feature_extractor.conv_layers.2.2.1.bias',\n",
       "               tensor([-2.7393e-01, -4.2920e-01, -7.0839e-03, -1.2244e-01, -1.6101e-01,\n",
       "                       -1.9165e-01, -1.7517e-01, -1.9360e-01, -9.7595e-02, -2.8125e-01,\n",
       "                       -1.6394e-01,  1.9974e-02, -1.8848e-01, -4.9390e-01, -4.3549e-02,\n",
       "                        3.2867e-02, -1.3232e-01, -2.4451e-01, -1.9800e-01, -1.1786e-01,\n",
       "                       -3.0664e-01, -4.9805e-01, -2.0361e-01, -3.8745e-01, -1.3843e-01,\n",
       "                       -1.4990e-01, -2.8931e-01, -1.2830e-01, -1.8738e-01, -1.4697e-01,\n",
       "                       -1.0364e-01, -1.2134e-01, -1.6479e-01, -1.4294e-01, -2.4353e-01,\n",
       "                       -1.5552e-01, -1.7261e-01, -2.4890e-01, -2.8320e-01, -2.8000e-02,\n",
       "                       -3.4302e-01, -2.1286e-02, -3.5132e-01, -4.4946e-01, -2.3450e-01,\n",
       "                       -2.8687e-01,  2.5116e-02, -1.5686e-01, -4.2578e-01, -4.1479e-01,\n",
       "                       -1.8591e-01, -1.6443e-01, -2.5223e-02, -2.1741e-01, -2.2449e-01,\n",
       "                       -1.8604e-01, -1.7688e-01, -3.2764e-01, -3.7817e-01, -1.6357e-01,\n",
       "                       -4.4441e-03, -5.5008e-03, -2.0703e-01, -1.6882e-01, -1.4905e-01,\n",
       "                       -2.0996e-01, -3.3862e-01, -3.6597e-01, -7.1655e-02, -3.7598e-01,\n",
       "                       -1.5955e-01, -4.1772e-01, -1.0712e-01, -3.3276e-01, -2.8418e-01,\n",
       "                       -2.4368e-02, -1.5479e-01, -2.9590e-01, -3.9331e-01, -4.5815e-03,\n",
       "                       -2.1497e-01, -8.1848e-02, -1.5942e-01, -8.7891e-02, -1.4087e-01,\n",
       "                       -1.1353e-02, -2.2205e-01, -3.9600e-01, -1.3977e-01, -3.1519e-01,\n",
       "                       -1.6565e-01, -1.4294e-01, -1.3147e-01,  8.2092e-03, -1.9910e-01,\n",
       "                       -6.4087e-02, -1.0657e-01, -3.7598e-01,  6.5552e-02, -4.4287e-01,\n",
       "                       -2.1777e-01, -1.2524e-01, -2.2034e-01, -5.0830e-01, -7.1973e-01,\n",
       "                       -1.7346e-01, -1.5430e-01,  4.1275e-03, -1.8372e-01, -2.2205e-01,\n",
       "                       -3.5229e-01, -1.8347e-01, -1.7383e-01,  5.0812e-02, -1.8921e-01,\n",
       "                       -1.8530e-01, -1.5808e-02, -2.4927e-01, -3.8843e-01, -3.8110e-01,\n",
       "                       -1.6174e-01, -2.7734e-01, -2.4634e-01, -8.7769e-02,  9.1324e-03,\n",
       "                       -2.9639e-01, -1.1261e-01, -3.2520e-01, -1.9031e-01, -2.9932e-01,\n",
       "                       -3.3252e-01, -1.3110e-01, -3.2764e-01, -1.9592e-01, -9.1431e-02,\n",
       "                       -1.8506e-01, -2.9565e-01, -1.5076e-01, -1.5112e-01, -1.3757e-01,\n",
       "                       -1.7786e-01,  5.0049e-03, -1.1908e-01, -1.3184e-01, -9.2773e-02,\n",
       "                       -1.5967e-01, -1.1652e-01, -3.3765e-01, -2.1375e-01, -1.0529e-01,\n",
       "                       -7.1484e-01, -3.1958e-01, -1.6589e-01, -3.3716e-01, -1.6687e-01,\n",
       "                       -2.4670e-01, -3.0371e-01, -6.5002e-02, -1.4978e-01, -1.7468e-01,\n",
       "                       -2.5244e-01, -1.3000e-01, -9.3750e-02, -1.0986e-01, -1.1188e-01,\n",
       "                       -7.7881e-02, -3.9111e-01, -4.3286e-01, -6.2988e-02, -2.1875e-01,\n",
       "                       -6.0400e-01, -9.0515e-02, -1.5173e-01, -1.3208e-01, -2.3645e-01,\n",
       "                       -8.3557e-02, -1.8494e-02, -1.2830e-01, -4.1479e-01, -1.9373e-01,\n",
       "                       -1.6418e-01, -2.6245e-01, -5.0781e-01, -3.0182e-02, -2.2290e-01,\n",
       "                       -3.5718e-01, -1.0577e-01, -3.3936e-02, -3.2007e-01, -1.4551e-01,\n",
       "                        7.2174e-03, -8.0383e-02, -1.4673e-01, -4.7333e-02, -6.2866e-02,\n",
       "                       -5.7031e-01, -3.9917e-01, -1.6663e-01, -1.0699e-01, -4.1211e-01,\n",
       "                       -3.6523e-01, -4.2969e-01, -3.3057e-01, -2.8638e-01, -1.2817e-01,\n",
       "                       -3.9746e-01, -6.6357e-01, -1.8848e-01, -4.1113e-01, -1.5881e-01,\n",
       "                       -4.1309e-01, -1.8127e-01, -4.3555e-01, -8.6365e-03, -1.6272e-01,\n",
       "                       -1.5527e-01, -8.4900e-02, -8.3984e-02, -2.6901e-02, -2.5000e-01,\n",
       "                       -3.0908e-01,  2.1545e-02, -2.1875e-01, -4.3311e-01, -3.8110e-01,\n",
       "                       -1.0901e-01, -3.3813e-01, -1.9739e-01, -1.9299e-01, -1.8787e-01,\n",
       "                       -2.2058e-01, -1.1517e-01, -2.7954e-01, -2.2046e-01, -2.7002e-01,\n",
       "                       -1.7761e-01, -1.1279e-01, -1.7151e-01, -5.3076e-01, -1.0040e-01,\n",
       "                       -2.1790e-01, -3.4839e-01, -2.0056e-01, -1.7834e-01, -3.3264e-03,\n",
       "                       -1.2128e-01,  3.6926e-03, -7.5012e-02, -1.6797e-01, -2.1033e-01,\n",
       "                       -7.7271e-02, -1.3695e-03, -9.1431e-02, -2.4829e-01, -2.0386e-01,\n",
       "                       -1.7798e-01,  2.7142e-03, -2.2046e-01, -2.9272e-01, -4.6338e-01,\n",
       "                        4.0344e-02, -2.0764e-01, -2.3914e-01, -1.3782e-01, -6.4575e-02,\n",
       "                       -3.4033e-01, -2.3682e-01, -1.2390e-02, -1.4697e-01, -1.4636e-01,\n",
       "                       -3.0518e-01, -1.9299e-01, -1.1285e-01, -2.5635e-01, -1.7566e-01,\n",
       "                       -1.4722e-01,  1.7609e-02, -2.7661e-01, -1.8579e-01, -7.1338e-01,\n",
       "                        2.7374e-02, -2.0923e-01, -4.0186e-01, -3.3386e-02, -1.5466e-01,\n",
       "                       -1.0559e-01, -1.4404e-01, -2.0605e-01, -1.9434e-01, -4.8767e-02,\n",
       "                       -2.0349e-01, -1.2299e-01, -2.5928e-01, -5.8887e-01, -1.4636e-01,\n",
       "                        3.6530e-02, -7.7820e-02, -5.2429e-02, -1.4270e-01, -2.2388e-01,\n",
       "                       -1.7252e-03, -2.9785e-01, -3.2007e-01, -1.7200e-01, -2.7734e-01,\n",
       "                       -3.2806e-02, -1.2537e-01, -1.6907e-01, -4.8409e-03, -3.6011e-01,\n",
       "                       -4.2572e-02, -2.2681e-01, -1.6760e-01, -2.7856e-01, -1.5404e-02,\n",
       "                       -1.6565e-01, -1.8079e-01, -3.6084e-01, -6.1432e-02, -2.8152e-02,\n",
       "                       -3.0396e-01, -3.0899e-02, -1.6016e-01, -2.8467e-01, -2.0459e-01,\n",
       "                       -2.7878e-02, -2.8564e-01, -3.3887e-01, -2.2339e-01,  2.8046e-02,\n",
       "                       -9.6802e-02, -1.0178e-02, -2.1497e-01, -2.0105e-01, -2.5781e-01,\n",
       "                       -8.8623e-02, -4.0222e-02, -5.2588e-01, -2.0825e-01, -1.4636e-01,\n",
       "                        7.6538e-02, -1.2708e-01, -4.7046e-01, -3.8818e-02, -1.0583e-01,\n",
       "                       -1.2573e-02,  9.2239e-03, -1.3379e-01, -3.1250e-01, -1.7737e-01,\n",
       "                       -4.7241e-01, -1.8402e-02, -1.2433e-01, -1.9055e-01, -2.8610e-02,\n",
       "                       -8.5449e-02, -3.9453e-01, -2.7002e-01, -1.2122e-01, -1.7725e-01,\n",
       "                       -1.6028e-01, -1.4465e-01, -1.5625e-01, -9.5337e-02, -2.9565e-01,\n",
       "                       -3.9087e-01, -1.7249e-01, -1.0107e-01, -1.7029e-01, -1.7017e-01,\n",
       "                       -3.3472e-01, -1.3794e-01, -2.0935e-01, -4.3921e-01, -1.6528e-01,\n",
       "                       -1.7310e-01, -2.3547e-01, -1.6687e-01, -3.1714e-01, -1.2878e-01,\n",
       "                       -9.1125e-02, -2.3022e-01, -3.5986e-01, -4.1577e-01, -3.6523e-01,\n",
       "                       -1.7847e-01, -1.8347e-01, -1.6479e-01, -8.1848e-02, -1.5051e-01,\n",
       "                       -1.1734e-02, -2.2864e-01, -7.9163e-02, -7.1924e-01, -3.3789e-01,\n",
       "                       -2.6416e-01, -4.4727e-01, -9.2224e-02, -2.3120e-01,  5.3070e-02,\n",
       "                       -1.6260e-01, -9.7229e-02, -1.2036e-01, -2.0340e-02, -1.1792e-01,\n",
       "                       -2.8296e-01, -6.0272e-02, -2.0203e-02, -3.5596e-01, -2.9346e-01,\n",
       "                       -4.7363e-02, -8.6853e-02, -1.3489e-01,  1.3649e-02, -3.9355e-01,\n",
       "                       -2.0532e-01, -3.2886e-01, -1.8701e-01, -3.2568e-01, -7.2556e-03,\n",
       "                       -4.2267e-02, -2.3083e-01, -2.2144e-01, -3.0127e-01, -1.7444e-01,\n",
       "                       -3.6890e-01, -1.7883e-01, -2.4796e-02, -1.4465e-01, -2.3499e-01,\n",
       "                       -6.7627e-02, -4.0552e-01, -1.9824e-01, -1.1603e-01, -3.5107e-01,\n",
       "                       -4.3872e-01, -2.1826e-01, -5.6982e-01, -2.2119e-01, -3.4570e-01,\n",
       "                       -8.0017e-02, -2.2437e-01, -1.9519e-01, -1.8298e-01, -6.6455e-01,\n",
       "                       -2.3047e-01, -2.0508e-01, -2.7588e-01, -9.8389e-02, -1.9299e-01,\n",
       "                       -3.7567e-02, -7.8125e-02, -2.7390e-02, -1.3794e-01, -5.0201e-02,\n",
       "                       -1.0791e-01, -3.0624e-02, -2.2839e-01, -5.6396e-01, -1.9690e-01,\n",
       "                       -5.7434e-02, -2.3254e-01, -3.2983e-01, -2.7490e-01, -3.7134e-01,\n",
       "                       -3.4644e-01, -2.9956e-01, -1.7960e-02, -2.5415e-01, -6.9824e-02,\n",
       "                       -1.4221e-01, -2.8717e-02, -2.9297e-01, -2.0288e-01, -1.4966e-01,\n",
       "                       -3.6060e-01, -1.8701e-01, -4.2334e-01, -2.1255e-02, -4.2554e-01,\n",
       "                       -3.5010e-01, -1.3138e-02, -3.0054e-01, -1.3208e-01, -1.0779e-01,\n",
       "                       -3.5913e-01, -2.1667e-01, -2.1497e-01, -2.1289e-01, -2.3975e-01,\n",
       "                       -1.9385e-01, -8.0811e-02, -2.1509e-01, -2.8809e-01, -1.9348e-01,\n",
       "                       -2.6929e-01, -2.5732e-01, -4.0619e-02, -4.4409e-01, -6.7902e-04,\n",
       "                       -3.3984e-01, -1.5417e-01, -1.0101e-01, -3.1030e-01, -1.8152e-01,\n",
       "                       -1.7847e-01, -1.9751e-01,  3.7231e-02, -3.0322e-01, -1.6248e-01,\n",
       "                       -2.7979e-01, -4.1577e-01])),\n",
       "              ('w2v_encoder.w2v_model.feature_extractor.conv_layers.3.0.weight',\n",
       "               tensor([[[ 0.0604,  0.0764, -0.0345],\n",
       "                        [-0.0184,  0.0707,  0.0114],\n",
       "                        [ 0.1982,  0.1328, -0.0189],\n",
       "                        ...,\n",
       "                        [ 0.0436, -0.0961, -0.0541],\n",
       "                        [-0.0214, -0.1182, -0.0380],\n",
       "                        [-0.0754, -0.0888,  0.1366]],\n",
       "               \n",
       "                       [[ 0.1700,  0.0351, -0.1131],\n",
       "                        [-0.0351, -0.0019, -0.0406],\n",
       "                        [ 0.0156,  0.1287,  0.0031],\n",
       "                        ...,\n",
       "                        [ 0.1283,  0.0028,  0.0607],\n",
       "                        [ 0.0346, -0.0823,  0.0015],\n",
       "                        [-0.1433, -0.1926, -0.0162]],\n",
       "               \n",
       "                       [[ 0.0323,  0.0202, -0.0152],\n",
       "                        [ 0.0129, -0.0157, -0.0201],\n",
       "                        [ 0.0372,  0.0337, -0.0134],\n",
       "                        ...,\n",
       "                        [-0.2258,  0.0135,  0.1257],\n",
       "                        [ 0.0258,  0.0790,  0.0761],\n",
       "                        [-0.1396,  0.1272, -0.0987]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[-0.0217, -0.0043,  0.0725],\n",
       "                        [ 0.0193,  0.1416,  0.0099],\n",
       "                        [ 0.1919,  0.0908, -0.2290],\n",
       "                        ...,\n",
       "                        [ 0.0376, -0.0595,  0.0863],\n",
       "                        [ 0.0758, -0.0703, -0.0955],\n",
       "                        [-0.0948,  0.0213, -0.0461]],\n",
       "               \n",
       "                       [[ 0.0287,  0.0905,  0.0561],\n",
       "                        [ 0.0590,  0.0336,  0.0137],\n",
       "                        [-0.0376, -0.0409,  0.0099],\n",
       "                        ...,\n",
       "                        [ 0.0383, -0.0627, -0.0735],\n",
       "                        [-0.0067,  0.0016,  0.0331],\n",
       "                        [ 0.0279, -0.0201, -0.0144]],\n",
       "               \n",
       "                       [[ 0.0471,  0.0792,  0.1125],\n",
       "                        [ 0.0765,  0.0721,  0.0131],\n",
       "                        [ 0.1208,  0.0097, -0.0116],\n",
       "                        ...,\n",
       "                        [-0.0259,  0.0117,  0.0165],\n",
       "                        [-0.0054,  0.0141, -0.0178],\n",
       "                        [ 0.1035,  0.2469,  0.0995]]])),\n",
       "              ('w2v_encoder.w2v_model.feature_extractor.conv_layers.3.2.1.weight',\n",
       "               tensor([0.4761, 0.5410, 0.5781, 0.2085, 1.0400, 0.5967, 0.3894, 0.5708, 0.7534,\n",
       "                       0.7646, 0.6489, 1.1152, 0.9590, 1.0518, 0.3569, 0.5620, 1.1035, 0.7100,\n",
       "                       0.7690, 1.4121, 0.3855, 0.9390, 0.9370, 0.2203, 0.8462, 0.7188, 0.6470,\n",
       "                       0.8589, 0.4199, 0.3289, 1.0205, 0.9536, 0.3391, 0.7456, 0.1271, 0.6284,\n",
       "                       0.4858, 0.4114, 0.7817, 0.6753, 0.4734, 1.0234, 0.7437, 0.4941, 0.3701,\n",
       "                       0.7778, 0.4590, 0.8218, 0.7192, 0.8818, 0.7656, 0.6870, 0.8208, 0.6475,\n",
       "                       0.7661, 0.5962, 0.7173, 0.6631, 1.1084, 0.2522, 0.3386, 0.6030, 1.0391,\n",
       "                       0.6123, 0.8901, 0.3286, 0.8296, 0.5571, 0.6870, 0.4341, 0.3950, 1.0723,\n",
       "                       0.4961, 0.5537, 0.1499, 0.4946, 0.3914, 0.6792, 0.5713, 0.5864, 0.6597,\n",
       "                       0.8447, 0.5781, 0.7266, 0.8159, 0.9414, 0.6714, 0.7202, 0.4868, 0.6147,\n",
       "                       1.3496, 0.7217, 0.8779, 0.5532, 1.7725, 0.3694, 0.6973, 1.6348, 1.5957,\n",
       "                       0.6914, 0.9224, 0.4795, 0.1930, 0.6343, 0.4280, 0.6094, 0.5386, 0.4966,\n",
       "                       0.8857, 0.6772, 0.2771, 0.7231, 0.6606, 0.3452, 0.4934, 0.6558, 1.1104,\n",
       "                       0.7812, 0.3645, 1.1455, 0.6704, 0.8120, 0.2944, 0.4236, 0.7651, 0.8872,\n",
       "                       0.3291, 0.7300, 0.6089, 0.3196, 0.5200, 0.5898, 0.6396, 0.4441, 0.6426,\n",
       "                       0.5854, 0.7637, 0.6714, 0.5122, 1.1934, 0.6001, 0.5366, 1.0986, 0.6528,\n",
       "                       0.5034, 1.3398, 0.5742, 0.6602, 0.9204, 1.2354, 1.1104, 0.1986, 1.0029,\n",
       "                       0.3792, 0.9404, 0.5830, 0.4312, 0.4065, 0.8696, 0.5156, 0.6841, 0.7490,\n",
       "                       0.4048, 1.1367, 0.6382, 0.4148, 0.6040, 0.4641, 0.4690, 0.6973, 0.3467,\n",
       "                       0.7256, 1.0820, 0.5498, 0.6123, 0.6523, 0.9233, 1.0068, 0.3889, 0.5063,\n",
       "                       0.8384, 0.6743, 1.0078, 0.9102, 0.8369, 0.9038, 0.4058, 0.6416, 0.2800,\n",
       "                       1.0430, 0.5591, 0.2607, 0.8179, 0.6206, 0.5132, 1.0400, 0.7378, 0.8325,\n",
       "                       0.3550, 0.3452, 1.0010, 0.7261, 0.5146, 0.7495, 0.5752, 0.8579, 0.6089,\n",
       "                       1.0781, 0.6943, 0.3093, 0.3381, 0.9082, 1.3857, 0.8696, 0.8511, 0.8799,\n",
       "                       0.4875, 0.4490, 0.6143, 0.8315, 0.3796, 1.0498, 0.9150, 0.9146, 0.7090,\n",
       "                       0.5322, 1.0088, 0.8789, 1.0449, 0.7144, 0.4854, 0.9326, 0.8037, 0.8145,\n",
       "                       0.4250, 0.5659, 0.5386, 0.4629, 0.8740, 0.8765, 0.6172, 0.7788, 0.9585,\n",
       "                       0.5903, 0.6016, 0.5200, 1.8369, 0.5190, 0.4917, 0.4463, 0.5850, 0.5977,\n",
       "                       0.8403, 1.1875, 1.0771, 0.8628, 0.8320, 0.2976, 0.4751, 0.5791, 0.9741,\n",
       "                       0.6304, 0.1765, 0.6201, 0.5693, 0.8799, 0.9795, 0.6069, 0.7305, 0.4609,\n",
       "                       0.9048, 0.5596, 0.5454, 0.5024, 0.5820, 0.4478, 0.5044, 0.5820, 0.6392,\n",
       "                       0.2463, 0.4260, 0.5903, 0.7700, 0.9043, 0.3149, 0.8770, 0.5093, 0.8525,\n",
       "                       0.8804, 0.8696, 0.8438, 0.5298, 0.6099, 1.0801, 0.9956, 0.7891, 0.8496,\n",
       "                       0.9536, 0.9067, 0.5679, 0.4326, 0.6841, 0.4792, 0.7344, 0.7886, 0.7271,\n",
       "                       0.7173, 0.7749, 0.7451, 0.9087, 0.5078, 0.5010, 0.7168, 0.2410, 1.2383,\n",
       "                       0.4309, 0.3044, 0.8340, 0.6616, 0.6460, 0.7051, 0.7407, 0.9072, 0.9409,\n",
       "                       0.4133, 0.3350, 0.5938, 1.0537, 1.1348, 0.4631, 0.3142, 0.9902, 0.3564,\n",
       "                       0.4199, 1.0586, 0.3477, 0.5996, 0.7305, 0.3335, 0.4775, 0.2163, 0.2969,\n",
       "                       0.3398, 0.7549, 0.4973, 0.9028, 0.5737, 0.3218, 0.7886, 0.5220, 0.8984,\n",
       "                       0.5693, 0.7134, 0.6636, 0.4497, 1.0078, 0.8115, 1.1143, 0.3186, 0.5801,\n",
       "                       1.3027, 0.5928, 0.7368, 0.7817, 0.5469, 0.7490, 0.2061, 0.2954, 0.2756,\n",
       "                       0.6655, 0.6250, 0.5088, 0.4475, 0.3206, 0.4951, 0.5986, 0.5078, 0.9839,\n",
       "                       0.6777, 0.3716, 0.7192, 0.3660, 1.2822, 0.6504, 0.5107, 0.8022, 0.6606,\n",
       "                       0.8916, 0.9326, 0.9146, 0.8125, 0.4873, 0.6475, 0.3125, 0.5791, 0.6475,\n",
       "                       0.9048, 0.9927, 1.2100, 1.1172, 1.3467, 0.8047, 0.8965, 0.4312, 0.9966,\n",
       "                       0.2932, 0.4702, 0.4285, 0.8931, 0.2047, 0.5791, 0.3545, 0.7163, 0.4070,\n",
       "                       0.3936, 0.7373, 1.3672, 0.8369, 0.5854, 0.4084, 0.8306, 0.7305, 0.4031,\n",
       "                       0.3931, 0.2954, 0.9199, 0.9346, 0.4741, 0.7378, 0.7856, 0.3547, 0.8608,\n",
       "                       1.0244, 0.5522, 1.6934, 0.4507, 0.6094, 0.5430, 0.4397, 1.1289, 0.4836,\n",
       "                       1.0635, 0.9038, 1.0449, 0.2208, 0.5449, 0.3181, 0.3738, 0.8203, 1.0195,\n",
       "                       0.5576, 0.7891, 0.3296, 0.6558, 0.6050, 1.5596, 0.7129, 0.8301, 0.3142,\n",
       "                       1.2910, 0.3835, 0.5859, 0.7734, 0.7554, 0.9995, 0.8633, 0.5449, 0.7129,\n",
       "                       0.3838, 0.9028, 0.5513, 0.4243, 0.6670, 0.7021, 0.8931, 0.7642, 0.3806,\n",
       "                       0.7842, 0.5254, 1.1113, 0.2698, 0.4250, 1.0361, 0.5273, 0.9819, 0.8140,\n",
       "                       0.6401, 0.8608, 0.4375, 0.4458, 0.3450, 0.9072, 0.3564, 0.5483, 0.2834,\n",
       "                       0.9902, 0.3796, 0.3257, 0.5996, 0.6284, 0.6968, 0.6533, 0.3625, 0.5439,\n",
       "                       0.6602, 0.3857, 0.4893, 1.9102, 0.6323, 0.8926, 0.5884, 0.7681])),\n",
       "              ('w2v_encoder.w2v_model.feature_extractor.conv_layers.3.2.1.bias',\n",
       "               tensor([-0.1588, -0.1781, -0.2189, -0.2683, -0.2986, -0.1566, -0.0793, -0.0621,\n",
       "                       -0.2842, -0.0407, -0.3472, -0.1747, -0.0670, -0.3130, -0.1880, -0.1072,\n",
       "                       -0.4871, -0.1498,  0.0048, -0.1442, -0.1477, -0.4641, -0.4275, -0.2246,\n",
       "                       -0.3560, -0.1154, -0.3506, -0.2642, -0.2047, -0.2252, -0.2179, -0.1696,\n",
       "                       -0.1650, -0.0969, -0.2456, -0.2371, -0.0519, -0.2223, -0.3110, -0.0764,\n",
       "                       -0.0304, -0.2837, -0.2119,  0.0007, -0.3198, -0.2152, -0.0909, -0.1887,\n",
       "                       -0.4131, -0.2656, -0.2180, -0.2485, -0.1841, -0.2534, -0.2041, -0.0535,\n",
       "                       -0.2517, -0.1652, -0.1392, -0.2803, -0.1598, -0.0941, -0.2416, -0.0458,\n",
       "                       -0.3455, -0.2432, -0.2554, -0.0472, -0.2883, -0.1033, -0.2101, -0.0091,\n",
       "                       -0.1917, -0.0800, -0.1320, -0.1719,  0.0323, -0.1124, -0.3477, -0.1404,\n",
       "                       -0.3120, -0.3696, -0.0864, -0.1418, -0.0906, -0.2062, -0.1344, -0.2800,\n",
       "                       -0.0976, -0.1578,  0.0557, -0.1378, -0.1471, -0.1063,  0.0203, -0.1864,\n",
       "                       -0.2632, -0.0930, -0.4233, -0.1675, -0.1207, -0.1289, -0.2417, -0.1852,\n",
       "                       -0.1755, -0.1167, -0.2622, -0.0856, -0.2903, -0.2642,  0.0917, -0.2903,\n",
       "                       -0.1207, -0.2070, -0.1130, -0.2715, -0.3103, -0.0201, -0.1735, -0.2637,\n",
       "                       -0.1074, -0.1746, -0.0724, -0.1052, -0.1053, -0.4712, -0.1974, -0.1412,\n",
       "                       -0.0410, -0.2144, -0.0594, -0.0634, -0.2832, -0.1001, -0.2551, -0.1393,\n",
       "                       -0.2346, -0.2812, -0.1299, -0.1570, -0.1061, -0.3450, -0.4512, -0.2098,\n",
       "                       -0.1890, -0.0306, -0.3479, -0.0745, -0.2097, -0.0966, -0.2502, -0.3005,\n",
       "                       -0.1929, -0.1266, -0.2703, -0.2888, -0.1090, -0.1367, -0.0931, -0.1438,\n",
       "                       -0.0428, -0.1282, -0.1730,  0.0008, -0.3650, -0.2028, -0.3960, -0.1095,\n",
       "                       -0.0067, -0.1615, -0.1307, -0.2224, -0.3108, -0.1747, -0.1960, -0.3867,\n",
       "                       -0.3218, -0.3003, -0.2334, -0.0455, -0.1980, -0.1975, -0.2209,  0.0127,\n",
       "                       -0.1852, -0.2197, -0.1360, -0.2839, -0.1997, -0.3840, -0.1118, -0.1583,\n",
       "                       -0.1017, -0.3420, -0.1427, -0.1217, -0.4021, -0.2047, -0.2637, -0.2539,\n",
       "                       -0.4844, -0.3157, -0.1384, -0.1321, -0.0243, -0.2878, -0.1038, -0.1071,\n",
       "                       -0.1917, -0.1993, -0.1476, -0.1583,  0.0162, -0.1191, -0.3169, -0.2322,\n",
       "                       -0.2330, -0.2462, -0.0595, -0.3511, -0.1637, -0.4675, -0.3594, -0.2299,\n",
       "                       -0.3286, -0.2001, -0.3003, -0.4341, -0.1969, -0.1685, -0.2151, -0.2859,\n",
       "                       -0.1912, -0.4302, -0.1838, -0.1859, -0.1207, -0.5381, -0.4065, -0.2588,\n",
       "                       -0.2496, -0.4397, -0.2817, -0.0338, -0.4011, -0.0846, -0.1405, -0.1002,\n",
       "                       -0.1378, -0.2496, -0.3584, -0.1930, -0.2477,  0.0495, -0.1829, -0.3232,\n",
       "                       -0.1785, -0.0331, -0.1252, -0.0466, -0.5029, -0.2769, -0.2489, -0.2228,\n",
       "                       -0.3491, -0.1808, -0.4641, -0.1219, -0.1713, -0.1978, -0.2854, -0.2561,\n",
       "                       -0.2830, -0.0378, -0.1525, -0.1733, -0.1860, -0.2198, -0.4739, -0.2573,\n",
       "                       -0.1088, -0.0099, -0.0290, -0.3887, -0.2627, -0.1158, -0.1487, -0.3557,\n",
       "                       -0.4001, -0.1713, -0.0566, -0.0610,  0.0042, -0.3352, -0.3545, -0.3416,\n",
       "                       -0.1630, -0.1891, -0.1257, -0.1428, -0.1454, -0.1985, -0.1639, -0.0992,\n",
       "                       -0.0958, -0.4065, -0.3250, -0.1737, -0.1750, -0.4280, -0.1021, -0.0971,\n",
       "                       -0.0646, -0.1558, -0.0291, -0.0479, -0.3025, -0.2969, -0.0629,  0.0238,\n",
       "                       -0.2578, -0.0770, -0.2211, -0.1770, -0.2126, -0.2358, -0.3582, -0.4822,\n",
       "                       -0.0711, -0.1429, -0.1768, -0.1181, -0.0588, -0.0852, -0.3616, -0.2000,\n",
       "                       -0.2832, -0.2100, -0.1765, -0.0865, -0.1462, -0.2346, -0.2432, -0.2874,\n",
       "                       -0.0101, -0.3308, -0.1008, -0.1766, -0.2203, -0.2766, -0.1034, -0.1484,\n",
       "                       -0.1997, -0.1960, -0.2556, -0.3069, -0.2460, -0.1946, -0.1161, -0.0079,\n",
       "                       -0.0775, -0.1790, -0.1027, -0.1611, -0.1736, -0.1379, -0.0277, -0.1865,\n",
       "                       -0.2457, -0.0479, -0.1175, -0.0136, -0.3721, -0.0923,  0.0095, -0.1711,\n",
       "                       -0.1337, -0.4070, -0.2744, -0.1973, -0.2976, -0.1599, -0.0863, -0.1980,\n",
       "                       -0.1753, -0.0619, -0.1353, -0.2578, -0.3652,  0.1567, -0.2340, -0.1349,\n",
       "                       -0.0669, -0.1840, -0.3767, -0.2401, -0.2600, -0.2291, -0.3130, -0.0685,\n",
       "                       -0.2352, -0.2498, -0.1422, -0.0268, -0.1321, -0.2133, -0.1248, -0.1808,\n",
       "                       -0.1851, -0.2634, -0.0681, -0.1343, -0.2837, -0.1378, -0.2258, -0.4131,\n",
       "                       -0.0517, -0.2542, -0.1790, -0.0279, -0.2632, -0.0894, -0.1119, -0.1281,\n",
       "                       -0.0660, -0.3660, -0.3672, -0.0918, -0.2400, -0.3777, -0.2603, -0.1677,\n",
       "                       -0.2175, -0.0742, -0.0274, -0.1188, -0.1798, -0.2052, -0.1311, -0.0811,\n",
       "                       -0.0900, -0.2083, -0.2625, -0.2091, -0.2649, -0.1636, -0.1252, -0.0806,\n",
       "                       -0.2321, -0.3149, -0.2517, -0.4150, -0.2003, -0.1528, -0.1234,  0.0563,\n",
       "                       -0.4636, -0.2561, -0.2408, -0.0281, -0.1682, -0.2385, -0.2427, -0.1907,\n",
       "                       -0.4980, -0.2644, -0.0313, -0.3442, -0.1532, -0.3413, -0.1647, -0.1624,\n",
       "                       -0.0685,  0.0022, -0.3535, -0.3848, -0.1908, -0.2030, -0.0586, -0.1730,\n",
       "                       -0.1191,  0.1343, -0.3901, -0.0337, -0.4172, -0.3257, -0.4829, -0.4563,\n",
       "                       -0.2347, -0.1267, -0.1964, -0.2308, -0.2593,  0.0010, -0.2025, -0.2347,\n",
       "                       -0.1814, -0.2229, -0.0525, -0.0139, -0.2125, -0.1703, -0.1072, -0.1099,\n",
       "                       -0.1688, -0.2037, -0.0141,  0.1000, -0.0477, -0.2683, -0.0935, -0.2040])),\n",
       "              ('w2v_encoder.w2v_model.feature_extractor.conv_layers.4.0.weight',\n",
       "               tensor([[[-0.1004, -0.0351,  0.0211],\n",
       "                        [ 0.0489,  0.0827,  0.0132],\n",
       "                        [ 0.0345,  0.0236,  0.0693],\n",
       "                        ...,\n",
       "                        [ 0.1978,  0.2250,  0.1570],\n",
       "                        [-0.0305,  0.0006,  0.1152],\n",
       "                        [ 0.0019,  0.0152,  0.0238]],\n",
       "               \n",
       "                       [[ 0.0325, -0.0287,  0.0036],\n",
       "                        [-0.0124, -0.0988, -0.0886],\n",
       "                        [ 0.0809,  0.0464, -0.0171],\n",
       "                        ...,\n",
       "                        [-0.1702, -0.1663, -0.1951],\n",
       "                        [ 0.0128,  0.0230,  0.1256],\n",
       "                        [ 0.1206,  0.0435,  0.0388]],\n",
       "               \n",
       "                       [[-0.2361, -0.1329,  0.0732],\n",
       "                        [ 0.1472,  0.1052, -0.0676],\n",
       "                        [-0.0071,  0.0257, -0.0015],\n",
       "                        ...,\n",
       "                        [ 0.0159, -0.1570, -0.1241],\n",
       "                        [-0.1076,  0.2520,  0.2734],\n",
       "                        [-0.0107,  0.0758, -0.0333]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[-0.0388, -0.0779, -0.0083],\n",
       "                        [ 0.0601, -0.0142,  0.0395],\n",
       "                        [ 0.0471,  0.0025,  0.0078],\n",
       "                        ...,\n",
       "                        [ 0.1075,  0.1648,  0.1649],\n",
       "                        [ 0.0759,  0.0310, -0.0224],\n",
       "                        [ 0.0598,  0.0572,  0.0196]],\n",
       "               \n",
       "                       [[ 0.3765,  0.2075, -0.0229],\n",
       "                        [ 0.0255,  0.0480, -0.0071],\n",
       "                        [ 0.0682, -0.0133,  0.0137],\n",
       "                        ...,\n",
       "                        [-0.0865, -0.0545, -0.0222],\n",
       "                        [-0.0186, -0.0195,  0.0796],\n",
       "                        [ 0.0291,  0.0567,  0.0659]],\n",
       "               \n",
       "                       [[ 0.0031,  0.0448,  0.0057],\n",
       "                        [ 0.0096,  0.0044, -0.0131],\n",
       "                        [ 0.0425,  0.0533,  0.0653],\n",
       "                        ...,\n",
       "                        [ 0.0914,  0.0661,  0.0540],\n",
       "                        [-0.0206,  0.0415, -0.0965],\n",
       "                        [ 0.0815,  0.0435,  0.0572]]])),\n",
       "              ('w2v_encoder.w2v_model.feature_extractor.conv_layers.4.2.1.weight',\n",
       "               tensor([0.6685, 0.3379, 1.0420, 0.5537, 0.3142, 0.7100, 0.3706, 0.7500, 0.5640,\n",
       "                       0.6445, 0.4841, 0.8159, 0.6895, 0.5391, 0.3870, 0.4080, 1.0127, 0.6768,\n",
       "                       0.8838, 0.9287, 1.4893, 0.6235, 0.7300, 0.5806, 0.4153, 0.4294, 0.4839,\n",
       "                       0.7769, 0.5420, 0.4319, 0.7632, 0.6616, 0.4382, 0.5034, 0.5732, 0.3213,\n",
       "                       0.5283, 0.4097, 0.6294, 0.6733, 0.5034, 0.4385, 0.5010, 0.6626, 0.5688,\n",
       "                       0.5869, 0.4824, 0.6904, 0.6138, 0.6206, 0.6890, 0.6353, 0.4360, 0.6709,\n",
       "                       0.5249, 0.7456, 0.3667, 0.5513, 0.4065, 0.3640, 0.8687, 0.4873, 0.8394,\n",
       "                       0.6987, 0.7075, 0.4365, 0.7036, 0.4519, 0.3362, 0.5166, 0.4819, 0.5889,\n",
       "                       0.6279, 0.7900, 0.7002, 0.4775, 0.3337, 0.3892, 0.4128, 0.6182, 0.3655,\n",
       "                       0.6646, 0.4919, 0.6025, 0.4705, 0.4192, 0.2898, 0.7153, 1.3438, 0.5796,\n",
       "                       0.6133, 0.7788, 0.5151, 0.4385, 0.5166, 0.6626, 1.3271, 0.4336, 0.7212,\n",
       "                       0.9429, 0.6069, 1.4160, 0.6206, 0.6606, 0.7778, 0.7329, 0.9512, 0.6265,\n",
       "                       0.3406, 0.3169, 0.3005, 0.3254, 0.7998, 0.7988, 0.7456, 0.8560, 0.5552,\n",
       "                       0.3977, 0.6685, 0.5991, 0.6299, 0.6948, 0.6899, 0.4248, 1.1846, 0.3914,\n",
       "                       1.4570, 0.6807, 0.4480, 0.6606, 0.9321, 0.6514, 0.7354, 0.4260, 0.3699,\n",
       "                       0.5820, 0.6494, 0.6631, 0.4360, 0.5723, 0.6294, 0.3440, 0.7109, 0.6494,\n",
       "                       0.7705, 0.4104, 0.3301, 0.4241, 0.3679, 0.4092, 0.4536, 0.6704, 0.6895,\n",
       "                       0.5415, 0.4617, 0.6689, 0.3958, 0.5581, 0.3289, 0.5254, 0.7856, 0.9800,\n",
       "                       0.6367, 0.6250, 0.6802, 0.5425, 1.1934, 0.4238, 0.6436, 1.4463, 0.5483,\n",
       "                       0.6343, 0.9565, 1.3730, 0.3787, 0.7100, 0.7183, 0.4648, 0.6743, 0.3645,\n",
       "                       0.6597, 0.6123, 0.6660, 0.5112, 0.5513, 1.5928, 0.6260, 0.8496, 0.3743,\n",
       "                       0.3916, 1.1553, 0.6914, 0.8135, 0.6201, 1.1309, 0.3540, 0.5171, 0.5942,\n",
       "                       0.6318, 0.6201, 0.7671, 0.5713, 0.6274, 0.6934, 1.0459, 0.7402, 0.6450,\n",
       "                       0.3660, 0.5840, 0.4666, 0.4202, 0.4387, 0.6768, 0.9067, 0.5229, 0.5151,\n",
       "                       0.4233, 0.5181, 0.4595, 0.5244, 0.6567, 0.8496, 0.7578, 0.7510, 0.3835,\n",
       "                       0.6357, 0.5869, 0.6489, 0.9985, 0.4922, 0.5981, 0.4492, 0.6143, 0.3792,\n",
       "                       0.6924, 0.4824, 0.9590, 0.6030, 0.7104, 0.3943, 0.4109, 0.7183, 1.6025,\n",
       "                       0.9097, 0.5171, 0.9204, 0.9609, 0.5791, 0.3267, 0.5244, 0.5483, 0.6489,\n",
       "                       0.5625, 0.3135, 0.5312, 0.5049, 0.6392, 0.5073, 0.3335, 0.7437, 0.5190,\n",
       "                       0.9780, 1.0957, 0.6372, 0.7505, 0.9893, 0.4685, 0.9321, 1.3955, 0.9004,\n",
       "                       1.3252, 0.6450, 0.6968, 0.6104, 1.3584, 0.3472, 0.4380, 0.4338, 0.5371,\n",
       "                       0.5508, 0.4028, 0.6895, 0.8286, 0.5654, 0.8555, 1.0557, 0.9932, 0.4858,\n",
       "                       0.6304, 0.7573, 0.7573, 0.3276, 0.9883, 0.4409, 0.3704, 0.6787, 0.8862,\n",
       "                       0.3848, 0.8037, 0.9053, 0.6299, 0.4094, 0.5493, 0.8110, 0.3730, 0.6626,\n",
       "                       0.8882, 0.4690, 0.9517, 1.0371, 0.3826, 0.5762, 0.5684, 0.3450, 0.6294,\n",
       "                       0.6416, 0.9199, 0.4648, 0.5562, 0.5762, 0.6118, 0.4292, 0.7471, 0.4512,\n",
       "                       0.8062, 0.5176, 1.1846, 0.8779, 0.8125, 1.3145, 0.8428, 0.2976, 0.2991,\n",
       "                       0.5283, 0.3171, 0.5391, 0.9136, 0.8584, 0.9048, 0.7324, 0.4165, 1.1611,\n",
       "                       0.5332, 0.5894, 0.4907, 0.3416, 0.4082, 0.4097, 0.3677, 0.5327, 0.6675,\n",
       "                       1.1523, 0.5942, 0.8032, 0.3782, 0.5532, 0.7109, 0.3677, 0.6152, 0.8511,\n",
       "                       0.4980, 0.5317, 0.6978, 0.6924, 0.5215, 0.4404, 0.5479, 0.4580, 0.7969,\n",
       "                       0.6436, 0.4463, 0.4795, 0.6675, 0.5303, 0.6177, 0.4421, 0.4060, 0.4624,\n",
       "                       0.5156, 0.7197, 0.6982, 0.3979, 0.6567, 0.4731, 0.5825, 0.5454, 0.9658,\n",
       "                       0.7417, 0.4153, 0.5791, 0.5405, 0.4094, 0.4189, 0.6274, 0.4084, 0.3274,\n",
       "                       0.4453, 0.4854, 0.3489, 0.5513, 0.5811, 0.5596, 0.3821, 0.8159, 0.8706,\n",
       "                       0.4717, 0.2717, 0.4333, 0.3025, 0.7852, 0.3884, 0.4202, 0.6123, 0.6753,\n",
       "                       0.5205, 0.4302, 0.6108, 0.4700, 0.8115, 0.7632, 1.0420, 0.5259, 0.6094,\n",
       "                       0.8584, 0.7129, 0.6440, 1.2607, 0.7656, 0.7524, 0.7485, 0.6123, 0.9556,\n",
       "                       0.3599, 0.7764, 0.4624, 0.5186, 0.6670, 0.5278, 0.6558, 0.5439, 0.6357,\n",
       "                       0.4871, 0.7124, 0.6123, 0.4766, 0.5112, 1.0303, 0.5889, 0.4380, 1.0039,\n",
       "                       0.5498, 0.7075, 0.7769, 0.5938, 0.7183, 0.7192, 0.5908, 0.8428, 0.5498,\n",
       "                       0.7754, 0.7153, 0.6055, 0.5562, 0.4243, 0.4482, 0.4753, 0.4490, 0.6504,\n",
       "                       0.5459, 0.8057, 0.9443, 0.5576, 0.6196, 0.7178, 0.7700, 0.3179, 1.3682,\n",
       "                       0.8242, 0.6416, 0.3516, 0.3525, 0.5928, 0.3789, 0.8965, 0.7690, 0.8521,\n",
       "                       0.6450, 0.7241, 0.7275, 1.0107, 0.4753, 0.7305, 0.4316, 0.7681, 0.4033,\n",
       "                       0.2810, 0.9854, 1.0820, 0.9863, 0.9453, 0.5811, 0.4141, 0.8359, 0.6616,\n",
       "                       0.8203, 0.8340, 0.5776, 0.8359, 0.4734, 0.6895, 0.6250, 0.4744])),\n",
       "              ('w2v_encoder.w2v_model.feature_extractor.conv_layers.4.2.1.bias',\n",
       "               tensor([-8.0627e-02, -1.8127e-01, -2.3792e-01, -4.9530e-02,  2.3621e-02,\n",
       "                       -4.1455e-01, -7.6904e-02, -2.0166e-01, -2.1326e-01, -3.2666e-01,\n",
       "                       -1.0284e-01, -2.1362e-01, -1.0645e-01, -3.0493e-01, -1.3013e-01,\n",
       "                       -5.3680e-02, -1.8018e-01,  2.4586e-03, -2.7344e-01, -5.9753e-02,\n",
       "                       -6.1572e-01, -1.8835e-01, -2.7710e-02, -9.7046e-02, -8.2520e-02,\n",
       "                        1.1497e-02,  8.6121e-02, -4.0234e-01, -2.0020e-01, -1.0638e-01,\n",
       "                       -2.4243e-01, -7.5745e-02, -4.7699e-02, -1.0724e-01, -9.7290e-02,\n",
       "                       -1.1017e-01, -1.1633e-01, -8.8135e-02, -1.5515e-01, -3.5248e-02,\n",
       "                       -1.3025e-01, -1.2634e-01, -1.6272e-01, -4.5959e-02,  2.2144e-03,\n",
       "                       -2.0691e-01, -1.1517e-01, -1.7700e-01, -1.9604e-01, -2.3218e-01,\n",
       "                       -5.2917e-02, -6.2927e-02, -8.5022e-02, -3.3105e-01, -2.5122e-01,\n",
       "                       -6.9519e-02, -4.7394e-02, -1.5332e-01,  3.2166e-02,  2.6169e-02,\n",
       "                       -2.0447e-01, -1.4282e-01, -9.8511e-02, -2.4951e-01, -4.9292e-01,\n",
       "                       -8.0261e-02, -1.9568e-01, -6.8237e-02, -1.0254e-01, -1.7346e-01,\n",
       "                       -2.4986e-03, -3.9825e-03, -1.4673e-01, -2.7319e-01, -6.1066e-02,\n",
       "                       -5.7587e-02, -1.0791e-01, -1.8311e-01,  1.5857e-01, -2.9077e-01,\n",
       "                       -2.2388e-01, -2.5293e-01, -1.8201e-01, -3.8635e-02,  8.2275e-02,\n",
       "                       -2.6657e-02, -7.0038e-03, -3.7085e-01, -5.3662e-01, -2.4219e-01,\n",
       "                       -1.4160e-01, -2.0068e-01, -3.9282e-01, -7.5928e-02, -2.1802e-01,\n",
       "                       -3.2935e-01, -7.5195e-01, -1.8140e-01, -5.8929e-02, -1.8921e-01,\n",
       "                       -2.1338e-01, -6.8555e-01,  4.0627e-03, -1.8750e-01, -3.2642e-01,\n",
       "                       -1.6956e-01, -3.5767e-01, -9.5825e-02, -1.4160e-01, -1.1670e-01,\n",
       "                        1.1462e-01, -9.7473e-02, -9.5642e-02, -1.3086e-01, -3.0811e-01,\n",
       "                       -1.4490e-01, -1.0120e-01, -1.4160e-01, -1.8323e-01, -4.7699e-02,\n",
       "                       -1.1432e-01, -1.4221e-01, -2.9858e-01,  9.5581e-02, -3.7769e-01,\n",
       "                       -9.6069e-02, -9.0881e-02, -1.3513e-01,  3.2654e-02,  7.6675e-03,\n",
       "                       -1.1859e-01, -6.1829e-02, -2.3730e-01, -5.3162e-02, -1.9849e-01,\n",
       "                       -1.4685e-01, -2.9126e-01, -1.7029e-01, -1.3977e-01, -3.2593e-02,\n",
       "                       -1.5491e-01,  3.3569e-02, -2.9272e-01, -2.4524e-01, -1.5430e-01,\n",
       "                       -7.1594e-02, -1.6309e-01,  1.2718e-02,  9.6191e-02, -1.9714e-01,\n",
       "                       -1.3208e-01, -7.3792e-02, -1.8628e-01,  1.0693e-01, -4.5166e-02,\n",
       "                       -1.9055e-01, -1.0095e-01, -2.7563e-01,  5.5511e-02,  4.7755e-04,\n",
       "                       -1.2390e-01, -1.8738e-01, -5.5664e-02, -3.3374e-01, -1.5955e-01,\n",
       "                       -3.3112e-02, -5.1221e-01, -4.4037e-02, -1.4026e-01, -9.3323e-02,\n",
       "                       -1.0193e-01, -5.0140e-02, -5.5420e-01, -4.3140e-01, -9.3689e-02,\n",
       "                       -1.5942e-01, -1.5649e-01, -9.2834e-02, -1.8066e-01, -3.6255e-02,\n",
       "                       -2.4011e-01, -2.4146e-01, -5.5328e-02, -1.0736e-01, -2.6685e-01,\n",
       "                       -3.0786e-01, -2.0032e-01, -1.9983e-01, -1.1353e-01, -3.6377e-02,\n",
       "                       -1.2952e-01, -1.6296e-01, -2.0605e-01, -6.9153e-02, -4.3384e-01,\n",
       "                       -8.9722e-02, -1.6614e-01, -2.3926e-01, -2.1765e-01, -6.6956e-02,\n",
       "                       -3.2471e-01, -1.0956e-01, -6.5430e-02, -2.7319e-01, -2.4585e-01,\n",
       "                       -2.2156e-01, -1.0602e-01, -1.4893e-01, -2.0593e-01, -8.1238e-02,\n",
       "                       -1.1743e-01,  2.4063e-02, -1.2256e-01, -2.1118e-01, -1.0382e-01,\n",
       "                       -1.2671e-01, -9.5825e-02, -6.5186e-02,  6.7322e-02,  3.0045e-02,\n",
       "                       -1.8787e-01, -1.6211e-01, -1.7554e-01,  7.2754e-02, -6.9031e-02,\n",
       "                       -2.4512e-01, -2.1271e-02, -2.8125e-01, -8.4595e-02, -1.6077e-01,\n",
       "                       -1.7761e-01, -1.8567e-01, -3.5498e-01, -1.0229e-01, -1.4160e-01,\n",
       "                       -1.6565e-01, -1.3660e-01, -8.8501e-02, -1.5735e-01, -1.5259e-01,\n",
       "                       -1.2927e-01, -1.0498e-01, -2.8174e-01, -1.5259e-01, -1.3696e-01,\n",
       "                       -3.3228e-01, -1.3440e-01, -1.5369e-01,  5.5908e-02, -6.6895e-02,\n",
       "                       -1.2286e-01, -2.0886e-01, -3.2056e-01, -1.4380e-01, -5.8044e-02,\n",
       "                        5.3192e-02, -1.1981e-01, -1.8054e-01, -2.6260e-02, -2.0532e-01,\n",
       "                       -2.7759e-01, -1.5210e-01, -4.3555e-01, -6.8848e-02, -3.0273e-01,\n",
       "                       -2.1289e-01, -1.4008e-02, -3.4839e-01, -5.3516e-01, -7.5073e-02,\n",
       "                       -4.3384e-01, -2.6221e-01, -1.4294e-01, -2.7832e-01, -2.2192e-01,\n",
       "                       -1.0779e-01, -2.3193e-02, -1.6821e-01, -2.0642e-01, -7.7332e-02,\n",
       "                       -8.7708e-02, -1.5039e-01, -3.7158e-01, -1.6443e-01, -2.2778e-01,\n",
       "                       -4.8633e-01, -2.1027e-02, -1.7664e-01, -2.3120e-01, -2.4597e-01,\n",
       "                       -7.7515e-02, -5.9814e-02, -1.3660e-01,  4.3221e-03, -1.7053e-01,\n",
       "                       -1.9836e-01, -2.2205e-01, -5.5420e-02, -2.5537e-01, -8.1970e-02,\n",
       "                       -3.4180e-02,  1.3184e-02, -6.1798e-02, -1.8677e-01,  9.4360e-02,\n",
       "                       -2.5024e-01, -1.7773e-01, -6.0394e-02, -2.4622e-01, -2.5732e-01,\n",
       "                       -2.0065e-02, -1.9861e-01, -7.6111e-02,  3.2684e-02, -1.8616e-01,\n",
       "                       -1.0406e-01, -7.3608e-02, -1.5881e-01, -1.1102e-01, -2.0996e-01,\n",
       "                       -3.4985e-01, -4.1046e-02, -2.8101e-01, -5.0690e-02, -1.3733e-01,\n",
       "                       -2.3468e-02, -2.2339e-01, -2.4365e-01, -1.7139e-01, -1.4319e-01,\n",
       "                       -1.1511e-01, -4.3121e-02, -2.7756e-02, -7.3364e-02, -9.5032e-02,\n",
       "                       -3.8513e-02, -1.6870e-01, -1.1328e-01, -1.2830e-01, -1.0437e-02,\n",
       "                       -1.1269e-02, -1.6052e-01, -1.0907e-01, -9.6924e-02, -1.2256e-01,\n",
       "                       -9.8022e-02, -4.8370e-03, -1.0248e-01, -1.6345e-01, -1.2146e-01,\n",
       "                       -2.3755e-01, -1.0504e-01, -2.5659e-01, -3.6621e-01, -7.7026e-02,\n",
       "                        2.6672e-02, -1.5808e-01, -8.6060e-02, -1.7590e-01, -1.8457e-01,\n",
       "                       -1.0547e-01, -1.3196e-01, -6.3416e-02, -1.4697e-01, -1.5625e-01,\n",
       "                       -1.2781e-01, -2.0056e-01, -3.2520e-03, -2.7051e-01, -2.1082e-01,\n",
       "                       -1.3025e-01, -1.9531e-01, -2.6733e-01, -1.9971e-01, -2.1753e-01,\n",
       "                       -1.3916e-01, -1.8506e-01, -7.6660e-02, -1.2427e-01, -1.6016e-01,\n",
       "                       -1.5955e-01, -2.2900e-01, -1.3696e-01, -7.3730e-02, -4.3121e-02,\n",
       "                       -2.5439e-01, -1.5442e-01, -2.6520e-02, -1.2756e-01, -7.1411e-02,\n",
       "                       -1.0168e-01,  4.9652e-02, -1.3477e-01, -2.7930e-01, -1.0333e-01,\n",
       "                        2.2095e-02, -4.3793e-02,  8.4961e-02, -1.0999e-01, -3.6682e-02,\n",
       "                       -1.9556e-01, -2.8833e-01, -4.8889e-02, -3.1030e-01, -2.3962e-01,\n",
       "                       -8.4229e-02,  3.9886e-02, -7.6660e-02,  5.5206e-02, -2.8662e-01,\n",
       "                       -4.8035e-02, -6.4575e-02,  6.6284e-02, -1.2952e-01, -2.0544e-01,\n",
       "                       -6.3538e-02, -1.0315e-01, -8.0322e-02, -1.3147e-01, -1.9043e-01,\n",
       "                       -2.5757e-01, -7.4890e-02, -3.5181e-01, -9.7595e-02, -2.9590e-01,\n",
       "                       -2.4902e-01, -3.8135e-01, -2.2705e-01, -2.3669e-01, -8.5144e-02,\n",
       "                       -2.0044e-01, -1.7212e-01, -2.1912e-01, -1.3367e-01,  1.3107e-02,\n",
       "                       -1.5320e-01, -1.7712e-01, -6.8298e-02, -1.8689e-01, -2.0593e-01,\n",
       "                       -7.8918e-02, -2.2290e-01, -2.4524e-01, -9.2712e-02, -1.0193e-01,\n",
       "                       -1.1914e-01, -2.2424e-01, -8.6304e-02, -6.5186e-02, -2.7637e-01,\n",
       "                       -2.1594e-01, -2.8247e-01, -4.2334e-01, -1.2952e-01, -2.4182e-01,\n",
       "                       -3.9307e-02, -5.8365e-03, -1.2341e-01, -1.9897e-01, -1.8188e-01,\n",
       "                       -2.7490e-01, -1.0974e-01, -8.7402e-02,  1.2091e-01, -8.4351e-02,\n",
       "                       -1.3940e-01, -2.0752e-01, -2.9956e-01, -3.2886e-01, -3.6108e-01,\n",
       "                       -1.4587e-01, -3.1689e-01, -1.4478e-01, -2.4719e-01, -2.0630e-01,\n",
       "                       -6.6345e-02, -4.0649e-02, -5.2246e-02, -1.1877e-01, -1.3916e-01,\n",
       "                        1.0107e-01, -5.5756e-02, -5.2277e-02, -4.7852e-01, -2.6880e-01,\n",
       "                       -1.6467e-01, -6.7322e-02, -2.0593e-01, -4.7803e-01, -1.4734e-01,\n",
       "                       -2.3792e-01, -1.9348e-01, -1.5358e-02, -1.9446e-01, -5.7068e-02,\n",
       "                       -8.2275e-02, -5.0293e-01, -1.9299e-01, -1.0455e-01, -4.3384e-01,\n",
       "                       -1.2292e-01,  8.2825e-02, -3.3154e-01, -1.6956e-01, -2.4561e-01,\n",
       "                       -3.0396e-01, -2.2009e-01, -3.8110e-01, -8.6731e-02, -3.8818e-01,\n",
       "                       -3.0579e-02, -3.3447e-02])),\n",
       "              ('w2v_encoder.w2v_model.feature_extractor.conv_layers.5.0.weight',\n",
       "               tensor([[[-0.0096, -0.0969],\n",
       "                        [-0.0377, -0.0344],\n",
       "                        [-0.1016, -0.0896],\n",
       "                        ...,\n",
       "                        [ 0.0764,  0.0419],\n",
       "                        [ 0.1608,  0.2451],\n",
       "                        [ 0.1243, -0.0228]],\n",
       "               \n",
       "                       [[ 0.0251,  0.0045],\n",
       "                        [-0.0536,  0.1410],\n",
       "                        [-0.0464, -0.1057],\n",
       "                        ...,\n",
       "                        [-0.0742, -0.3435],\n",
       "                        [ 0.0928,  0.0532],\n",
       "                        [ 0.0627, -0.0372]],\n",
       "               \n",
       "                       [[ 0.0198,  0.1018],\n",
       "                        [-0.1172, -0.0692],\n",
       "                        [ 0.0828, -0.0081],\n",
       "                        ...,\n",
       "                        [-0.0663, -0.1010],\n",
       "                        [-0.0065,  0.0670],\n",
       "                        [-0.1400, -0.1505]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[-0.1559, -0.1089],\n",
       "                        [ 0.1470,  0.2302],\n",
       "                        [-0.0750, -0.1144],\n",
       "                        ...,\n",
       "                        [ 0.1188,  0.0736],\n",
       "                        [-0.0024,  0.0800],\n",
       "                        [ 0.1434,  0.2083]],\n",
       "               \n",
       "                       [[ 0.0553,  0.0742],\n",
       "                        [ 0.0040,  0.0080],\n",
       "                        [-0.0246,  0.0827],\n",
       "                        ...,\n",
       "                        [-0.0213, -0.0050],\n",
       "                        [ 0.0097,  0.1265],\n",
       "                        [-0.0213,  0.0090]],\n",
       "               \n",
       "                       [[-0.2079, -0.3494],\n",
       "                        [-0.0690,  0.0461],\n",
       "                        [-0.0089,  0.0646],\n",
       "                        ...,\n",
       "                        [ 0.0281,  0.0692],\n",
       "                        [ 0.0355,  0.0626],\n",
       "                        [-0.0923, -0.1261]]])),\n",
       "              ('w2v_encoder.w2v_model.feature_extractor.conv_layers.5.2.1.weight',\n",
       "               tensor([0.3484, 0.8423, 1.0410, 0.8633, 0.8589, 0.2532, 0.4797, 0.9473, 0.3196,\n",
       "                       0.6997, 1.1660, 1.0225, 0.3916, 0.3140, 0.3958, 0.2927, 0.6968, 0.5332,\n",
       "                       0.5166, 0.9785, 0.9800, 0.4531, 0.8486, 0.3188, 0.6084, 0.4539, 0.7666,\n",
       "                       0.3535, 0.5068, 0.9839, 0.9346, 0.8379, 0.8862, 0.3467, 0.9468, 0.3513,\n",
       "                       0.4727, 0.3347, 0.4658, 0.3325, 0.3945, 0.6294, 0.4827, 0.3296, 0.2830,\n",
       "                       0.9570, 0.3926, 0.7061, 0.2996, 0.2832, 0.4780, 0.3660, 0.7119, 0.3252,\n",
       "                       0.6992, 0.6963, 0.2563, 0.5078, 0.8950, 0.8340, 0.6992, 0.2871, 0.8145,\n",
       "                       0.4038, 0.8306, 0.7695, 0.2410, 0.6953, 0.7832, 0.8892, 0.2996, 0.6836,\n",
       "                       0.3313, 0.2959, 0.2949, 0.4414, 0.7651, 0.3909, 0.9351, 1.3125, 0.8789,\n",
       "                       0.4995, 0.4495, 1.1279, 0.8887, 0.9839, 1.1162, 0.3101, 0.2878, 0.9561,\n",
       "                       0.3884, 0.5049, 0.3411, 0.8618, 0.3174, 0.7788, 0.7871, 0.2915, 0.4043,\n",
       "                       0.9131, 1.0273, 0.3362, 0.9375, 0.3611, 0.3257, 0.9214, 0.3108, 0.5693,\n",
       "                       0.3022, 0.5537, 0.4270, 0.3103, 0.3516, 0.6172, 0.3115, 0.3574, 0.3865,\n",
       "                       0.5854, 1.2803, 0.2732, 0.5718, 0.5938, 0.9956, 0.4067, 0.7256, 0.8823,\n",
       "                       0.8135, 0.8052, 0.3521, 0.7964, 0.4121, 0.7402, 0.3201, 0.2515, 0.6587,\n",
       "                       0.3584, 0.7778, 0.2590, 0.3015, 0.3508, 0.3491, 0.2993, 0.6147, 0.9692,\n",
       "                       0.9194, 0.3032, 0.4998, 0.9790, 0.9971, 1.4453, 1.0869, 0.7915, 0.2661,\n",
       "                       1.0684, 0.7300, 0.3750, 1.0049, 0.8721, 0.6348, 0.6489, 0.3252, 1.3184,\n",
       "                       0.8633, 0.8833, 0.5688, 1.1416, 0.7036, 0.5518, 0.3750, 0.2949, 0.6709,\n",
       "                       0.2964, 0.3105, 0.3616, 0.4067, 0.3372, 0.4485, 0.6284, 1.0420, 0.7104,\n",
       "                       0.9355, 0.5791, 0.3765, 1.0029, 0.6787, 0.3589, 0.3984, 0.3049, 0.9062,\n",
       "                       0.5771, 0.2922, 0.8926, 0.3655, 0.2676, 0.4329, 0.3250, 0.5249, 0.8960,\n",
       "                       1.0762, 0.3638, 0.9897, 0.3191, 0.3582, 0.7681, 0.4084, 0.8535, 0.3333,\n",
       "                       0.9019, 1.2168, 0.8545, 0.2661, 1.6582, 1.0244, 0.3489, 1.1377, 0.3740,\n",
       "                       0.3540, 0.3040, 0.3604, 0.2771, 0.6611, 0.3567, 0.3435, 1.1377, 0.8789,\n",
       "                       0.3975, 0.6865, 0.3423, 0.2852, 0.4199, 0.3591, 0.3047, 0.6138, 0.2991,\n",
       "                       0.6357, 0.3279, 0.9238, 0.4243, 0.3977, 0.3779, 0.3135, 0.7817, 0.3806,\n",
       "                       0.6914, 0.3362, 0.4563, 0.5835, 0.5923, 0.3564, 0.2377, 0.3523, 0.5283,\n",
       "                       0.2996, 0.4204, 0.3650, 0.7627, 0.3579, 1.3027, 0.9761, 0.7432, 0.4453,\n",
       "                       0.2539, 0.2954, 0.8545, 0.2939, 0.3987, 0.7764, 0.6885, 0.2842, 0.3433,\n",
       "                       0.2830, 0.7935, 0.3345, 0.3359, 0.6318, 0.9941, 0.7871, 0.2812, 0.8364,\n",
       "                       1.0869, 1.1348, 0.7158, 0.2917, 0.7231, 0.2494, 0.9058, 0.6465, 0.2854,\n",
       "                       0.3091, 0.7441, 0.9209, 0.8086, 0.3298, 0.3386, 0.5293, 0.4727, 0.4658,\n",
       "                       1.0439, 1.2998, 0.5566, 0.8721, 0.8682, 0.3057, 0.7666, 0.8696, 0.5435,\n",
       "                       0.8403, 0.5615, 0.3083, 0.3379, 0.4695, 0.3242, 0.9648, 0.7148, 0.3889,\n",
       "                       0.4673, 0.5591, 0.3357, 0.3779, 0.3191, 0.6309, 0.8672, 0.3921, 0.8203,\n",
       "                       0.3130, 0.3430, 0.5371, 1.1768, 0.3315, 0.3604, 0.7021, 0.6733, 0.8857,\n",
       "                       0.3665, 0.2639, 0.9263, 0.3105, 0.8687, 0.5176, 0.3152, 0.8481, 0.9062,\n",
       "                       1.2529, 0.8516, 0.7720, 0.3430, 0.9878, 0.4062, 0.3228, 0.3528, 0.3584,\n",
       "                       0.5269, 0.4004, 0.8623, 0.3853, 1.1270, 0.7881, 0.3081, 1.0332, 0.9844,\n",
       "                       0.3564, 1.0947, 0.3381, 0.3271, 0.3857, 0.4028, 0.3679, 0.3398, 0.9292,\n",
       "                       0.2369, 0.3372, 1.0938, 0.9204, 0.3279, 0.3059, 0.6499, 0.3901, 0.2615,\n",
       "                       0.6226, 0.4377, 0.8594, 0.3262, 1.2412, 0.6299, 0.6045, 0.8735, 0.4309,\n",
       "                       0.4497, 0.4026, 0.3748, 1.0850, 0.2920, 0.3535, 0.2135, 0.6772, 0.8442,\n",
       "                       0.6069, 0.3335, 0.3313, 0.2761, 0.7954, 0.4614, 0.8394, 0.3245, 0.6372,\n",
       "                       0.7051, 0.3376, 0.8267, 0.2847, 1.1270, 0.2944, 0.7368, 0.4817, 0.3625,\n",
       "                       0.7134, 0.3442, 0.7002, 0.5513, 0.3650, 0.9565, 1.0479, 0.3362, 0.8213,\n",
       "                       0.3425, 1.0977, 0.5190, 0.3093, 0.6240, 0.9482, 0.4985, 0.3923, 0.8979,\n",
       "                       0.4092, 0.7681, 0.3013, 0.7305, 0.3137, 0.2681, 0.3140, 0.7217, 0.6729,\n",
       "                       0.2993, 0.2734, 0.3794, 0.6997, 0.3071, 0.2695, 0.4346, 0.2744, 0.3838,\n",
       "                       0.3467, 0.9150, 0.8218, 0.7388, 0.8477, 0.4248, 0.7280, 0.4087, 0.4771,\n",
       "                       0.5474, 0.4109, 1.2832, 0.2556, 1.1709, 0.9043, 0.7554, 0.8120, 0.8564,\n",
       "                       0.3667, 0.7319, 1.1514, 0.3545, 0.5771, 0.4094, 0.2942, 0.7183, 0.8511,\n",
       "                       0.5381, 0.5190, 0.5610, 0.4985, 1.1963, 0.9385, 0.7280, 0.2957, 0.3386,\n",
       "                       0.9116, 0.3477, 0.4114, 0.8369, 0.2830, 0.6123, 0.7627, 0.3103, 0.8672,\n",
       "                       0.4636, 0.7607, 0.6768, 0.8789, 0.2954, 0.3215, 1.1309, 0.7144, 0.4146,\n",
       "                       0.5498, 0.3206, 0.3179, 0.9053, 0.8643, 1.1553, 0.3450, 0.8711])),\n",
       "              ('w2v_encoder.w2v_model.feature_extractor.conv_layers.5.2.1.bias',\n",
       "               tensor([-1.1787e-02, -1.2878e-01, -2.3486e-01, -4.7705e-01, -4.2627e-01,\n",
       "                       -2.8580e-02, -1.9763e-01, -5.9863e-01, -3.7872e-02, -1.7615e-01,\n",
       "                       -3.4766e-01, -4.6216e-01, -7.5439e-02,  5.9418e-02, -4.8431e-02,\n",
       "                       -6.0150e-02, -1.0223e-01, -2.2640e-03, -1.3220e-01, -4.2090e-01,\n",
       "                       -2.8271e-01, -8.3252e-02, -3.6353e-01, -4.0863e-02, -1.1487e-01,\n",
       "                       -5.9235e-02, -8.2397e-02, -1.3748e-02, -9.2590e-02, -4.1333e-01,\n",
       "                       -5.1465e-01, -3.8086e-01, -2.6221e-01, -7.2998e-02, -3.9697e-01,\n",
       "                       -5.0232e-02, -1.1223e-02, -1.0071e-02,  8.9264e-03, -4.1229e-02,\n",
       "                       -3.5980e-02, -9.8953e-03, -2.2510e-01, -1.5884e-02, -6.4636e-02,\n",
       "                       -3.1519e-01, -1.3245e-01, -2.4170e-01, -6.3538e-02, -8.7708e-02,\n",
       "                       -8.4473e-02, -6.5430e-02, -1.8591e-01, -2.8564e-02, -1.6800e-02,\n",
       "                       -1.8555e-01, -1.1246e-02, -1.6394e-01, -4.9023e-01, -6.5918e-01,\n",
       "                        9.5459e-02, -2.5818e-02, -2.7905e-01, -1.2903e-01, -4.6997e-01,\n",
       "                       -1.6296e-01, -1.3550e-02, -1.4343e-01, -1.9800e-01, -3.0054e-01,\n",
       "                       -7.7087e-02, -2.7148e-01, -2.7161e-02, -8.0933e-02, -8.6670e-02,\n",
       "                       -6.5369e-02, -6.1572e-01, -8.2336e-02, -3.9526e-01, -5.1367e-01,\n",
       "                       -4.3970e-01, -2.8149e-01, -2.0337e-01, -1.7383e-01, -3.9819e-01,\n",
       "                       -2.2937e-01, -3.3423e-01, -3.8635e-02, -9.4604e-02, -3.5889e-01,\n",
       "                       -4.7577e-02, -1.3940e-01, -1.1459e-02, -2.2314e-01, -2.9129e-02,\n",
       "                       -2.5659e-01, -7.1045e-02, -7.1960e-02, -1.0187e-01, -5.1270e-01,\n",
       "                       -1.0913e-01, -9.9060e-02, -1.4270e-01, -1.2314e-02, -3.6621e-02,\n",
       "                       -2.5146e-01, -2.3575e-02, -1.6711e-01, -5.5603e-02, -2.3364e-01,\n",
       "                       -9.0881e-02,  3.9551e-02, -1.2805e-01, -2.8052e-01,  1.0480e-01,\n",
       "                       -6.2256e-03, -8.8745e-02, -3.5571e-01, -2.3279e-01, -6.4575e-02,\n",
       "                       -1.1432e-01, -1.7224e-01, -5.0598e-02, -1.0382e-01, -2.7832e-01,\n",
       "                       -2.2375e-01, -1.7859e-01, -2.8833e-01, -1.4624e-01, -1.4978e-01,\n",
       "                        6.2500e-02, -1.8103e-01, -8.4412e-02, -2.3254e-02, -4.0234e-01,\n",
       "                       -3.5767e-02, -2.6440e-01,  7.5912e-03, -7.9834e-02, -2.9831e-02,\n",
       "                       -5.0537e-02, -3.4546e-02, -1.3879e-01, -2.6343e-01, -4.8584e-01,\n",
       "                       -1.0016e-01, -2.6270e-01, -2.9858e-01, -4.0186e-01, -3.2666e-01,\n",
       "                       -3.4961e-01, -4.5239e-01, -4.6265e-02, -1.7590e-01, -4.0308e-01,\n",
       "                        1.5588e-01, -5.3857e-01, -1.8909e-01, -2.1216e-01, -3.8037e-01,\n",
       "                       -6.6406e-02, -2.7441e-01, -3.0273e-01, -2.8662e-01, -6.5857e-02,\n",
       "                       -2.6245e-01, -2.1912e-01,  1.0963e-02, -7.5500e-02, -3.1311e-02,\n",
       "                       -1.2598e-01,  3.5309e-02, -5.3589e-02, -4.0161e-02, -1.0980e-01,\n",
       "                       -1.4905e-01, -1.9263e-01, -2.9028e-01, -2.6538e-01, -2.1863e-01,\n",
       "                       -3.5376e-01, -1.0101e-01, -1.5022e-02, -3.5767e-01, -2.8760e-01,\n",
       "                       -3.2776e-02, -1.5857e-01, -8.8562e-02, -2.6782e-01, -1.6125e-01,\n",
       "                       -5.4169e-02, -4.3164e-01, -3.6774e-02,  8.6670e-03, -4.0710e-02,\n",
       "                        2.4612e-02, -6.1615e-02, -3.0273e-01, -4.6973e-01, -1.0419e-01,\n",
       "                       -2.2498e-01, -6.0608e-02, -5.9692e-02, -3.5400e-01, -9.6130e-02,\n",
       "                       -2.7283e-02, -6.7017e-02, -3.8281e-01, -4.9756e-01, -2.5757e-01,\n",
       "                       -3.4454e-02, -1.0449e+00, -5.9180e-01, -1.4258e-01, -4.7339e-01,\n",
       "                       -4.3915e-02, -2.3636e-02, -5.7220e-02,  2.5711e-02,  9.4666e-02,\n",
       "                       -1.5942e-01,  2.2736e-03, -1.1066e-01, -4.8462e-01, -2.3254e-01,\n",
       "                       -7.3059e-02, -5.1123e-01, -3.6560e-02, -7.4097e-02, -6.0806e-03,\n",
       "                       -4.8248e-02, -6.6719e-03, -2.1057e-01, -4.5319e-02, -5.1331e-02,\n",
       "                       -6.0638e-02, -5.0684e-01, -4.6448e-02, -9.8999e-02, -5.1361e-02,\n",
       "                       -6.8237e-02, -4.8584e-01, -4.1473e-02, -4.4775e-01, -5.2490e-02,\n",
       "                        8.2153e-02, -8.3130e-02, -3.2373e-01, -6.8542e-02, -4.5746e-02,\n",
       "                       -6.9763e-02,  1.5701e-02, -1.4893e-02,  2.1643e-01,  1.5106e-03,\n",
       "                       -4.1968e-01, -6.3782e-02, -2.4890e-01, -4.2407e-01, -2.8735e-01,\n",
       "                       -8.8684e-02,  5.2002e-02, -6.1768e-02, -3.7744e-01, -4.0070e-02,\n",
       "                       -1.3940e-01, -2.6782e-01, -1.1292e-01, -7.5340e-03, -7.5806e-02,\n",
       "                       -2.5223e-02, -3.4277e-01, -1.4015e-02,  9.1370e-02, -2.2705e-01,\n",
       "                       -5.8398e-01, -5.8838e-02, -2.9114e-02, -2.2656e-01, -5.4004e-01,\n",
       "                       -6.0645e-01, -1.5454e-01, -1.4725e-02, -1.1848e-02, -7.3669e-02,\n",
       "                       -6.3965e-01, -2.2815e-01, -9.2285e-02, -3.7689e-02, -2.2546e-01,\n",
       "                       -5.0293e-01, -2.8711e-01, -9.2468e-02, -9.7122e-03, -4.7516e-02,\n",
       "                        7.0679e-02, -2.6733e-01, -6.7773e-01, -7.3438e-01, -6.7078e-02,\n",
       "                       -4.4995e-01, -3.5522e-01, -3.6194e-02, -1.9763e-01, -1.4015e-02,\n",
       "                       -2.2339e-01, -2.8955e-01, -2.3254e-01, -3.1372e-02, -3.5217e-02,\n",
       "                       -1.1768e-01,  9.7473e-02, -2.5879e-01, -2.6538e-01, -1.3025e-01,\n",
       "                       -5.7190e-02, -1.6260e-01, -3.1342e-02,  3.2440e-02, -6.3721e-02,\n",
       "                       -1.9702e-01, -3.2690e-01, -8.9417e-02, -4.0845e-01, -5.9265e-02,\n",
       "                       -2.9388e-02, -1.8494e-01, -1.3794e-01,  7.3814e-04, -1.3672e-01,\n",
       "                       -2.3474e-01, -2.5659e-01, -2.2510e-01,  2.1957e-02, -6.3477e-02,\n",
       "                       -2.8882e-01, -3.4454e-02, -1.9250e-01, -2.4756e-01, -2.7237e-02,\n",
       "                       -4.3140e-01, -3.4790e-01, -4.3018e-01, -4.2090e-01, -1.7834e-01,\n",
       "                        2.9419e-02, -1.2781e-01, -5.1178e-02,  8.9966e-02, -6.8542e-02,\n",
       "                       -2.4399e-02, -1.6016e-01,  5.9784e-02, -4.1968e-01,  4.4159e-02,\n",
       "                       -3.9380e-01, -4.8828e-01, -9.1919e-02, -3.7720e-01, -6.8701e-01,\n",
       "                       -1.0643e-02, -3.8843e-01, -7.5317e-02, -9.7412e-02, -7.6782e-02,\n",
       "                       -6.9092e-02,  4.6051e-02,  4.1412e-02, -1.8127e-01, -2.7832e-02,\n",
       "                       -2.7100e-02, -4.1199e-02, -4.2871e-01, -1.0216e-02, -4.8431e-02,\n",
       "                       -7.4646e-02, -8.0078e-02, -3.1235e-02, -2.2302e-01, -1.4062e-01,\n",
       "                       -1.9580e-01, -6.6833e-02, -2.2327e-01, -1.2494e-01, -2.8662e-01,\n",
       "                       -1.3318e-01, -6.8481e-02, -7.6477e-02, -8.8989e-02, -2.9633e-02,\n",
       "                       -3.0713e-01, -6.0333e-02, -1.2962e-02, -7.7209e-02, -2.7026e-01,\n",
       "                       -2.8149e-01, -1.6321e-01, -4.5700e-03, -5.5389e-02, -9.1675e-02,\n",
       "                       -2.2009e-01, -8.2031e-02, -3.3130e-01, -9.3933e-02, -2.3145e-01,\n",
       "                       -3.5547e-01,  1.1574e-02,  4.9347e-02, -1.0654e+00, -7.0068e-01,\n",
       "                        3.2074e-02, -2.0166e-01, -5.5237e-02, -6.3293e-02, -2.7930e-01,\n",
       "                       -5.2643e-02, -3.5425e-01, -1.7468e-01, -9.3750e-02, -3.0591e-01,\n",
       "                       -4.3164e-01, -6.3293e-02, -1.7041e-01, -3.5248e-02, -3.4058e-01,\n",
       "                       -1.9690e-01, -7.7026e-02, -1.2073e-01, -3.1982e-01, -1.2469e-01,\n",
       "                       -1.6870e-01, -3.4302e-01, -7.1228e-02, -2.8906e-01,  4.0588e-03,\n",
       "                       -6.1279e-01, -8.8745e-02, -5.1041e-03, -1.4511e-02, -4.0259e-01,\n",
       "                       -2.1021e-01,  1.1243e-01,  8.6853e-02, -5.0262e-02, -3.7964e-01,\n",
       "                       -6.2408e-02, -2.1729e-02, -1.3806e-01,  2.6169e-02, -5.1804e-03,\n",
       "                        1.3016e-02, -5.5273e-01, -2.0312e-01, -1.2036e-01, -2.5732e-01,\n",
       "                       -1.7566e-01, -3.4106e-01, -5.2551e-02, -9.0027e-03, -1.3916e-01,\n",
       "                       -7.5195e-02, -7.5732e-01,  8.5876e-02, -1.4526e-01, -2.1008e-01,\n",
       "                       -2.3022e-01, -2.7197e-01, -1.3440e-01, -1.3939e-02, -4.7144e-01,\n",
       "                       -5.3320e-01, -3.8788e-02, -9.2896e-02, -1.7615e-01,  3.7659e-02,\n",
       "                       -1.3293e-01, -2.4292e-01, -1.4026e-01, -1.1432e-01, -2.0276e-01,\n",
       "                       -8.7708e-02, -6.1768e-01, -2.7368e-01, -8.3435e-02,  2.8976e-02,\n",
       "                        3.8208e-02, -2.7563e-01, -7.9590e-02, -7.8186e-02, -2.9248e-01,\n",
       "                       -7.7942e-02, -3.3386e-02, -5.6458e-02, -1.2779e-02, -4.5703e-01,\n",
       "                       -5.9601e-02, -4.0625e-01, -7.9712e-02, -6.5125e-02, -2.9037e-02,\n",
       "                        6.0089e-02, -2.3779e-01,  1.8829e-02, -6.4354e-03, -2.2070e-01,\n",
       "                        2.6073e-03, -6.8604e-02, -2.2522e-01, -2.4255e-01, -6.8750e-01,\n",
       "                       -4.6021e-02, -2.4512e-01])),\n",
       "              ('w2v_encoder.w2v_model.feature_extractor.conv_layers.6.0.weight',\n",
       "               tensor([[[ 0.0046, -0.0846],\n",
       "                        [ 0.0510,  0.0373],\n",
       "                        [-0.1594, -0.0127],\n",
       "                        ...,\n",
       "                        [-0.0850,  0.0166],\n",
       "                        [-0.0491, -0.1611],\n",
       "                        [-0.0257, -0.0617]],\n",
       "               \n",
       "                       [[ 0.1460, -0.0262],\n",
       "                        [-0.0447,  0.0320],\n",
       "                        [-0.0030, -0.0270],\n",
       "                        ...,\n",
       "                        [-0.0432, -0.0553],\n",
       "                        [ 0.1127,  0.1426],\n",
       "                        [-0.0810, -0.0164]],\n",
       "               \n",
       "                       [[-0.1981, -0.0537],\n",
       "                        [-0.1667, -0.1272],\n",
       "                        [-0.1070, -0.0367],\n",
       "                        ...,\n",
       "                        [ 0.0937,  0.0618],\n",
       "                        [ 0.0164,  0.1471],\n",
       "                        [ 0.1349,  0.1316]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[-0.0355,  0.0613],\n",
       "                        [-0.0883, -0.0178],\n",
       "                        [ 0.0912,  0.0468],\n",
       "                        ...,\n",
       "                        [ 0.0343,  0.1247],\n",
       "                        [-0.2168, -0.0793],\n",
       "                        [-0.0075, -0.0367]],\n",
       "               \n",
       "                       [[-1.5225, -1.4883],\n",
       "                        [ 0.7305,  0.7729],\n",
       "                        [ 0.9692,  1.0234],\n",
       "                        ...,\n",
       "                        [ 0.7632,  0.6992],\n",
       "                        [-1.5820, -1.5859],\n",
       "                        [ 0.6846,  0.6631]],\n",
       "               \n",
       "                       [[ 0.1432,  0.1613],\n",
       "                        [-0.0555, -0.0874],\n",
       "                        [ 0.0559,  0.0184],\n",
       "                        ...,\n",
       "                        [-0.0522,  0.0103],\n",
       "                        [-0.0049,  0.0363],\n",
       "                        [ 0.0182,  0.0784]]])),\n",
       "              ('w2v_encoder.w2v_model.feature_extractor.conv_layers.6.2.1.weight',\n",
       "               tensor([0.1603, 0.1864, 0.3816, 0.3186, 0.3135, 0.3545, 0.2568, 0.2671, 0.3982,\n",
       "                       0.3408, 0.3774, 0.3108, 0.3596, 0.2469, 0.3169, 0.3140, 0.2847, 0.3052,\n",
       "                       0.3933, 0.1497, 0.2290, 0.3167, 0.3882, 0.3088, 0.3350, 0.2874, 0.3093,\n",
       "                       0.3240, 0.2269, 0.3647, 0.3105, 0.2861, 0.2820, 0.3621, 0.3228, 0.2671,\n",
       "                       0.3523, 0.2795, 0.1641, 0.1759, 0.2666, 0.3459, 0.3416, 0.4221, 0.1260,\n",
       "                       0.3274, 0.2544, 0.3335, 0.1829, 0.2384, 0.2554, 0.2617, 0.4507, 0.2847,\n",
       "                       0.2480, 0.2610, 0.2189, 0.1854, 0.1908, 0.2478, 0.2866, 0.3652, 0.1935,\n",
       "                       0.3093, 0.2798, 0.1719, 0.4299, 0.1589, 0.1787, 0.3596, 0.1437, 0.1688,\n",
       "                       0.1438, 0.3164, 0.3994, 0.3083, 0.3572, 0.3389, 0.4114, 0.3672, 0.3447,\n",
       "                       0.3005, 0.5947, 0.3677, 0.2290, 0.2147, 0.2908, 0.3008, 0.2871, 0.2491,\n",
       "                       0.3660, 0.2192, 0.3455, 0.1277, 0.5288, 0.1893, 0.3909, 0.2428, 0.2108,\n",
       "                       0.3115, 0.2568, 0.1356, 0.3289, 0.4456, 0.2651, 0.2976, 0.3413, 0.2113,\n",
       "                       0.1825, 0.3145, 0.2959, 0.3154, 0.3596, 0.2532, 0.1953, 0.3623, 0.2751,\n",
       "                       0.2759, 0.3013, 0.3064, 0.2700, 0.3140, 0.3257, 0.3477, 0.3191, 0.1566,\n",
       "                       0.3704, 0.0793, 0.2629, 0.2664, 0.1736, 0.2720, 0.3391, 0.3408, 0.3154,\n",
       "                       0.1991, 0.4009, 0.3179, 0.3481, 0.2959, 0.1754, 0.6299, 0.2257, 0.3516,\n",
       "                       0.2321, 0.3508, 0.3359, 0.2583, 0.2556, 0.1897, 0.2469, 0.4758, 0.3674,\n",
       "                       0.2839, 0.3079, 0.2820, 0.2377, 1.0459, 0.3616, 0.3518, 0.3181, 0.3125,\n",
       "                       0.3044, 0.2357, 0.2578, 0.1575, 0.2981, 0.2725, 0.3298, 0.2263, 0.2896,\n",
       "                       0.2864, 0.2313, 0.1816, 0.2637, 0.3074, 0.2891, 0.2703, 0.2764, 0.2368,\n",
       "                       0.3113, 0.3823, 0.3606, 0.4358, 0.3247, 0.3367, 0.3291, 0.2125, 0.2927,\n",
       "                       0.1648, 0.3137, 0.3965, 0.3286, 0.3850, 0.3640, 0.2922, 0.3064, 0.2529,\n",
       "                       0.4062, 0.3530, 0.2769, 0.2634, 0.2646, 0.1940, 0.3289, 0.4243, 0.2500,\n",
       "                       0.3018, 0.4875, 0.1693, 0.3054, 0.3081, 0.3381, 0.2678, 0.3025, 0.3176,\n",
       "                       0.3103, 0.3601, 0.4587, 0.3103, 0.2771, 0.3884, 0.3267, 0.2876, 0.3020,\n",
       "                       0.2566, 0.3328, 0.3052, 0.2786, 0.2932, 0.3005, 0.2102, 0.3389, 0.5215,\n",
       "                       0.3186, 0.2603, 0.3208, 0.3047, 0.2764, 0.1926, 0.3662, 0.2200, 0.3044,\n",
       "                       0.1808, 0.2710, 0.3838, 0.3401, 0.1913, 0.2783, 0.2878, 0.3474, 0.3555,\n",
       "                       0.2227, 0.3081, 0.3269, 0.2473, 0.2421, 0.3726, 0.1766, 0.3479, 0.2324,\n",
       "                       0.3264, 0.3118, 0.3477, 0.3386, 0.2413, 0.3359, 0.3171, 0.2480, 0.1577,\n",
       "                       0.2363, 0.3472, 0.3196, 0.3167, 0.2915, 0.3271, 0.4082, 0.2710, 0.2971,\n",
       "                       0.2754, 0.2600, 0.1346, 0.4939, 0.3521, 0.3582, 0.2820, 0.2742, 0.3333,\n",
       "                       0.2961, 0.1542, 0.3308, 0.2654, 0.3147, 0.3142, 0.2798, 0.3372, 0.3418,\n",
       "                       0.3296, 0.3450, 0.3301, 0.4380, 0.2812, 0.2993, 0.1852, 0.3257, 0.2732,\n",
       "                       0.3152, 0.2681, 0.3894, 0.2355, 0.3469, 0.2219, 0.3164, 0.1490, 0.1913,\n",
       "                       0.5254, 0.3545, 0.2781, 0.2966, 0.3821, 0.3538, 0.3818, 0.2573, 0.1840,\n",
       "                       0.2472, 0.3274, 0.3220, 0.3252, 0.2634, 0.3142, 0.4561, 0.3174, 0.6729,\n",
       "                       0.2671, 0.2817, 0.2729, 0.3596, 0.1572, 0.1237, 0.3860, 0.2966, 0.1669,\n",
       "                       0.3286, 0.3008, 0.3933, 0.3657, 0.3899, 0.3533, 0.2998, 0.4158, 0.1857,\n",
       "                       0.2954, 0.2566, 0.3440, 0.1686, 0.3247, 0.6069, 0.2325, 0.2700, 0.3242,\n",
       "                       0.2151, 0.3047, 0.2952, 0.1946, 0.1599, 0.2661, 0.1073, 0.1742, 0.3647,\n",
       "                       0.2451, 0.3740, 0.4050, 0.2961, 0.3389, 0.3347, 0.2299, 0.3254, 0.3132,\n",
       "                       0.2820, 0.2249, 0.2893, 0.3037, 0.3245, 0.2910, 0.3425, 0.2871, 0.2930,\n",
       "                       0.1572, 0.1758, 0.3057, 0.3083, 0.2942, 0.3157, 0.2957, 0.2886, 0.3259,\n",
       "                       0.4087, 0.2499, 0.2761, 0.3408, 0.2112, 0.2213, 0.3435, 0.4280, 0.2937,\n",
       "                       0.2644, 0.3328, 0.3303, 0.5542, 0.2759, 0.2661, 0.3147, 0.2172, 0.2416,\n",
       "                       0.2155, 0.2297, 0.5322, 0.3445, 0.2703, 0.3035, 0.3608, 0.1747, 0.2827,\n",
       "                       0.3203, 0.8447, 0.3062, 0.1752, 0.4727, 0.3318, 0.2551, 0.3091, 0.3223,\n",
       "                       0.3755, 0.4131, 0.3442, 0.1785, 0.2917, 0.3223, 0.2854, 0.3745, 0.3323,\n",
       "                       0.3684, 0.5107, 0.3320, 0.3848, 0.2510, 0.2795, 0.4231, 0.3206, 0.3066,\n",
       "                       0.6475, 0.3267, 0.1707, 0.2715, 0.3625, 0.3342, 0.2097, 0.3049, 0.3091,\n",
       "                       0.2524, 0.2404, 0.3167, 0.3232, 0.3154, 0.2354, 0.4033, 0.3340, 0.2676,\n",
       "                       0.3286, 0.2783, 0.2749, 0.4368, 0.2416, 0.2839, 0.3345, 0.2151, 0.3103,\n",
       "                       0.3447, 0.1693, 0.4243, 0.3818, 0.2354, 0.2942, 0.2063, 0.3093, 0.3606,\n",
       "                       0.3027, 0.4426, 0.3308, 0.3206, 0.2830, 0.3030, 0.1929, 0.1421, 0.2517,\n",
       "                       0.3181, 0.4038, 0.2498, 0.3291, 0.2020, 0.1242, 0.4246, 0.3398, 0.3450,\n",
       "                       0.2169, 0.3147, 0.3779, 0.2837, 0.2839, 0.2520, 0.5435, 0.2588])),\n",
       "              ('w2v_encoder.w2v_model.feature_extractor.conv_layers.6.2.1.bias',\n",
       "               tensor([-0.0262, -0.0191, -0.0298, -0.0222, -0.0270, -0.0242, -0.0254, -0.0250,\n",
       "                       -0.0338, -0.0339, -0.0244, -0.0304, -0.0348, -0.0316, -0.0289, -0.0277,\n",
       "                       -0.0394, -0.0279, -0.0293, -0.0164, -0.0190, -0.0239, -0.0297, -0.0287,\n",
       "                       -0.0273, -0.0293, -0.0285, -0.0331, -0.0266, -0.0276, -0.0276, -0.0349,\n",
       "                       -0.0163, -0.0290, -0.0225, -0.0297, -0.0324, -0.0286, -0.0208, -0.0194,\n",
       "                       -0.0338, -0.0308, -0.0305, -0.0302, -0.0219, -0.0301, -0.0265, -0.0245,\n",
       "                       -0.0160, -0.0197, -0.0308, -0.0356, -0.0347, -0.0244, -0.0212, -0.0294,\n",
       "                       -0.0281, -0.0206, -0.0261, -0.0320, -0.0298, -0.0261, -0.0182, -0.0222,\n",
       "                       -0.0237, -0.0177, -0.0329, -0.0246, -0.0168, -0.0261, -0.0253, -0.0204,\n",
       "                       -0.0189, -0.0273, -0.0370, -0.0319, -0.0321, -0.0212, -0.0067, -0.0353,\n",
       "                       -0.0327, -0.0304, -0.0426, -0.0281, -0.0227, -0.0298, -0.0308, -0.0238,\n",
       "                       -0.0256, -0.0192, -0.0308, -0.0249, -0.0305, -0.0218, -0.0339, -0.0221,\n",
       "                       -0.0293, -0.0232, -0.0177, -0.0221, -0.0198, -0.0158, -0.0228, -0.0319,\n",
       "                       -0.0320, -0.0366, -0.0264, -0.0241, -0.0245, -0.0281, -0.0309, -0.0300,\n",
       "                       -0.0302, -0.0287, -0.0264, -0.0341, -0.0227, -0.0246, -0.0308, -0.0257,\n",
       "                       -0.0243, -0.0311, -0.0276, -0.0321, -0.0246, -0.0191, -0.0279, -0.0218,\n",
       "                       -0.0238, -0.0217, -0.0173, -0.0282, -0.0322, -0.0277, -0.0214, -0.0279,\n",
       "                       -0.0426, -0.0269, -0.0321, -0.0262, -0.0226, -0.0313, -0.0184, -0.0248,\n",
       "                       -0.0235, -0.0230, -0.0304, -0.0198, -0.0210, -0.0215, -0.0295, -0.0341,\n",
       "                       -0.0338, -0.0231, -0.0239, -0.0264, -0.0164, -0.0384, -0.0265, -0.0335,\n",
       "                       -0.0234, -0.0277, -0.0208, -0.0349, -0.0323, -0.0144, -0.0261, -0.0291,\n",
       "                       -0.0206, -0.0255, -0.0249, -0.0163, -0.0182, -0.0146, -0.0266, -0.0257,\n",
       "                       -0.0288, -0.0249, -0.0319, -0.0367, -0.0266, -0.0342, -0.0297, -0.0312,\n",
       "                       -0.0281, -0.0321, -0.0300, -0.0317, -0.0244, -0.0249, -0.0240, -0.0330,\n",
       "                       -0.0287, -0.0224, -0.0295, -0.0323, -0.0317, -0.0287, -0.0332, -0.0380,\n",
       "                       -0.0320, -0.0225, -0.0297, -0.0169, -0.0270, -0.0249, -0.0228, -0.0299,\n",
       "                       -0.0395, -0.0260, -0.0202, -0.0213, -0.0304, -0.0346, -0.0252, -0.0263,\n",
       "                       -0.0261, -0.0316, -0.0136, -0.0313, -0.0303, -0.0385, -0.0334, -0.0234,\n",
       "                       -0.0251, -0.0276, -0.0269, -0.0296, -0.0262, -0.0260, -0.0242, -0.0282,\n",
       "                       -0.0327, -0.0395, -0.0243, -0.0283, -0.0255, -0.0265, -0.0413, -0.0203,\n",
       "                       -0.0318, -0.0211, -0.0264, -0.0184, -0.0266, -0.0348, -0.0336, -0.0174,\n",
       "                       -0.0302, -0.0221, -0.0292, -0.0238, -0.0199, -0.0366, -0.0270, -0.0238,\n",
       "                       -0.0272, -0.0293, -0.0137, -0.0242, -0.0296, -0.0261, -0.0216, -0.0334,\n",
       "                       -0.0284, -0.0300, -0.0253, -0.0194, -0.0236, -0.0166, -0.0204, -0.0264,\n",
       "                       -0.0246, -0.0348, -0.0235, -0.0338, -0.0231, -0.0318, -0.0357, -0.0358,\n",
       "                       -0.0222, -0.0264, -0.0308, -0.0335, -0.0262, -0.0330, -0.0247, -0.0205,\n",
       "                       -0.0310, -0.0190, -0.0289, -0.0244, -0.0296, -0.0276, -0.0219, -0.0362,\n",
       "                       -0.0234, -0.0356, -0.0414, -0.0253, -0.0323, -0.0329, -0.0320, -0.0254,\n",
       "                       -0.0306, -0.0294, -0.0258, -0.0212, -0.0267, -0.0215, -0.0297, -0.0354,\n",
       "                       -0.0302, -0.0134, -0.0224, -0.0375, -0.0287, -0.0333, -0.0281, -0.0310,\n",
       "                       -0.0270, -0.0306, -0.0209, -0.0201, -0.0252, -0.0297, -0.0320, -0.0279,\n",
       "                       -0.0260, -0.0263, -0.0361, -0.0184, -0.3752, -0.0364, -0.0258, -0.0209,\n",
       "                       -0.0318, -0.0179, -0.0160, -0.0304, -0.0331, -0.0214, -0.0313, -0.0279,\n",
       "                       -0.0276, -0.0360, -0.0337, -0.0226, -0.0187, -0.0274, -0.0258, -0.0286,\n",
       "                       -0.0271, -0.0334, -0.0137, -0.0269, -0.0444, -0.0233, -0.0295, -0.0322,\n",
       "                       -0.0322, -0.0251, -0.0271, -0.0262, -0.0168, -0.0273, -0.0180, -0.0188,\n",
       "                       -0.0320, -0.0237, -0.0270, -0.0280, -0.0338, -0.0322, -0.0321, -0.0388,\n",
       "                       -0.0338, -0.0201, -0.0315, -0.0291, -0.0207, -0.0312, -0.0275, -0.0303,\n",
       "                       -0.0239, -0.0309, -0.0182, -0.0165, -0.0191, -0.0287, -0.0277, -0.0249,\n",
       "                       -0.0267, -0.0190, -0.0163, -0.0272, -0.0373, -0.0272, -0.0253, -0.0300,\n",
       "                       -0.0251, -0.0242, -0.0298, -0.0318, -0.0337, -0.0260, -0.0280, -0.0258,\n",
       "                       -0.0412, -0.0260, -0.0286, -0.0325, -0.0219, -0.0301, -0.0289, -0.0224,\n",
       "                       -0.0315, -0.0268, -0.0309, -0.0286, -0.0308, -0.0162, -0.0240, -0.0268,\n",
       "                       -0.0392, -0.0217, -0.0176, -0.0348, -0.0306, -0.0275, -0.0239, -0.0256,\n",
       "                       -0.0283, -0.0305, -0.0326, -0.0240, -0.0228, -0.0249, -0.0349, -0.0245,\n",
       "                       -0.0225, -0.0268, -0.0273, -0.0293, -0.0373, -0.0228, -0.0288, -0.0310,\n",
       "                       -0.0284, -0.0241, -0.0353, -0.0274, -0.0158, -0.0245, -0.0285, -0.0260,\n",
       "                       -0.0234, -0.0199, -0.0249, -0.0232, -0.0270, -0.0272, -0.0276, -0.0303,\n",
       "                       -0.0298, -0.0360, -0.0312, -0.0177, -0.0256, -0.0246, -0.0318, -0.0304,\n",
       "                       -0.0275, -0.0277, -0.0309, -0.0228, -0.0291, -0.0267, -0.0196, -0.0258,\n",
       "                       -0.0304, -0.0244, -0.0221, -0.0292, -0.0278, -0.0342, -0.0226, -0.0271,\n",
       "                       -0.0350, -0.0340, -0.0259, -0.0211, -0.0246, -0.0238, -0.0275, -0.0324,\n",
       "                       -0.0285, -0.0214, -0.0254, -0.0157, -0.0183, -0.0237, -0.0351, -0.0259,\n",
       "                       -0.0283, -0.0269, -0.0316, -0.0255, -0.0245, -0.0243, -0.0210, -0.0266])),\n",
       "              ('w2v_encoder.w2v_model.post_extract_proj.weight',\n",
       "               tensor([[-0.0307, -0.1118,  0.0495,  ...,  0.0864,  0.1255,  0.0156],\n",
       "                       [ 0.2732,  0.1403,  0.0701,  ...,  0.1198,  0.4885,  0.0574],\n",
       "                       [ 0.0773, -0.1164,  0.0786,  ..., -0.1726,  0.1735,  0.1520],\n",
       "                       ...,\n",
       "                       [-0.0964,  0.0165,  0.0254,  ...,  0.0016, -0.0087, -0.1029],\n",
       "                       [-0.0172,  0.0555, -0.0200,  ...,  0.0454, -0.1133, -0.0051],\n",
       "                       [ 0.0962, -0.0024, -0.0043,  ..., -0.0201, -0.1400, -0.0917]])),\n",
       "              ('w2v_encoder.w2v_model.post_extract_proj.bias',\n",
       "               tensor([-0.0797, -0.0369, -0.0734,  ...,  0.0170, -0.1337, -0.0107])),\n",
       "              ('w2v_encoder.w2v_model.quantizer.vars',\n",
       "               tensor([[[ 0.1641,  0.2979,  0.0615,  ...,  0.0994,  0.1385,  0.1388],\n",
       "                        [ 0.2010,  0.3069,  0.1249,  ...,  0.0302,  0.3064,  0.1835],\n",
       "                        [ 0.1403,  0.1205,  0.1724,  ...,  0.0964,  0.0093,  0.2852],\n",
       "                        ...,\n",
       "                        [ 0.0699,  0.1635,  0.2871,  ...,  0.1396,  0.1504,  0.2159],\n",
       "                        [ 0.1302,  0.2551,  0.1774,  ...,  0.1193,  0.1941,  0.0537],\n",
       "                        [ 0.1096,  0.1334, -0.0041,  ...,  0.0982,  0.2290,  0.0790]]])),\n",
       "              ('w2v_encoder.w2v_model.quantizer.weight_proj.weight',\n",
       "               tensor([[-0.2021,  0.2168,  0.0807,  ..., -0.4253,  0.2512, -0.4126],\n",
       "                       [ 0.6040,  0.2432, -0.0182,  ..., -0.1279, -0.2527,  0.0199],\n",
       "                       [-0.4128,  0.0909,  0.1104,  ...,  0.2043, -0.7690, -0.1097],\n",
       "                       ...,\n",
       "                       [ 0.4214, -0.3589, -0.5981,  ..., -0.3850, -0.1897, -0.0655],\n",
       "                       [ 0.1042, -0.1034,  0.1790,  ..., -0.5464, -0.0978,  0.2406],\n",
       "                       [-0.1819,  0.0931,  0.6016,  ...,  0.4236, -0.2944,  0.3542]])),\n",
       "              ('w2v_encoder.w2v_model.quantizer.weight_proj.bias',\n",
       "               tensor([-0.3750, -0.3411, -0.2114, -0.2051, -0.3296,  0.0877, -0.3552, -0.3635,\n",
       "                       -0.3604, -0.3066, -0.2458,  0.1236, -0.2457, -0.2864, -0.3467, -0.3052,\n",
       "                       -0.2439, -0.2227,  0.1182, -0.3201, -0.2693, -0.3481, -0.2891,  0.0212,\n",
       "                       -0.2981, -0.2327, -0.1931, -0.3281, -0.1805, -0.2150, -0.2598, -0.2147,\n",
       "                        0.0022, -0.3518, -0.1993, -0.2494, -0.2395, -0.2231, -0.1974, -0.1787,\n",
       "                       -0.2505, -0.3164, -0.2910, -0.2834, -0.2256,  0.3398, -0.3547,  0.0798,\n",
       "                       -0.2549, -0.1034, -0.2112, -0.3022, -0.1838, -0.2473,  0.0626,  0.2312,\n",
       "                       -0.2656,  0.2057, -0.2163, -0.2190, -0.3210,  0.0880, -0.2529, -0.2411,\n",
       "                       -0.2307, -0.2900, -0.2712, -0.3220, -0.1981, -0.1703, -0.2607, -0.3760,\n",
       "                        0.2769,  0.0500, -0.2161, -0.2483, -0.2032, -0.1093,  0.1847, -0.2140,\n",
       "                       -0.2478, -0.2957, -0.1331, -0.3047, -0.0964,  0.0823, -0.2993, -0.2115,\n",
       "                       -0.2225, -0.2542, -0.2108, -0.2786, -0.2583,  0.1276, -0.2690, -0.3076,\n",
       "                       -0.2649, -0.1210, -0.2483, -0.2930, -0.2695, -0.1753, -0.3572, -0.3276,\n",
       "                       -0.2010, -0.1406, -0.1949, -0.2234, -0.2920, -0.2517,  0.0058, -0.2756,\n",
       "                       -0.8545, -0.2778, -0.3477, -0.3215, -0.3420, -0.2488, -0.6611, -0.1835,\n",
       "                       -0.2798, -0.1982, -0.3560, -0.2168, -0.3472, -0.0829,  0.1638, -0.2365,\n",
       "                        0.2593,  0.4155, -0.2681, -0.1965, -0.2235, -0.3362, -0.3254, -0.2086,\n",
       "                       -0.2808,  0.0788,  0.3525,  0.2266, -0.2971, -0.3364, -0.1287, -0.2571,\n",
       "                       -0.2593, -0.2015, -0.1920,  0.1240, -0.0959,  0.4182, -0.0557, -0.2607,\n",
       "                       -0.4355, -0.1180, -0.1969, -0.2085, -0.2107, -0.2426, -0.2340, -0.4268,\n",
       "                       -0.2405, -0.3630, -0.2323, -0.2620, -0.2264, -0.3667, -0.2333, -0.3040,\n",
       "                       -0.2891, -0.2113, -0.2622, -0.2598, -0.1790, -0.2534,  0.1098, -0.2260,\n",
       "                       -0.2898, -0.2172, -0.1677, -0.4285, -0.1930, -0.2188, -0.2744, -0.1663,\n",
       "                       -0.2502, -0.3074, -0.2260,  0.2976, -0.2686, -0.2013, -0.3098, -0.2510,\n",
       "                       -0.2391, -0.1981, -0.2401, -0.2461, -0.2034, -0.2128, -0.1976, -0.2455,\n",
       "                       -0.3342, -0.3096, -0.2345, -0.3416, -0.3582,  0.1389, -0.3037, -0.2122,\n",
       "                       -0.3767, -0.2900,  0.1655, -0.2174, -0.2430,  0.1447, -0.0984, -0.2131,\n",
       "                       -0.3657, -0.2925,  0.0721, -0.2952, -0.2834, -0.1760,  0.2242, -0.2317,\n",
       "                       -0.2981, -0.2629, -0.1970, -0.2336, -0.2527, -0.2507, -0.2087, -0.2844,\n",
       "                       -0.1724, -0.2158, -0.2413, -0.2321, -0.3911, -0.2805,  0.1521, -0.1785,\n",
       "                        0.3682,  0.0967,  0.1823, -0.1742, -0.2527, -0.1732,  0.0568, -0.2561,\n",
       "                       -0.2678, -0.3127,  0.0694, -0.2710, -0.2264, -0.3621, -0.0105, -0.2952,\n",
       "                        0.3271, -0.1824,  0.0881, -0.3152, -0.3853, -0.2644, -0.4744, -0.2556,\n",
       "                       -0.1621, -0.2479, -0.2778,  0.3301,  0.2939, -0.1357,  0.3735, -0.3188,\n",
       "                       -0.0279, -0.2087, -0.2903, -0.2209, -0.2275, -0.2903,  0.0563, -0.0125,\n",
       "                       -0.3157, -0.2050,  0.0521, -0.1926,  0.1270,  0.2454,  0.1733, -0.3008,\n",
       "                       -0.0131, -0.2539, -0.2937,  0.1190, -0.3086, -0.2825, -0.3064, -0.1610,\n",
       "                       -0.3120, -0.2876, -0.3665, -0.3665,  0.2690, -0.3464, -0.2280,  0.2842,\n",
       "                       -0.2189, -0.2788, -0.2435, -0.2374, -0.2096, -0.2788, -0.3420, -0.2571,\n",
       "                       -0.3237,  0.1708, -0.2358, -0.2656, -0.1903, -0.2678, -0.1836, -0.2534,\n",
       "                       -0.2477, -0.2561, -0.5259, -0.3757, -0.3315, -0.4392, -0.3770, -0.3403,\n",
       "                       -0.3655, -0.3323, -0.3904, -0.3804, -0.3274, -0.3196, -0.3674, -0.0178,\n",
       "                       -0.3357, -0.2815, -0.4468, -0.1053,  0.0109, -0.4500, -0.0545, -0.3176,\n",
       "                       -0.3833, -0.4321, -0.3594, -0.2705, -0.3601, -0.3652, -0.2717,  0.0662,\n",
       "                       -0.2749, -0.2832,  0.1677,  0.0282, -0.3818, -0.0334, -0.3250, -0.3508,\n",
       "                       -0.4148, -0.2812, -0.4387, -0.2433, -0.3909, -0.3423, -0.3345, -0.4507,\n",
       "                       -0.3718, -0.4329, -0.1576, -0.2561, -0.3440, -0.3630, -0.3652, -0.4119,\n",
       "                       -0.5278, -0.2942, -0.2661, -0.0312, -0.3845, -0.2759, -0.3616, -0.3970,\n",
       "                       -0.2091,  0.0872, -0.4668, -0.3474, -0.3484, -0.4045, -0.4580, -0.4248,\n",
       "                        0.3167,  0.2184, -0.3572, -0.3953,  0.1445, -0.3584,  0.3782, -0.3398,\n",
       "                       -0.3237, -0.3557, -0.4275, -0.3164, -0.2693, -0.2126, -0.2656,  0.0066,\n",
       "                       -0.3657, -0.4604, -0.3616,  0.4055, -0.3667, -0.3589, -0.3513, -0.3833,\n",
       "                       -0.3503, -0.2607, -0.3433, -0.4272, -0.3403, -0.9229, -0.3779, -0.3320,\n",
       "                       -0.3535, -0.3533,  0.2444, -0.3240, -0.3857, -0.3779, -0.3198, -0.4819,\n",
       "                       -0.3933, -0.3750, -0.3433, -0.5649, -0.3696, -0.3022, -0.1309, -0.2512,\n",
       "                       -0.3662, -0.3987, -0.3081, -0.3171, -0.2805, -0.3027, -0.4175, -0.2588,\n",
       "                       -0.2220, -0.4585, -0.3792, -0.4812, -0.3782, -0.0401, -0.3677, -0.3008,\n",
       "                       -0.2964, -0.4373, -0.3936, -0.4849, -0.4065, -0.3350,  0.0951, -0.3623,\n",
       "                       -0.4363, -0.2949, -0.3054, -0.4600, -0.2242, -0.4009, -0.3298, -0.3599,\n",
       "                       -0.4070,  0.3447, -0.3521,  0.2590, -0.1096, -0.3450, -0.2722, -0.2896,\n",
       "                       -0.2177, -0.2001, -0.2462, -0.4065, -0.3511, -0.3069, -0.3406, -0.0681,\n",
       "                       -0.2649, -0.2307, -0.3486, -0.2993, -0.3687,  0.0349, -0.4041, -0.4189,\n",
       "                       -0.3147, -0.3606, -0.2820,  0.3989, -0.2515, -0.3225, -0.3416, -0.3413,\n",
       "                        0.0043, -0.3025, -0.3293,  0.0645, -0.2113, -0.3015, -0.4214, -0.0404,\n",
       "                       -0.4419,  0.2148,  0.0706, -0.2844, -0.4119, -0.3862, -0.3867, -0.4417,\n",
       "                       -0.3987, -0.1299, -0.4226, -0.4185, -0.0488, -0.2512, -0.3474, -0.2467,\n",
       "                       -0.2366, -0.2268, -0.4202,  0.1628, -0.4348,  0.2603, -0.2394, -0.3396,\n",
       "                        0.3123, -0.4929, -0.3586, -0.3135, -0.2927, -0.2783, -0.3135, -0.4778,\n",
       "                       -0.4307, -0.3418, -0.4578, -0.3982, -0.4670, -0.3130,  0.0568, -0.4080,\n",
       "                        0.1881, -0.3496, -0.3882, -0.4333, -0.4026, -0.3130, -0.3186, -0.4819,\n",
       "                        0.1722, -0.4487, -0.3782, -0.3215, -0.3745, -0.2871, -0.2654, -0.3325,\n",
       "                       -0.3159, -0.5942, -0.3149, -0.4121, -0.3037,  0.0668, -0.3911, -0.3164,\n",
       "                       -0.3091,  0.1620, -0.2900, -0.3779, -0.3088, -0.4468, -0.4241, -0.3367,\n",
       "                       -0.4272, -0.6602, -0.4604, -0.2427, -0.4651, -0.2014, -0.2974, -0.2129,\n",
       "                       -0.2900, -0.2903,  0.2781,  0.0182,  0.2239, -0.4197, -0.3057,  0.3308,\n",
       "                       -0.3413,  0.0973, -0.0775, -0.3442, -0.4006, -0.4028, -0.2932,  0.1290,\n",
       "                       -0.3916, -0.4329, -0.3428, -0.3552, -0.2815, -0.2686, -0.2932, -0.4099,\n",
       "                       -0.4614,  0.1626, -0.3738, -0.3406, -0.1508, -0.0893, -0.3926, -0.2349,\n",
       "                       -0.4019, -0.2817, -0.3579, -0.4268, -0.3491, -0.3149, -0.3220, -0.3254,\n",
       "                       -0.3408,  0.1758, -0.4187, -0.3630, -0.4419, -0.4309, -0.3872, -0.2649])),\n",
       "              ('w2v_encoder.w2v_model.project_q.weight',\n",
       "               tensor([[ 2.5574e-02, -6.1005e-02, -5.2551e-02,  ..., -3.5645e-02,\n",
       "                        -4.6143e-02,  3.0350e-02],\n",
       "                       [ 6.4209e-02,  7.4219e-02, -2.9907e-02,  ..., -1.2970e-03,\n",
       "                         1.5454e-01,  1.4636e-01],\n",
       "                       [ 3.2318e-02,  1.0852e-01,  1.2903e-01,  ..., -5.5328e-02,\n",
       "                        -7.2754e-02, -6.9885e-02],\n",
       "                       ...,\n",
       "                       [ 8.8745e-02, -1.0651e-02,  8.0566e-02,  ..., -5.9326e-02,\n",
       "                        -5.8380e-02, -2.0111e-02],\n",
       "                       [ 2.4307e-02, -2.4460e-02, -1.4782e-05,  ...,  6.4697e-02,\n",
       "                         7.8812e-03, -4.8492e-02],\n",
       "                       [-1.7914e-02,  2.7908e-02, -6.8359e-02,  ...,  4.2267e-03,\n",
       "                        -5.4962e-02, -5.7861e-02]])),\n",
       "              ('w2v_encoder.w2v_model.project_q.bias',\n",
       "               tensor([ 2.3865e-02,  3.2471e-02, -2.3117e-03,  3.7506e-02, -7.6256e-03,\n",
       "                        1.4801e-02,  1.3275e-02, -3.0727e-03,  3.1281e-02, -1.1642e-02,\n",
       "                       -1.7181e-02,  1.0780e-02, -1.2627e-03,  3.2135e-02,  1.1086e-02,\n",
       "                       -3.2187e-06,  1.5350e-02, -2.5131e-02,  7.6256e-03,  1.4069e-02,\n",
       "                       -6.6376e-03,  5.7030e-03, -2.2717e-03,  1.0025e-02,  1.3725e-02,\n",
       "                       -2.3987e-02,  5.8174e-03, -2.9087e-03,  9.1324e-03,  2.6443e-02,\n",
       "                        2.2324e-02,  2.8286e-03, -2.1286e-02, -1.6632e-02, -7.9956e-03,\n",
       "                        4.1656e-02,  2.5543e-02,  5.7678e-03, -1.9821e-02, -2.4353e-02,\n",
       "                       -9.7580e-03, -6.8932e-03, -2.2064e-02, -1.0490e-02, -4.5586e-04,\n",
       "                        1.9958e-02, -1.9241e-02, -2.2278e-03, -2.6398e-03, -1.2035e-03,\n",
       "                        1.6037e-02, -1.5821e-03, -2.6512e-04, -5.4855e-03,  3.5515e-03,\n",
       "                        3.9291e-03, -1.2527e-02,  1.7975e-02, -7.7438e-03, -1.0979e-02,\n",
       "                       -1.1559e-02, -1.1948e-02,  2.1408e-02,  1.5022e-02,  1.7349e-02,\n",
       "                       -1.2978e-02,  1.7288e-02, -3.0613e-03,  1.2573e-02, -5.2404e-04,\n",
       "                        7.0343e-03, -1.7166e-02,  4.8518e-04,  3.5439e-03, -1.3618e-02,\n",
       "                       -1.8143e-02,  1.4526e-02, -3.3630e-02,  1.9272e-02,  7.0114e-03,\n",
       "                        1.5478e-03,  2.0035e-02,  1.7120e-02, -5.5962e-03,  1.4252e-02,\n",
       "                       -3.2074e-02,  4.3259e-03, -6.1989e-03, -1.0824e-03,  9.9945e-04,\n",
       "                        1.6052e-02,  1.5976e-02, -1.0292e-02,  1.0155e-02, -2.6978e-02,\n",
       "                       -6.3858e-03, -6.4812e-03, -7.8201e-03,  1.6174e-02,  2.2690e-02,\n",
       "                       -1.3977e-02, -1.2459e-02, -2.5162e-02,  1.3870e-02,  1.9852e-02,\n",
       "                        4.7760e-03,  2.9159e-04,  1.8402e-02,  7.5579e-04,  2.4429e-02,\n",
       "                        8.5983e-03,  1.8845e-02,  1.2535e-02,  5.4016e-03,  9.4833e-03,\n",
       "                       -3.7048e-02,  2.5330e-03,  4.7424e-02, -1.1223e-02,  5.1975e-05,\n",
       "                        2.9388e-02,  3.5942e-05,  3.3142e-02,  1.8677e-02,  2.9826e-04,\n",
       "                       -7.0076e-03,  1.4565e-02, -2.8839e-03,  8.0032e-03,  5.2948e-03,\n",
       "                        1.6193e-03,  3.4103e-03,  3.7201e-02, -2.4933e-02,  1.3313e-03,\n",
       "                        1.0269e-02,  3.3936e-02,  5.7106e-03, -1.3107e-02,  2.0111e-02,\n",
       "                       -4.9362e-03,  7.1487e-03,  1.5961e-02, -1.6586e-02, -1.7761e-02,\n",
       "                       -1.2924e-02, -2.5833e-02,  2.2598e-02, -6.7472e-04,  7.0534e-03,\n",
       "                       -1.4267e-03,  9.1982e-04, -1.2405e-02,  9.0179e-03, -1.8524e-02,\n",
       "                       -2.0401e-02,  1.2138e-02, -8.2092e-03, -1.9760e-02,  1.2283e-02,\n",
       "                       -1.7271e-03, -1.2711e-02,  1.5297e-02,  4.8256e-03,  7.3280e-03,\n",
       "                        1.0857e-02, -1.7548e-02, -1.5381e-02, -6.6566e-03, -6.0768e-03,\n",
       "                       -8.2779e-03, -1.8753e-02, -1.0506e-02,  4.3060e-02,  1.3885e-02,\n",
       "                        1.2634e-02, -9.6359e-03, -1.4019e-03, -4.9477e-03, -1.1539e-03,\n",
       "                        4.0527e-02,  5.0240e-03, -5.6953e-03, -8.6212e-03,  2.0477e-02,\n",
       "                        7.7133e-03, -4.6349e-03, -3.7918e-03, -5.0316e-03,  9.0332e-03,\n",
       "                        5.6314e-04, -1.3710e-02,  3.0396e-02,  2.0248e-02,  3.5126e-02,\n",
       "                        5.1270e-03, -5.1193e-03, -1.9135e-02,  1.0063e-02,  7.8354e-03,\n",
       "                       -6.0120e-03,  8.1329e-03,  2.4460e-02,  9.5558e-04, -4.2389e-02,\n",
       "                       -1.9958e-02,  8.5983e-03,  8.3160e-03, -4.7684e-03,  2.5757e-02,\n",
       "                       -7.9956e-03,  8.0338e-03, -4.5204e-03, -9.7885e-03, -8.8348e-03,\n",
       "                       -1.2329e-02,  7.6637e-03, -2.4259e-05,  5.3177e-03, -1.4297e-02,\n",
       "                       -2.8229e-03,  8.3084e-03,  8.3771e-03,  7.1669e-04, -7.2479e-03,\n",
       "                        1.7136e-02, -1.4404e-02,  7.3700e-03, -2.0752e-02, -3.1250e-02,\n",
       "                        1.2085e-02, -2.2217e-02, -1.5480e-02, -1.6584e-03, -2.1027e-02,\n",
       "                       -1.7639e-02,  1.1940e-02,  4.1565e-02, -1.6525e-02,  5.7411e-03,\n",
       "                       -1.0529e-02, -8.0338e-03,  3.1719e-03, -8.8196e-03, -1.3664e-02,\n",
       "                        1.2985e-02, -2.1072e-02, -2.1927e-02, -2.6016e-02,  3.3512e-03,\n",
       "                       -2.6108e-02,  1.9562e-02, -1.6800e-02,  2.2964e-02, -2.0706e-02,\n",
       "                       -1.1734e-02,  2.2400e-02, -6.2294e-03,  7.6141e-03,  2.0935e-02,\n",
       "                        9.4681e-03,  2.8061e-02, -1.5526e-02, -2.1896e-02, -1.1536e-02,\n",
       "                       -2.5253e-02, -2.6306e-02,  4.4250e-03,  6.9618e-03, -1.0185e-02,\n",
       "                       -7.8278e-03,  1.7471e-02,  1.5297e-02, -1.3481e-02, -3.1757e-03,\n",
       "                       -2.8954e-03,  1.5961e-02,  1.1902e-02,  3.7804e-03,  2.2449e-03,\n",
       "                       -1.4091e-02,  1.7395e-02, -2.6627e-03,  7.0524e-04, -8.9264e-03,\n",
       "                        2.4155e-02,  7.8659e-03,  5.6763e-03,  4.2191e-03,  1.0902e-02,\n",
       "                        2.8954e-03,  1.2566e-02,  1.2390e-02,  1.2665e-02, -1.7792e-02,\n",
       "                       -2.2690e-02,  1.2711e-02,  9.7504e-03,  1.5610e-02,  5.9700e-04,\n",
       "                       -2.3438e-02,  1.2589e-02,  4.0802e-02, -2.1973e-03, -2.7603e-02,\n",
       "                       -1.6739e-02,  2.3666e-02, -2.5425e-03,  2.2659e-02,  2.9404e-02,\n",
       "                        1.4297e-02,  5.3520e-03,  1.5656e-02, -1.0185e-03, -1.7670e-02,\n",
       "                       -1.5869e-02,  3.1738e-03,  1.8112e-02,  3.6106e-03, -4.0512e-03,\n",
       "                        1.4412e-02,  7.2136e-03, -2.5330e-02, -8.4763e-03, -3.0994e-03,\n",
       "                       -9.6207e-03,  5.8212e-03,  1.2421e-02,  1.4887e-03, -6.0692e-03,\n",
       "                       -1.0460e-02,  8.0261e-03, -2.2324e-02, -7.7515e-03,  1.2650e-02,\n",
       "                        6.0692e-03, -2.2373e-03, -6.6223e-03, -4.2582e-04,  2.6226e-04,\n",
       "                        9.5825e-03,  7.7934e-03,  6.1760e-03,  1.6159e-02,  1.0269e-02,\n",
       "                       -8.6441e-03, -1.2459e-02, -3.9551e-02,  1.7395e-02,  4.0588e-03,\n",
       "                        8.1711e-03,  1.4648e-02, -6.9351e-03,  1.4030e-02, -9.0256e-03,\n",
       "                        2.4063e-02, -1.2016e-02, -2.8900e-02,  1.2001e-02, -1.2789e-03,\n",
       "                       -7.4615e-03, -6.7520e-03,  1.2199e-02, -2.8030e-02, -2.2018e-02,\n",
       "                       -1.3838e-03,  2.0428e-03, -1.5612e-03,  1.7914e-02,  1.8112e-02,\n",
       "                       -1.2291e-02, -2.2705e-02, -1.7792e-02, -3.7403e-03,  3.8738e-03,\n",
       "                       -4.5815e-03,  1.8167e-03,  5.0735e-04,  1.8509e-02, -1.8799e-02,\n",
       "                       -1.2558e-02, -5.8441e-03,  3.2902e-03,  7.0610e-03, -9.1858e-03,\n",
       "                        1.2642e-02, -1.1162e-02, -6.5651e-03, -4.9133e-03,  2.0187e-02,\n",
       "                        1.2909e-02,  4.1924e-03,  1.7334e-02,  1.4328e-02,  1.1749e-02,\n",
       "                       -2.6560e-04, -1.4259e-02, -9.8038e-03,  5.5046e-03, -2.7485e-03,\n",
       "                       -1.5533e-02, -2.0325e-02,  8.6689e-04, -2.5436e-02,  1.7815e-03,\n",
       "                       -1.4420e-02,  1.4931e-02, -2.6367e-02,  3.1403e-02, -2.0809e-03,\n",
       "                       -1.0509e-03,  1.3802e-02,  8.0566e-03,  3.1113e-02,  2.3865e-02,\n",
       "                       -4.0398e-03,  2.8641e-02, -1.6846e-02,  1.9836e-02,  3.9940e-03,\n",
       "                       -3.3356e-02, -2.9648e-02, -2.5177e-02,  2.0767e-02,  2.6245e-02,\n",
       "                       -2.5497e-02,  1.3885e-02,  1.8417e-02,  2.1133e-03, -2.1881e-02,\n",
       "                       -8.7051e-03,  2.7542e-02, -8.8272e-03, -1.3931e-02, -3.4485e-02,\n",
       "                       -4.8561e-03, -2.8870e-02, -1.3908e-02,  1.0460e-02,  8.2016e-03,\n",
       "                        2.7828e-03, -1.8921e-02,  2.6260e-02, -8.1558e-03, -1.7262e-03,\n",
       "                       -7.2384e-04, -2.2095e-02, -4.6120e-03, -1.0796e-02, -1.0818e-02,\n",
       "                        3.5477e-03, -5.4932e-03, -1.7029e-02, -1.9440e-02, -2.5528e-02,\n",
       "                        9.4910e-03, -3.5736e-02, -1.0811e-02,  1.3565e-02,  1.4763e-02,\n",
       "                        3.4698e-02, -4.0970e-03, -4.9820e-03,  9.9716e-03,  4.3335e-03,\n",
       "                       -1.3065e-03, -5.4016e-03, -8.7585e-03,  8.7204e-03,  2.7084e-02,\n",
       "                        2.1759e-02,  9.0027e-03, -1.3542e-02, -1.6724e-02, -2.6846e-04,\n",
       "                        1.5686e-02,  3.1281e-03,  5.9319e-03, -2.6367e-02, -2.3209e-02,\n",
       "                        2.4231e-02, -1.7948e-03, -2.6443e-02, -6.7329e-03, -1.2199e-02,\n",
       "                       -2.4704e-02,  1.5556e-02, -2.8763e-02, -3.7476e-02,  1.6769e-02,\n",
       "                        3.2768e-03,  1.4381e-02,  8.9264e-03, -1.1997e-03, -5.2719e-03,\n",
       "                       -6.2523e-03, -1.6998e-02,  2.9624e-05, -1.4183e-02, -1.1818e-02,\n",
       "                        8.4305e-03, -5.7077e-04,  9.2621e-03,  2.1194e-02, -2.1683e-02,\n",
       "                       -9.6130e-04, -4.3983e-03,  1.7624e-02,  1.5915e-02, -1.7410e-02,\n",
       "                        5.9509e-04, -3.2520e-04, -5.0262e-02, -2.1378e-02, -1.5783e-03,\n",
       "                       -1.3260e-02,  6.8130e-03, -2.4490e-02,  1.2646e-03, -4.9706e-03,\n",
       "                       -7.4005e-03, -3.4676e-03, -1.1367e-04, -9.1553e-03, -1.5554e-03,\n",
       "                       -1.1993e-02, -2.7191e-02, -3.1647e-02,  9.3460e-03,  6.1560e-04,\n",
       "                       -8.4610e-03, -2.5139e-03, -1.5808e-02, -3.3966e-02, -2.0462e-02,\n",
       "                       -6.8817e-03, -2.5528e-02, -3.8361e-02, -1.4648e-02,  1.7136e-02,\n",
       "                       -1.0414e-03,  3.4088e-02,  2.6489e-02,  7.2594e-03, -2.0485e-03,\n",
       "                        6.7787e-03, -8.1863e-03,  1.1082e-03,  7.9803e-03,  1.8372e-02,\n",
       "                        1.4320e-02,  1.8555e-02,  2.2049e-02, -2.0035e-02, -1.4519e-02,\n",
       "                       -9.8038e-03, -1.1703e-02,  1.1110e-03, -1.9608e-02, -8.4305e-04,\n",
       "                        2.4719e-02,  1.2856e-02,  2.9564e-03, -3.8391e-02, -2.7161e-03,\n",
       "                       -2.5768e-03,  2.1698e-02,  2.7733e-03,  1.3535e-02, -2.0752e-03,\n",
       "                        2.1729e-02, -2.9816e-02, -8.6899e-03, -1.9791e-02,  7.6065e-03,\n",
       "                       -1.8677e-02,  2.4734e-02, -6.7902e-03, -4.4647e-02,  1.8051e-02,\n",
       "                       -3.7842e-03,  6.0844e-03, -1.2856e-02,  7.9651e-03, -5.0125e-03,\n",
       "                       -1.2093e-02, -2.5482e-03, -1.0178e-02,  5.1231e-03,  3.4149e-02,\n",
       "                        1.2711e-02, -2.2217e-02, -2.9251e-02,  3.0914e-02,  3.2715e-02,\n",
       "                       -5.1727e-03,  2.0508e-02,  9.4147e-03, -4.5509e-03,  3.5583e-02,\n",
       "                       -6.4507e-03, -1.0048e-02,  8.9951e-03,  2.0020e-02,  7.8125e-03,\n",
       "                       -1.4236e-02, -1.2222e-02, -1.8799e-02, -1.5205e-02,  1.1475e-02,\n",
       "                        1.0101e-02,  1.0399e-02,  1.8509e-02, -3.5339e-02,  1.1475e-02,\n",
       "                       -1.5961e-02,  1.0704e-02, -1.8433e-02,  1.0674e-02, -1.1452e-02,\n",
       "                       -1.2833e-02, -1.1986e-02,  3.4363e-02,  9.5825e-03,  3.9177e-03,\n",
       "                       -4.2953e-03,  8.6441e-03,  1.1597e-02,  1.5198e-02,  2.5501e-03,\n",
       "                        6.3667e-03,  1.7105e-02,  1.3168e-02,  8.7967e-03, -1.7319e-02,\n",
       "                       -1.1299e-02, -2.0340e-02, -1.9135e-02,  1.1581e-02,  2.7351e-03,\n",
       "                       -9.5139e-03,  1.2856e-02,  1.8860e-02,  2.3651e-02,  3.7575e-03,\n",
       "                       -4.5662e-03,  1.4610e-02,  2.3895e-02,  2.0569e-02,  2.1652e-02,\n",
       "                       -2.7695e-03, -1.7242e-02,  3.9291e-03,  2.0921e-05, -2.2491e-02,\n",
       "                       -2.1225e-02, -2.2598e-02, -2.8046e-02,  6.0997e-03,  7.2327e-03,\n",
       "                        1.9363e-02,  8.1329e-03,  3.4618e-03, -1.0185e-02,  1.4057e-03,\n",
       "                       -2.2644e-02,  7.9422e-03, -1.7776e-02, -1.0139e-02, -2.7481e-02,\n",
       "                       -2.0569e-02, -8.1024e-03,  1.0979e-02, -1.3741e-02, -1.0765e-02,\n",
       "                        1.5631e-03,  6.3133e-03,  8.4305e-03,  5.0392e-03, -6.8512e-03,\n",
       "                        8.0204e-04,  9.5673e-03,  1.3985e-02, -1.7347e-03,  6.0120e-03,\n",
       "                        6.7978e-03,  2.2461e-02,  1.1566e-02, -1.5839e-02,  4.5419e-04,\n",
       "                        2.2141e-02,  1.4412e-02, -1.3840e-02,  1.8875e-02,  2.4094e-02,\n",
       "                       -1.8387e-02, -7.6714e-03,  1.2405e-02,  8.8501e-03, -1.0025e-02,\n",
       "                        6.9466e-03,  3.8025e-02,  1.5327e-02,  6.9847e-03,  2.7725e-02,\n",
       "                        1.3435e-02,  3.7861e-03,  1.1520e-02, -8.3084e-03, -1.4954e-03,\n",
       "                       -6.5269e-03,  5.1804e-03, -1.8225e-03,  1.4412e-02, -5.5771e-03,\n",
       "                       -1.2848e-02,  3.1342e-02,  1.8585e-02, -1.0208e-02, -5.1575e-03,\n",
       "                        5.2261e-03, -6.4278e-03,  2.1591e-02,  1.8568e-03, -7.0953e-03,\n",
       "                       -1.7273e-02,  1.1574e-02,  1.2058e-04,  5.9509e-03, -6.0692e-03,\n",
       "                        1.7899e-02, -3.1036e-02, -9.9258e-03, -5.4131e-03,  2.7222e-02,\n",
       "                        8.1482e-03,  1.9684e-02,  2.7313e-02, -8.0032e-03, -4.5514e-04,\n",
       "                        1.0513e-02, -2.7893e-02, -1.1284e-02,  7.9575e-03, -6.8512e-03,\n",
       "                       -2.6608e-03,  1.0803e-02, -1.1421e-02,  2.3117e-02, -4.1199e-02,\n",
       "                       -8.4000e-03,  1.5251e-02, -1.4450e-02, -2.0962e-03, -3.5706e-03,\n",
       "                       -7.5912e-03, -8.5754e-03, -2.3331e-02, -4.7112e-03, -4.8294e-03,\n",
       "                       -3.5431e-02,  3.0613e-03,  2.1118e-02, -8.3466e-03,  4.3755e-03,\n",
       "                       -4.3373e-03, -8.9493e-03, -2.8290e-02])),\n",
       "              ('w2v_encoder.w2v_model.encoder.pos_conv.0.0.weight',\n",
       "               tensor([[[ 9.8801e-04, -5.1765e-03, -2.8671e-02,  ..., -2.2598e-02,\n",
       "                          4.1718e-02,  2.6794e-02],\n",
       "                        [ 1.1871e-02,  5.1208e-02,  2.3102e-02,  ..., -1.7456e-02,\n",
       "                         -2.0386e-02,  3.0731e-02],\n",
       "                        [ 2.3224e-02, -2.3605e-02, -5.8985e-04,  ..., -1.2161e-02,\n",
       "                          5.4207e-03, -1.4740e-02],\n",
       "                        ...,\n",
       "                        [-2.6825e-02,  1.8063e-03,  1.6373e-02,  ..., -2.2018e-02,\n",
       "                         -4.0802e-02,  9.0485e-03],\n",
       "                        [-2.7359e-02, -8.8928e-02, -2.5665e-02,  ..., -1.2421e-02,\n",
       "                          5.9319e-03, -6.2500e-02],\n",
       "                        [ 2.8763e-02, -5.0964e-03, -2.6169e-02,  ...,  6.0272e-02,\n",
       "                          1.9104e-02,  1.9455e-03]],\n",
       "               \n",
       "                       [[-5.5786e-02, -6.5918e-02, -9.4177e-02,  ..., -7.8064e-02,\n",
       "                         -3.7964e-02, -5.9998e-02],\n",
       "                        [ 6.4583e-03,  8.8348e-03, -6.0211e-02,  ..., -2.7580e-03,\n",
       "                         -3.5126e-02, -4.2480e-02],\n",
       "                        [ 1.9958e-02,  4.1656e-02,  6.4087e-02,  ..., -3.0518e-02,\n",
       "                         -7.9632e-04, -1.3321e-02],\n",
       "                        ...,\n",
       "                        [ 4.9042e-02, -2.1515e-03, -1.1322e-02,  ..., -3.9368e-03,\n",
       "                         -6.3972e-03, -1.3344e-02],\n",
       "                        [-1.1482e-02,  2.6226e-03, -2.5467e-02,  ..., -9.5367e-03,\n",
       "                          3.8376e-03,  1.1282e-03],\n",
       "                        [-5.1727e-02, -6.6040e-02, -9.8938e-02,  ..., -5.8136e-03,\n",
       "                         -3.2288e-02, -5.7709e-02]],\n",
       "               \n",
       "                       [[-3.8116e-02, -4.0466e-02, -3.3264e-02,  ..., -1.1957e-01,\n",
       "                         -3.3051e-02, -5.2673e-02],\n",
       "                        [ 3.9612e-02, -2.7100e-02,  7.2021e-02,  ...,  7.3853e-02,\n",
       "                          2.2614e-02,  3.4515e-02],\n",
       "                        [ 3.9307e-02, -6.0394e-02,  3.8269e-02,  ...,  2.2949e-02,\n",
       "                         -1.6479e-02,  7.2289e-03],\n",
       "                        ...,\n",
       "                        [-5.6839e-03,  1.5343e-02,  2.2232e-02,  ...,  6.4331e-02,\n",
       "                         -5.0697e-03,  4.8332e-03],\n",
       "                        [ 7.1655e-02, -1.3367e-02, -2.9800e-02,  ..., -1.1688e-01,\n",
       "                         -7.4280e-02, -4.6295e-02],\n",
       "                        [-6.4697e-03, -2.2598e-02,  2.5497e-02,  ...,  6.9695e-03,\n",
       "                          5.2338e-02,  1.6678e-02]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[-2.2018e-02, -2.2171e-02, -5.5298e-02,  ..., -6.4026e-02,\n",
       "                          1.7731e-02, -3.7694e-04],\n",
       "                        [ 1.9398e-03,  2.5864e-02,  2.8076e-02,  ...,  3.3478e-02,\n",
       "                          3.2272e-03,  2.2018e-02],\n",
       "                        [ 1.7136e-02, -1.3359e-02, -2.2945e-03,  ...,  2.3346e-02,\n",
       "                          3.1738e-02, -4.0817e-03],\n",
       "                        ...,\n",
       "                        [ 3.5858e-02,  6.3599e-02,  2.8442e-02,  ..., -9.4681e-03,\n",
       "                         -2.0294e-02,  5.6076e-03],\n",
       "                        [ 1.4137e-02,  3.8929e-03,  3.7659e-02,  ..., -4.1290e-02,\n",
       "                         -1.5381e-02,  2.4734e-02],\n",
       "                        [ 9.1675e-02,  4.4830e-02,  3.0289e-03,  ...,  4.8859e-02,\n",
       "                          2.5925e-02,  1.6342e-02]],\n",
       "               \n",
       "                       [[ 4.5166e-02,  5.2032e-02,  7.6660e-02,  ...,  1.9617e-01,\n",
       "                          2.0477e-02,  2.6230e-02],\n",
       "                        [ 9.6252e-02,  2.8854e-02,  1.9562e-02,  ...,  4.6967e-02,\n",
       "                          4.1237e-03,  4.1351e-02],\n",
       "                        [-1.2886e-02, -1.2672e-02, -3.9246e-02,  ..., -2.9953e-02,\n",
       "                         -7.2632e-02,  1.9501e-02],\n",
       "                        ...,\n",
       "                        [-3.9459e-02, -1.3367e-02,  8.8654e-03,  ..., -5.6915e-03,\n",
       "                          3.7270e-03, -1.2903e-01],\n",
       "                        [ 3.2978e-03, -1.8127e-02,  2.9297e-02,  ..., -5.0201e-02,\n",
       "                         -1.6571e-02,  1.2482e-02],\n",
       "                        [-2.1378e-02,  4.2439e-05, -2.2354e-02,  ...,  2.7481e-02,\n",
       "                         -8.7769e-02, -1.3049e-01]],\n",
       "               \n",
       "                       [[ 4.0497e-02,  5.8861e-03,  2.6627e-02,  ...,  4.0550e-03,\n",
       "                          2.8725e-03, -1.6279e-03],\n",
       "                        [-2.6566e-02, -3.7193e-03, -1.2260e-02,  ..., -2.4857e-02,\n",
       "                         -4.3526e-03,  2.8782e-03],\n",
       "                        [ 4.1656e-03,  5.1804e-03,  8.6441e-03,  ..., -4.7058e-02,\n",
       "                         -3.4218e-03, -1.1627e-02],\n",
       "                        ...,\n",
       "                        [-5.2834e-03,  9.6970e-03, -1.0063e-02,  ...,  1.2596e-02,\n",
       "                          3.1799e-02,  2.2537e-02],\n",
       "                        [-1.0933e-02, -2.9022e-02,  3.4981e-03,  ..., -1.6708e-02,\n",
       "                         -1.8234e-02, -1.1765e-02],\n",
       "                        [-1.0929e-03,  2.3254e-02,  1.2703e-02,  ..., -2.5970e-02,\n",
       "                          7.8106e-04, -2.0294e-02]]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.pos_conv.0.0.bias',\n",
       "               tensor([0.0569, 0.0424, 0.0367,  ..., 0.1326, 0.0604, 0.0364])),\n",
       "              ('w2v_encoder.w2v_model.encoder.pos_conv.1.0.weight',\n",
       "               tensor([[[ 2.1286e-02,  3.1250e-02,  6.2866e-02,  ..., -1.2741e-03,\n",
       "                          4.8828e-02,  7.8613e-02],\n",
       "                        [-2.5528e-02, -3.1830e-02, -3.7785e-03,  ..., -5.7259e-03,\n",
       "                         -2.6093e-03, -2.2522e-02],\n",
       "                        [ 9.0698e-02,  7.4097e-02,  3.9551e-02,  ..., -7.1045e-02,\n",
       "                         -1.7288e-02,  3.3936e-02],\n",
       "                        ...,\n",
       "                        [-5.1636e-02,  5.5176e-02,  5.7770e-02,  ..., -1.1426e-01,\n",
       "                         -4.7882e-02,  8.9228e-05],\n",
       "                        [ 2.4948e-02,  1.2527e-02,  2.3758e-02,  ...,  1.8356e-02,\n",
       "                         -3.2227e-02,  1.5152e-02],\n",
       "                        [-9.2926e-03, -1.3908e-02, -1.4236e-02,  ...,  2.4384e-02,\n",
       "                         -2.7542e-02,  1.3657e-02]],\n",
       "               \n",
       "                       [[ 5.5603e-02, -2.4357e-03,  4.8065e-03,  ..., -3.3417e-02,\n",
       "                         -4.4067e-02, -2.2842e-02],\n",
       "                        [ 6.2286e-02,  7.9823e-04, -1.1856e-02,  ..., -4.5868e-02,\n",
       "                         -3.4065e-03, -2.5742e-02],\n",
       "                        [-5.0323e-02, -1.0400e-01, -2.7939e-02,  ...,  3.4698e-02,\n",
       "                         -7.2510e-02, -4.2969e-02],\n",
       "                        ...,\n",
       "                        [ 8.6731e-02,  3.7750e-02,  8.7219e-02,  ..., -7.5134e-02,\n",
       "                         -4.9866e-02,  2.5528e-02],\n",
       "                        [-2.1576e-02,  2.9404e-02, -2.9469e-03,  ..., -1.6357e-02,\n",
       "                         -8.5907e-03, -4.7943e-02],\n",
       "                        [-2.9160e-02, -1.5404e-02,  1.4015e-02,  ..., -4.0039e-02,\n",
       "                         -7.0068e-02, -7.5684e-02]],\n",
       "               \n",
       "                       [[ 2.5024e-02, -7.9590e-02,  5.5267e-02,  ...,  5.7190e-02,\n",
       "                          8.4717e-02,  8.5876e-02],\n",
       "                        [-3.2959e-02, -1.0175e-01, -6.2447e-03,  ...,  2.5223e-02,\n",
       "                          1.6260e-01,  1.2494e-01],\n",
       "                        [ 2.8473e-02,  6.9458e-02,  9.4666e-02,  ..., -3.4454e-02,\n",
       "                         -2.9129e-02, -3.6621e-02],\n",
       "                        ...,\n",
       "                        [ 8.1970e-02,  4.5959e-02,  8.8806e-03,  ..., -1.5015e-01,\n",
       "                         -1.3940e-01, -2.0667e-01],\n",
       "                        [ 2.3178e-02,  4.4952e-02, -2.2598e-02,  ..., -1.5205e-02,\n",
       "                         -6.8298e-02, -4.9805e-02],\n",
       "                        [-6.3904e-02, -1.0345e-01, -1.2585e-01,  ..., -3.1776e-03,\n",
       "                         -3.0670e-02,  6.4621e-03]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[-1.3634e-02,  1.6830e-02,  1.7212e-02,  ..., -1.2054e-01,\n",
       "                          2.5101e-02,  5.8990e-02],\n",
       "                        [ 5.0842e-02, -3.4180e-02, -2.4399e-02,  ...,  3.0079e-03,\n",
       "                          3.5736e-02,  1.9135e-02],\n",
       "                        [ 1.7395e-02, -2.9419e-02, -6.9336e-02,  ..., -2.9068e-02,\n",
       "                         -4.6265e-02, -8.1421e-02],\n",
       "                        ...,\n",
       "                        [-6.2378e-02, -2.3315e-02,  7.2021e-03,  ...,  2.5082e-03,\n",
       "                         -5.9090e-03,  5.5313e-03],\n",
       "                        [ 4.8737e-02, -6.8848e-02, -5.6885e-02,  ..., -1.1818e-02,\n",
       "                         -1.7700e-02,  3.4027e-02],\n",
       "                        [-9.6069e-02, -8.0627e-02, -4.8065e-02,  ...,  4.8828e-02,\n",
       "                         -2.1362e-02, -4.4098e-02]],\n",
       "               \n",
       "                       [[ 5.0079e-02,  2.2629e-02,  1.1475e-01,  ...,  6.7566e-02,\n",
       "                          5.5450e-02,  2.1164e-02],\n",
       "                        [-5.6488e-02,  6.7406e-03,  7.2510e-02,  ..., -7.2571e-02,\n",
       "                         -1.0696e-02, -7.6294e-02],\n",
       "                        [-8.5083e-02, -3.9551e-02,  4.6005e-03,  ...,  1.7181e-02,\n",
       "                          3.7720e-02,  5.4840e-02],\n",
       "                        ...,\n",
       "                        [ 3.0563e-02, -2.6489e-02, -4.2206e-02,  ...,  4.5990e-02,\n",
       "                          9.3365e-04, -8.6060e-02],\n",
       "                        [ 1.6394e-01,  1.3318e-01,  1.6525e-02,  ...,  1.4542e-02,\n",
       "                          6.0921e-03, -7.5928e-02],\n",
       "                        [-5.3711e-03,  3.2349e-03, -1.2993e-02,  ...,  7.6172e-02,\n",
       "                          5.7800e-02, -1.4160e-02]],\n",
       "               \n",
       "                       [[-1.1285e-01, -5.5969e-02, -4.8889e-02,  ...,  5.3467e-02,\n",
       "                          7.0923e-02, -4.0527e-02],\n",
       "                        [ 9.8511e-02,  7.2021e-02,  1.8570e-02,  ..., -2.9388e-02,\n",
       "                         -1.1505e-02, -1.8188e-02],\n",
       "                        [ 5.2673e-02,  1.5900e-02,  4.2038e-03,  ...,  7.6050e-02,\n",
       "                          9.0393e-02,  9.4971e-02],\n",
       "                        ...,\n",
       "                        [-5.1727e-02, -1.6464e-02,  2.0905e-02,  ..., -2.6535e-02,\n",
       "                         -1.0139e-02,  2.0782e-02],\n",
       "                        [-3.4485e-02, -3.1616e-02, -6.4049e-03,  ...,  2.0874e-02,\n",
       "                          2.4963e-02, -3.9825e-02],\n",
       "                        [ 2.1133e-02,  2.9099e-02,  4.2175e-02,  ..., -4.8431e-02,\n",
       "                         -2.7832e-02,  1.3214e-02]]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.pos_conv.1.0.bias',\n",
       "               tensor([ 0.0609,  0.1099,  0.1353,  ..., -0.0205,  0.0175,  0.0115])),\n",
       "              ('w2v_encoder.w2v_model.encoder.pos_conv.2.0.weight',\n",
       "               tensor([[[-0.0240,  0.0906, -0.1296,  ..., -0.0182,  0.0095,  0.0093],\n",
       "                        [ 0.1410,  0.1952,  0.0288,  ..., -0.0061, -0.0416, -0.0119],\n",
       "                        [-0.0877,  0.1248, -0.0155,  ...,  0.0063,  0.0592, -0.0449],\n",
       "                        ...,\n",
       "                        [ 0.0696, -0.0004,  0.0378,  ..., -0.0153, -0.0404, -0.0762],\n",
       "                        [ 0.0371, -0.1198,  0.0633,  ..., -0.1029, -0.0312, -0.0214],\n",
       "                        [-0.0078,  0.0973, -0.1124,  ...,  0.0021, -0.0024, -0.0652]],\n",
       "               \n",
       "                       [[-0.0117, -0.0426, -0.0721,  ...,  0.0583, -0.0082, -0.0724],\n",
       "                        [-0.0284,  0.0510,  0.0047,  ..., -0.0340, -0.0019, -0.0155],\n",
       "                        [ 0.0086, -0.0235, -0.0163,  ..., -0.0189,  0.0262,  0.0191],\n",
       "                        ...,\n",
       "                        [ 0.0255, -0.0028, -0.0046,  ...,  0.0795,  0.0365, -0.0004],\n",
       "                        [ 0.0176,  0.0066, -0.0148,  ...,  0.0482, -0.0207, -0.0855],\n",
       "                        [ 0.0074, -0.0355,  0.0023,  ...,  0.0228,  0.0121,  0.0017]],\n",
       "               \n",
       "                       [[ 0.0021, -0.0204, -0.0085,  ...,  0.0358,  0.0413,  0.0443],\n",
       "                        [-0.0136,  0.0346,  0.0625,  ...,  0.0071,  0.0090, -0.0087],\n",
       "                        [-0.0298, -0.0048, -0.0025,  ..., -0.0175,  0.0301,  0.0737],\n",
       "                        ...,\n",
       "                        [ 0.0374,  0.0256,  0.0280,  ..., -0.0339,  0.0155,  0.0454],\n",
       "                        [ 0.0191, -0.0315, -0.0250,  ..., -0.0183,  0.0020, -0.0217],\n",
       "                        [ 0.0222,  0.0056,  0.0202,  ...,  0.0101,  0.0717,  0.0339]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[ 0.0172,  0.0427,  0.0154,  ..., -0.0079, -0.0016,  0.0695],\n",
       "                        [ 0.0036, -0.0461, -0.1057,  ...,  0.0416,  0.0102, -0.0021],\n",
       "                        [ 0.1344,  0.0741,  0.0143,  ..., -0.0938, -0.0123,  0.0125],\n",
       "                        ...,\n",
       "                        [ 0.0533, -0.0297, -0.0695,  ..., -0.0261, -0.0203,  0.0050],\n",
       "                        [-0.0864, -0.0548, -0.0432,  ..., -0.0862,  0.0581,  0.0682],\n",
       "                        [ 0.0077, -0.0837, -0.0892,  ...,  0.0650,  0.0805,  0.0980]],\n",
       "               \n",
       "                       [[-0.0019,  0.0121,  0.0021,  ..., -0.1639, -0.1577, -0.0753],\n",
       "                        [-0.1016, -0.0057,  0.0974,  ..., -0.1037, -0.1116, -0.1055],\n",
       "                        [-0.0238,  0.0081,  0.0023,  ..., -0.0354,  0.0681,  0.0218],\n",
       "                        ...,\n",
       "                        [-0.0549,  0.0167,  0.0031,  ...,  0.1007,  0.0676,  0.0628],\n",
       "                        [-0.0262,  0.0032,  0.0576,  ...,  0.0498, -0.0344, -0.0807],\n",
       "                        [-0.0235, -0.0563, -0.0677,  ...,  0.0029,  0.0175, -0.0101]],\n",
       "               \n",
       "                       [[ 0.0041,  0.0137,  0.0038,  ..., -0.0330,  0.0199,  0.0542],\n",
       "                        [-0.0270, -0.0110, -0.0102,  ..., -0.0020, -0.0022, -0.0389],\n",
       "                        [-0.0102, -0.0206, -0.0360,  ...,  0.0731,  0.0011,  0.0634],\n",
       "                        ...,\n",
       "                        [ 0.0116, -0.0087, -0.0119,  ...,  0.0016,  0.0100,  0.0585],\n",
       "                        [ 0.0428,  0.0266, -0.0026,  ...,  0.0011, -0.0243,  0.0050],\n",
       "                        [ 0.0880,  0.0439,  0.0126,  ...,  0.0699,  0.1012,  0.1010]]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.pos_conv.2.0.bias',\n",
       "               tensor([ 0.0235, -0.1119, -0.0526,  ...,  0.1539, -0.0170,  0.0048])),\n",
       "              ('w2v_encoder.w2v_model.encoder.pos_conv.3.0.weight',\n",
       "               tensor([[[ 0.0417,  0.0549,  0.0088,  ..., -0.1884, -0.1243, -0.2261],\n",
       "                        [ 0.0573,  0.0017, -0.0708,  ..., -0.0256, -0.1473, -0.1464],\n",
       "                        [-0.0199, -0.0293, -0.0540,  ..., -0.2124, -0.2300, -0.1400],\n",
       "                        ...,\n",
       "                        [-0.0402, -0.0466,  0.0256,  ..., -0.1775, -0.1735, -0.1646],\n",
       "                        [ 0.0548,  0.0368,  0.0101,  ...,  0.0515,  0.0476,  0.0627],\n",
       "                        [ 0.0320, -0.0172, -0.0408,  ..., -0.0714,  0.1159,  0.1378]],\n",
       "               \n",
       "                       [[ 0.0056, -0.0026, -0.0527,  ..., -0.0723,  0.0922, -0.1061],\n",
       "                        [ 0.0830,  0.0790, -0.0521,  ...,  0.0014,  0.0089, -0.0353],\n",
       "                        [-0.0608, -0.0436, -0.0387,  ..., -0.0064, -0.0731, -0.0923],\n",
       "                        ...,\n",
       "                        [ 0.0412, -0.0279,  0.0597,  ...,  0.0553, -0.0091,  0.0369],\n",
       "                        [-0.0471, -0.0101,  0.0444,  ...,  0.0436,  0.0919,  0.0695],\n",
       "                        [ 0.0608,  0.0329,  0.0265,  ..., -0.0510, -0.1049,  0.1156]],\n",
       "               \n",
       "                       [[ 0.0209,  0.0268,  0.0772,  ...,  0.0186,  0.0229,  0.0332],\n",
       "                        [ 0.1068,  0.1225,  0.0719,  ...,  0.0485, -0.0750, -0.0388],\n",
       "                        [-0.0195, -0.0603, -0.1450,  ...,  0.0520,  0.0424, -0.0233],\n",
       "                        ...,\n",
       "                        [-0.0796, -0.0812,  0.0179,  ...,  0.0208,  0.1059,  0.0363],\n",
       "                        [-0.0271, -0.0272, -0.0806,  ..., -0.0462, -0.0522, -0.0950],\n",
       "                        [ 0.0894,  0.0505,  0.1086,  ...,  0.0977,  0.1004,  0.0889]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[-0.0213,  0.0277, -0.0900,  ...,  0.0450,  0.0151,  0.0555],\n",
       "                        [-0.0013,  0.0047,  0.0690,  ..., -0.0834, -0.0429, -0.0202],\n",
       "                        [ 0.1379,  0.0509,  0.0173,  ..., -0.0262,  0.0490,  0.0222],\n",
       "                        ...,\n",
       "                        [-0.0037,  0.0490, -0.0662,  ..., -0.0267,  0.0238,  0.0345],\n",
       "                        [-0.0646, -0.0843, -0.0403,  ...,  0.0419, -0.0689, -0.0748],\n",
       "                        [-0.0105, -0.0325, -0.0592,  ..., -0.0737,  0.0072,  0.0728]],\n",
       "               \n",
       "                       [[-0.0590,  0.0438,  0.0472,  ..., -0.0487,  0.0562,  0.0843],\n",
       "                        [ 0.0340,  0.0585,  0.0219,  ...,  0.1372, -0.0690,  0.0451],\n",
       "                        [ 0.0173,  0.0061, -0.0240,  ..., -0.0463, -0.0036,  0.0256],\n",
       "                        ...,\n",
       "                        [ 0.1511,  0.1377,  0.0434,  ...,  0.0672, -0.0102,  0.0406],\n",
       "                        [-0.0977, -0.1059, -0.0148,  ...,  0.0120, -0.0536, -0.0457],\n",
       "                        [ 0.0151, -0.0076,  0.0203,  ...,  0.0830,  0.0257,  0.0623]],\n",
       "               \n",
       "                       [[ 0.1149,  0.0682, -0.0594,  ...,  0.0515,  0.0573,  0.0420],\n",
       "                        [ 0.1866,  0.1786,  0.1310,  ...,  0.1595,  0.0440,  0.1449],\n",
       "                        [-0.1353, -0.0674,  0.0008,  ...,  0.0760,  0.0800,  0.0704],\n",
       "                        ...,\n",
       "                        [ 0.0883,  0.0603,  0.0576,  ..., -0.0023, -0.0415,  0.0139],\n",
       "                        [ 0.0275,  0.0341,  0.0741,  ..., -0.0152, -0.0759, -0.0531],\n",
       "                        [ 0.0494,  0.0094,  0.0480,  ...,  0.0476,  0.0215,  0.0440]]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.pos_conv.3.0.bias',\n",
       "               tensor([ 0.0069, -0.1732, -0.0954,  ...,  0.1014,  0.2418,  0.1212])),\n",
       "              ('w2v_encoder.w2v_model.encoder.pos_conv.4.0.weight',\n",
       "               tensor([[[-7.4585e-02, -5.5511e-02,  3.1769e-02,  ..., -1.4477e-03,\n",
       "                         -4.2686e-03,  2.9236e-02],\n",
       "                        [ 3.9825e-02,  5.6305e-02, -3.3844e-02,  ..., -3.8544e-02,\n",
       "                          1.3342e-01,  3.6194e-02],\n",
       "                        [-6.9641e-02, -1.4717e-02,  1.0201e-02,  ...,  3.1860e-02,\n",
       "                          8.5938e-02,  4.6539e-02],\n",
       "                        ...,\n",
       "                        [-4.0405e-02, -3.1189e-02,  1.8219e-02,  ...,  1.7090e-03,\n",
       "                         -5.0781e-02, -1.3708e-01],\n",
       "                        [ 3.8116e-02,  9.9365e-02,  4.3182e-02,  ...,  6.2866e-02,\n",
       "                          6.4026e-02,  8.0444e-02],\n",
       "                        [-8.9493e-03, -4.5807e-02,  2.9022e-02,  ...,  9.3689e-03,\n",
       "                         -2.3178e-02, -2.0063e-04]],\n",
       "               \n",
       "                       [[-3.9368e-02, -5.5695e-02, -7.5806e-02,  ...,  1.9196e-02,\n",
       "                          4.7974e-02,  2.9877e-02],\n",
       "                        [-9.1400e-03, -3.8666e-02,  7.7759e-02,  ...,  4.8737e-02,\n",
       "                          1.7017e-01,  1.6455e-01],\n",
       "                        [-9.6069e-02, -4.8309e-02, -7.0435e-02,  ...,  1.3037e-01,\n",
       "                         -2.8397e-02,  1.4816e-02],\n",
       "                        ...,\n",
       "                        [-7.0435e-02, -8.9172e-02,  1.5221e-02,  ...,  7.3891e-03,\n",
       "                         -3.3844e-02, -1.1554e-01],\n",
       "                        [-1.4966e-01, -1.3806e-01, -1.4856e-01,  ..., -7.6721e-02,\n",
       "                         -8.8440e-02, -1.2286e-01],\n",
       "                        [ 1.1224e-01,  1.3367e-01,  1.0010e-01,  ...,  3.8910e-02,\n",
       "                          3.5004e-02,  1.3954e-02]],\n",
       "               \n",
       "                       [[ 7.6828e-03, -5.6496e-03, -6.5125e-02,  ...,  4.5380e-02,\n",
       "                         -1.1368e-02,  8.5510e-02],\n",
       "                        [-1.8967e-02, -5.6267e-03, -3.7720e-02,  ...,  4.3365e-02,\n",
       "                         -8.9661e-02, -9.6497e-02],\n",
       "                        [ 1.4816e-02,  2.2964e-02, -1.4694e-02,  ...,  1.7441e-02,\n",
       "                         -1.0689e-02,  3.0869e-02],\n",
       "                        ...,\n",
       "                        [ 5.4565e-02,  4.7485e-02,  4.3549e-02,  ...,  5.8060e-03,\n",
       "                         -4.3640e-02, -9.3994e-03],\n",
       "                        [ 2.4277e-02, -5.6793e-02, -7.0007e-02,  ..., -5.9174e-02,\n",
       "                          4.6448e-02, -4.1443e-02],\n",
       "                        [-1.0513e-02, -2.2247e-02,  1.9989e-02,  ..., -1.1620e-02,\n",
       "                          1.8585e-02,  2.6260e-02]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[-1.5297e-03,  1.9255e-03,  3.4698e-02,  ..., -2.3636e-02,\n",
       "                          4.0779e-03,  3.7628e-02],\n",
       "                        [ 5.1300e-02,  9.2010e-03,  4.3549e-02,  ...,  4.4861e-02,\n",
       "                         -7.3364e-02, -1.2054e-02],\n",
       "                        [ 8.5754e-03,  6.2027e-03,  1.3504e-02,  ..., -1.8356e-02,\n",
       "                         -1.3626e-02, -2.7695e-03],\n",
       "                        ...,\n",
       "                        [-3.2227e-02, -4.6661e-02,  6.9641e-02,  ...,  2.3422e-03,\n",
       "                          6.8115e-02, -7.2899e-03],\n",
       "                        [ 7.4890e-02, -1.0330e-02, -9.0881e-02,  ..., -1.4954e-01,\n",
       "                         -1.4717e-02, -3.9551e-02],\n",
       "                        [ 9.4147e-03, -3.3550e-03,  5.0751e-02,  ...,  6.3904e-02,\n",
       "                          1.4087e-01,  6.6956e-02]],\n",
       "               \n",
       "                       [[-4.9042e-02, -5.9631e-02, -4.8309e-02,  ...,  2.9266e-02,\n",
       "                          3.2379e-02,  7.1594e-02],\n",
       "                        [-3.2558e-03, -1.6174e-03, -2.0218e-03,  ...,  6.1584e-02,\n",
       "                         -2.5223e-02,  6.2805e-02],\n",
       "                        [ 5.1270e-02,  1.1299e-02,  8.8501e-02,  ..., -4.0817e-04,\n",
       "                         -3.8055e-02, -6.2347e-02],\n",
       "                        ...,\n",
       "                        [-4.1595e-02, -2.2766e-02,  9.7351e-02,  ..., -5.7800e-02,\n",
       "                         -3.2684e-02,  1.2001e-02],\n",
       "                        [ 6.4270e-02,  2.4628e-02,  9.8190e-03,  ...,  6.8207e-03,\n",
       "                          1.4148e-01,  3.2867e-02],\n",
       "                        [-7.3853e-02, -9.8450e-02, -2.7679e-02,  ...,  6.7368e-03,\n",
       "                          1.3184e-01,  9.8755e-02]],\n",
       "               \n",
       "                       [[ 3.3691e-01,  2.6270e-01,  2.1399e-01,  ...,  6.9763e-02,\n",
       "                          8.8135e-02,  7.5745e-02],\n",
       "                        [-2.6993e-02, -1.2781e-01, -7.4280e-02,  ...,  5.0629e-02,\n",
       "                          2.9419e-02,  8.4106e-02],\n",
       "                        [ 1.3501e-01,  1.2140e-01,  1.4990e-01,  ...,  5.1880e-02,\n",
       "                          5.4688e-02,  5.3497e-02],\n",
       "                        ...,\n",
       "                        [ 9.9182e-02,  3.4729e-02,  4.5837e-02,  ..., -1.4679e-02,\n",
       "                          9.5703e-02,  3.9795e-02],\n",
       "                        [-4.6387e-02, -7.8735e-02, -1.0406e-01,  ...,  7.9041e-03,\n",
       "                         -5.3253e-02, -6.4026e-02],\n",
       "                        [ 6.7200e-02, -2.1915e-03, -3.8929e-03,  ..., -1.2225e-01,\n",
       "                         -1.0254e-01, -3.5828e-02]]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.pos_conv.4.0.bias',\n",
       "               tensor([-0.0194, -0.1855, -0.0926,  ...,  0.0060,  0.2313, -0.0588])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.0.self_attn.k_proj.weight',\n",
       "               tensor([[-0.0857, -0.0807, -0.0607,  ...,  0.0020,  0.0867,  0.0869],\n",
       "                       [ 0.0396, -0.0138, -0.0269,  ...,  0.0247, -0.0696, -0.1667],\n",
       "                       [ 0.0228,  0.0721,  0.0942,  ..., -0.0068,  0.0302,  0.0167],\n",
       "                       ...,\n",
       "                       [-0.0345,  0.0519, -0.0688,  ..., -0.0117,  0.0662,  0.1170],\n",
       "                       [-0.0446, -0.0143, -0.0596,  ...,  0.0826, -0.0829,  0.0325],\n",
       "                       [ 0.0285,  0.0686, -0.0573,  ..., -0.0238,  0.0687,  0.0210]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.0.self_attn.k_proj.bias',\n",
       "               tensor([-0.0031, -0.0105,  0.0089,  ..., -0.0029,  0.0010, -0.0099])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.0.self_attn.v_proj.weight',\n",
       "               tensor([[ 0.0150, -0.0200, -0.0498,  ..., -0.0047, -0.0012,  0.0043],\n",
       "                       [-0.0405, -0.0164, -0.0040,  ...,  0.0254, -0.0062,  0.0242],\n",
       "                       [ 0.0367, -0.0120,  0.0312,  ...,  0.0138, -0.0128, -0.0210],\n",
       "                       ...,\n",
       "                       [ 0.0581, -0.0351,  0.0197,  ..., -0.0067,  0.0250, -0.0072],\n",
       "                       [ 0.0332,  0.0051, -0.0440,  ..., -0.0045, -0.0001, -0.0800],\n",
       "                       [ 0.0046,  0.0440,  0.0092,  ..., -0.0197, -0.0277,  0.0378]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.0.self_attn.v_proj.bias',\n",
       "               tensor([-0.0032, -0.0024, -0.0010,  ...,  0.0008, -0.0032, -0.0136])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.0.self_attn.q_proj.weight',\n",
       "               tensor([[-0.0548, -0.0323, -0.0773,  ...,  0.0044,  0.1190, -0.0170],\n",
       "                       [ 0.0358, -0.0842,  0.0616,  ...,  0.0334, -0.1383, -0.0665],\n",
       "                       [ 0.0222,  0.0004,  0.0075,  ...,  0.0601, -0.0434,  0.1022],\n",
       "                       ...,\n",
       "                       [ 0.0949,  0.0886, -0.1211,  ..., -0.0453,  0.0967,  0.0050],\n",
       "                       [-0.0234, -0.1564,  0.0399,  ...,  0.0271,  0.0523,  0.0049],\n",
       "                       [-0.0179, -0.0048, -0.0528,  ..., -0.0212,  0.1598,  0.0155]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.0.self_attn.q_proj.bias',\n",
       "               tensor([ 0.3723,  0.5171, -0.1042,  ...,  0.0374, -0.9980, -0.0731])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.0.self_attn.out_proj.weight',\n",
       "               tensor([[ 0.0035, -0.0002,  0.0282,  ...,  0.0426, -0.0291,  0.0173],\n",
       "                       [ 0.0047, -0.0515, -0.0388,  ...,  0.0640, -0.0075, -0.0139],\n",
       "                       [ 0.0198,  0.0166, -0.0132,  ...,  0.0090,  0.0014, -0.0029],\n",
       "                       ...,\n",
       "                       [-0.0316, -0.0205, -0.0037,  ...,  0.0300, -0.0036,  0.0325],\n",
       "                       [-0.0046,  0.0120,  0.0218,  ...,  0.0740, -0.0024, -0.0386],\n",
       "                       [ 0.0259, -0.0081,  0.0062,  ...,  0.0018,  0.0509, -0.0154]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.0.self_attn.out_proj.bias',\n",
       "               tensor([ 0.0087,  0.0003, -0.0014,  ..., -0.0005,  0.0063,  0.0078])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.0.self_attn_layer_norm.weight',\n",
       "               tensor([0.2111, 0.1785, 0.2017,  ..., 0.2427, 0.5586, 0.2009])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.0.self_attn_layer_norm.bias',\n",
       "               tensor([-0.0105, -0.0113, -0.0147,  ..., -0.0283, -0.0415,  0.0276])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.0.fc1.weight',\n",
       "               tensor([[ 0.0061, -0.1364,  0.1134,  ..., -0.0050,  0.0039, -0.2212],\n",
       "                       [-0.1199,  0.0765, -0.0499,  ...,  0.0540, -0.0167,  0.0035],\n",
       "                       [-0.0211,  0.1342,  0.0540,  ..., -0.1649, -0.0274, -0.0374],\n",
       "                       ...,\n",
       "                       [-0.0667,  0.0894,  0.0524,  ...,  0.0098, -0.0269,  0.0088],\n",
       "                       [-0.0671,  0.1353,  0.0624,  ..., -0.0137,  0.0032,  0.0620],\n",
       "                       [ 0.0123, -0.0528,  0.0207,  ..., -0.2335,  0.0258, -0.0374]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.0.fc1.bias',\n",
       "               tensor([-0.0564, -0.0549, -0.0220,  ..., -0.0476, -0.1097, -0.0251])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.0.fc2.weight',\n",
       "               tensor([[ 0.0933, -0.0391, -0.2551,  ..., -0.0842,  0.0440,  0.0285],\n",
       "                       [-0.0654, -0.0338, -0.0922,  ...,  0.1324,  0.0090, -0.0122],\n",
       "                       [-0.0642,  0.0341,  0.1356,  ..., -0.0761, -0.0366, -0.0312],\n",
       "                       ...,\n",
       "                       [ 0.0656,  0.0245,  0.0576,  ...,  0.0624, -0.0518,  0.0772],\n",
       "                       [ 0.0347,  0.0162, -0.0192,  ...,  0.0302, -0.0327, -0.0723],\n",
       "                       [ 0.2329,  0.0382, -0.0059,  ..., -0.1327, -0.0117, -0.0663]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.0.fc2.bias',\n",
       "               tensor([-0.0122,  0.4841,  0.0164,  ...,  0.0219,  0.0209,  0.0475])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.0.final_layer_norm.weight',\n",
       "               tensor([0.0766, 0.0264, 0.2120,  ..., 0.2399, 0.5488, 0.1639])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.0.final_layer_norm.bias',\n",
       "               tensor([-0.0058, -0.0870,  0.0211,  ..., -0.0209, -0.0348,  0.0111])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.1.self_attn.k_proj.weight',\n",
       "               tensor([[ 0.0665,  0.0752,  0.0499,  ..., -0.0542, -0.0828, -0.0213],\n",
       "                       [ 0.0741,  0.3137,  0.0570,  ...,  0.0369,  0.0843, -0.1743],\n",
       "                       [ 0.0200,  0.0219,  0.0380,  ..., -0.0804,  0.1919, -0.0784],\n",
       "                       ...,\n",
       "                       [-0.0421,  0.0232, -0.0472,  ..., -0.1652, -0.0102, -0.1860],\n",
       "                       [-0.0909,  0.0910, -0.0034,  ..., -0.0207,  0.0120, -0.0571],\n",
       "                       [-0.0693,  0.0267,  0.0153,  ...,  0.0442, -0.1914, -0.1251]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.1.self_attn.k_proj.bias',\n",
       "               tensor([-0.0035, -0.0010, -0.0035,  ...,  0.0079, -0.0101, -0.0166])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.1.self_attn.v_proj.weight',\n",
       "               tensor([[ 0.0058, -0.0184,  0.0168,  ...,  0.0316,  0.0102, -0.0084],\n",
       "                       [-0.0230,  0.0172, -0.0047,  ..., -0.0208,  0.0373,  0.0650],\n",
       "                       [ 0.0132, -0.0034,  0.0245,  ...,  0.0190, -0.0137,  0.0041],\n",
       "                       ...,\n",
       "                       [ 0.0023,  0.0073, -0.0310,  ...,  0.0276, -0.0219,  0.0467],\n",
       "                       [ 0.0889, -0.0269, -0.0309,  ..., -0.0247, -0.0145,  0.0286],\n",
       "                       [-0.0005, -0.0362, -0.0277,  ...,  0.0250, -0.0586, -0.0577]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.1.self_attn.v_proj.bias',\n",
       "               tensor([-0.0016,  0.0663, -0.0125,  ...,  0.0019,  0.0216,  0.0070])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.1.self_attn.q_proj.weight',\n",
       "               tensor([[-0.0406, -0.1371, -0.0753,  ...,  0.0036, -0.0685, -0.0447],\n",
       "                       [-0.0012,  0.0670,  0.0248,  ...,  0.0044, -0.0373,  0.0461],\n",
       "                       [ 0.0838, -0.0300,  0.0854,  ..., -0.0486,  0.1373,  0.0348],\n",
       "                       ...,\n",
       "                       [-0.0197,  0.1580, -0.0788,  ..., -0.1520,  0.0058, -0.1938],\n",
       "                       [-0.0624, -0.0635,  0.0120,  ..., -0.0641, -0.0536, -0.0446],\n",
       "                       [-0.0238, -0.0137,  0.0300,  ...,  0.0202, -0.0474,  0.0162]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.1.self_attn.q_proj.bias',\n",
       "               tensor([ 0.2195,  0.4556,  0.3374,  ...,  0.0927,  0.2428, -0.0214])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.1.self_attn.out_proj.weight',\n",
       "               tensor([[-0.0029,  0.0401,  0.0521,  ..., -0.0463,  0.0231,  0.0532],\n",
       "                       [-0.0003, -0.0856, -0.0205,  ..., -0.0394, -0.1434,  0.0840],\n",
       "                       [-0.0158, -0.0563, -0.0409,  ...,  0.0215, -0.0146,  0.0088],\n",
       "                       ...,\n",
       "                       [-0.0116,  0.0862,  0.0126,  ..., -0.0282,  0.0309, -0.0119],\n",
       "                       [-0.0032,  0.0560,  0.0031,  ..., -0.0333, -0.0135,  0.0457],\n",
       "                       [-0.0155, -0.0999,  0.0760,  ..., -0.0216, -0.0558,  0.0617]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.1.self_attn.out_proj.bias',\n",
       "               tensor([-0.1644,  0.0720,  0.0168,  ..., -0.0125, -0.0090,  0.0555])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.1.self_attn_layer_norm.weight',\n",
       "               tensor([0.2102, 0.0107, 0.3572,  ..., 0.3440, 0.3828, 0.4006])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.1.self_attn_layer_norm.bias',\n",
       "               tensor([-0.5527, -0.4937,  0.1434,  ..., -0.1893, -0.0933,  0.3777])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.1.fc1.weight',\n",
       "               tensor([[-0.0154, -0.0213, -0.0117,  ...,  0.0215, -0.0220,  0.0244],\n",
       "                       [ 0.0338, -0.0267, -0.0020,  ..., -0.0094, -0.0434,  0.0243],\n",
       "                       [-0.0437, -0.0032,  0.0070,  ..., -0.0002,  0.0091, -0.0061],\n",
       "                       ...,\n",
       "                       [-0.0367, -0.0166, -0.0500,  ..., -0.1400, -0.0467,  0.0992],\n",
       "                       [-0.0293, -0.0410,  0.0392,  ...,  0.0313, -0.0267,  0.0043],\n",
       "                       [-0.0078, -0.0040,  0.0192,  ...,  0.0186, -0.0405, -0.0299]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.1.fc1.bias',\n",
       "               tensor([-0.0186, -0.0108, -0.0128,  ..., -0.0066, -0.0259, -0.0077])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.1.fc2.weight',\n",
       "               tensor([[ 0.0087, -0.0021, -0.0290,  ..., -0.0784,  0.0160, -0.0100],\n",
       "                       [ 0.0134, -0.0090, -0.0121,  ...,  0.0270, -0.0145, -0.0056],\n",
       "                       [ 0.0124, -0.0038, -0.0287,  ...,  0.0231, -0.0066,  0.0220],\n",
       "                       ...,\n",
       "                       [-0.0032,  0.0064,  0.0029,  ..., -0.0775, -0.0238,  0.0277],\n",
       "                       [ 0.0019,  0.0090,  0.0221,  ..., -0.0037, -0.0101,  0.0069],\n",
       "                       [-0.0187, -0.0029, -0.0107,  ...,  0.1037,  0.0015,  0.0239]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.1.fc2.bias',\n",
       "               tensor([ 0.0916,  0.0704, -0.0231,  ..., -0.0129, -0.0315, -0.0251])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.1.final_layer_norm.weight',\n",
       "               tensor([0.0104, 0.0773, 0.3359,  ..., 0.3301, 0.4277, 0.1877])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.1.final_layer_norm.bias',\n",
       "               tensor([ 0.0019,  0.0164, -0.0887,  ...,  0.1060,  0.0493, -0.1228])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.2.self_attn.k_proj.weight',\n",
       "               tensor([[-0.0337, -0.0356,  0.0515,  ..., -0.0050, -0.0790,  0.1614],\n",
       "                       [-0.0654,  0.0040, -0.0683,  ..., -0.0174,  0.0806, -0.1204],\n",
       "                       [-0.0225, -0.0979, -0.0561,  ...,  0.0841,  0.0378,  0.1554],\n",
       "                       ...,\n",
       "                       [-0.0051,  0.0004, -0.0082,  ...,  0.1141,  0.0723,  0.1549],\n",
       "                       [ 0.0698,  0.0744, -0.0048,  ..., -0.0296,  0.0028, -0.0657],\n",
       "                       [-0.0135,  0.1035, -0.0222,  ...,  0.1233,  0.0226,  0.0144]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.2.self_attn.k_proj.bias',\n",
       "               tensor([-0.0149, -0.0073,  0.0099,  ...,  0.0078,  0.0176, -0.0179])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.2.self_attn.v_proj.weight',\n",
       "               tensor([[ 0.0341,  0.1096,  0.0039,  ..., -0.0005, -0.0122,  0.0367],\n",
       "                       [ 0.0272, -0.0076, -0.0116,  ...,  0.0378, -0.0074, -0.0253],\n",
       "                       [ 0.0216, -0.0065,  0.0258,  ..., -0.0578,  0.0012,  0.0233],\n",
       "                       ...,\n",
       "                       [-0.0809,  0.0656, -0.1444,  ..., -0.0122,  0.0382, -0.0114],\n",
       "                       [-0.0146, -0.0251, -0.0522,  ...,  0.0390,  0.0429, -0.0249],\n",
       "                       [-0.0056,  0.0310, -0.0177,  ...,  0.0462, -0.0413, -0.0628]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.2.self_attn.v_proj.bias',\n",
       "               tensor([ 0.0018,  0.0001, -0.0181,  ..., -0.0130, -0.0051, -0.0138])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.2.self_attn.q_proj.weight',\n",
       "               tensor([[ 0.0576, -0.0229, -0.0163,  ...,  0.1573, -0.0614, -0.0240],\n",
       "                       [ 0.0853,  0.0046,  0.0013,  ..., -0.0087, -0.0834,  0.0968],\n",
       "                       [-0.0140,  0.0074,  0.0954,  ..., -0.0238, -0.0068, -0.0297],\n",
       "                       ...,\n",
       "                       [ 0.0419,  0.0742, -0.0659,  ..., -0.0124,  0.0785, -0.0569],\n",
       "                       [ 0.1017, -0.0470,  0.0663,  ...,  0.0876, -0.0736, -0.0117],\n",
       "                       [ 0.0185, -0.0501,  0.0466,  ...,  0.0203, -0.0044,  0.0443]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.2.self_attn.q_proj.bias',\n",
       "               tensor([ 0.0364,  0.1893, -0.1356,  ...,  0.4104, -0.1921,  0.1434])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.2.self_attn.out_proj.weight',\n",
       "               tensor([[ 0.0503,  0.0236,  0.0595,  ...,  0.0782, -0.0217,  0.0894],\n",
       "                       [-0.0586, -0.0966,  0.1401,  ..., -0.1538,  0.0006,  0.0013],\n",
       "                       [ 0.0152,  0.0097, -0.0494,  ...,  0.0194,  0.0123,  0.0260],\n",
       "                       ...,\n",
       "                       [-0.0201, -0.0135, -0.0421,  ..., -0.0414,  0.0237,  0.0209],\n",
       "                       [ 0.0263,  0.0492, -0.0379,  ..., -0.0034,  0.0172, -0.0048],\n",
       "                       [ 0.0049,  0.0445, -0.0116,  ..., -0.0160,  0.0441, -0.0548]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.2.self_attn.out_proj.bias',\n",
       "               tensor([-0.1349, -0.0903,  0.0311,  ..., -0.0127,  0.0066,  0.0787])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.2.self_attn_layer_norm.weight',\n",
       "               tensor([0.1323, 0.0963, 0.2617,  ..., 0.3245, 0.3892, 0.2522])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.2.self_attn_layer_norm.bias',\n",
       "               tensor([-0.3391, -0.5000,  0.0955,  ..., -0.0563, -0.0110,  0.3281])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.2.fc1.weight',\n",
       "               tensor([[ 0.0016,  0.0083, -0.0830,  ...,  0.0028, -0.0954,  0.0457],\n",
       "                       [ 0.0214,  0.0305,  0.1351,  ...,  0.0901, -0.0091, -0.0136],\n",
       "                       [-0.0171, -0.0771,  0.2157,  ..., -0.0126, -0.0854, -0.1313],\n",
       "                       ...,\n",
       "                       [ 0.0303, -0.0127, -0.0113,  ...,  0.0276,  0.0760, -0.0244],\n",
       "                       [ 0.0714, -0.0600, -0.1327,  ...,  0.1930, -0.0473,  0.0060],\n",
       "                       [-0.0026,  0.0030, -0.0518,  ..., -0.0075,  0.0537, -0.0168]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.2.fc1.bias',\n",
       "               tensor([ 0.0106,  0.0097, -0.0076,  ..., -0.0113,  0.0031,  0.0101])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.2.fc2.weight',\n",
       "               tensor([[ 0.0111,  0.0035, -0.1705,  ...,  0.0193, -0.0787, -0.0219],\n",
       "                       [ 0.0192,  0.1003, -0.0798,  ...,  0.0053, -0.0978, -0.0011],\n",
       "                       [ 0.0726, -0.1852,  0.0257,  ...,  0.0100, -0.0370, -0.0356],\n",
       "                       ...,\n",
       "                       [-0.0257,  0.0271,  0.0436,  ..., -0.0035,  0.0271,  0.0290],\n",
       "                       [ 0.0057,  0.0210,  0.0345,  ..., -0.0583, -0.0217,  0.0305],\n",
       "                       [-0.0261,  0.0520, -0.0235,  ..., -0.0062, -0.0972, -0.0152]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.2.fc2.bias',\n",
       "               tensor([-0.0313,  0.0403,  0.0469,  ..., -0.0414, -0.0303, -0.0164])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.2.final_layer_norm.weight',\n",
       "               tensor([0.0354, 0.0563, 0.2045,  ..., 0.3135, 0.5239, 0.1017])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.2.final_layer_norm.bias',\n",
       "               tensor([ 0.0021,  0.0186, -0.0144,  ...,  0.0328,  0.0511, -0.0340])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.3.self_attn.k_proj.weight',\n",
       "               tensor([[ 0.0125, -0.0771,  0.0246,  ...,  0.0492, -0.0697,  0.0558],\n",
       "                       [-0.0933,  0.0792,  0.0262,  ..., -0.1357, -0.0382, -0.0602],\n",
       "                       [ 0.0307, -0.1016,  0.0881,  ..., -0.0367, -0.0781,  0.1451],\n",
       "                       ...,\n",
       "                       [ 0.0051, -0.0579,  0.0089,  ...,  0.0698, -0.1096,  0.0101],\n",
       "                       [ 0.1597,  0.0106,  0.0144,  ..., -0.0489, -0.0239,  0.1426],\n",
       "                       [ 0.0855,  0.1221,  0.0453,  ...,  0.0523,  0.0085,  0.0768]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.3.self_attn.k_proj.bias',\n",
       "               tensor([-0.0108, -0.0066,  0.0060,  ...,  0.0078, -0.0133,  0.0135])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.3.self_attn.v_proj.weight',\n",
       "               tensor([[ 0.0011, -0.0836, -0.0666,  ...,  0.0615,  0.0027,  0.0160],\n",
       "                       [-0.0036,  0.0518,  0.0210,  ..., -0.0837,  0.0175,  0.0142],\n",
       "                       [-0.0026,  0.0333,  0.0527,  ..., -0.0798, -0.0318, -0.1208],\n",
       "                       ...,\n",
       "                       [-0.1252,  0.0393,  0.0308,  ..., -0.0252, -0.0232,  0.0578],\n",
       "                       [-0.2498,  0.0616, -0.0175,  ..., -0.0296,  0.0119,  0.0886],\n",
       "                       [ 0.0038, -0.0565,  0.0435,  ...,  0.0161,  0.0254,  0.0558]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.3.self_attn.v_proj.bias',\n",
       "               tensor([ 0.0084,  0.0060,  0.0145,  ...,  0.0018, -0.0177, -0.0093])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.3.self_attn.q_proj.weight',\n",
       "               tensor([[ 0.0576,  0.0107, -0.0333,  ...,  0.0115,  0.0494,  0.0309],\n",
       "                       [-0.1653, -0.1525, -0.0056,  ..., -0.0260, -0.0126, -0.0119],\n",
       "                       [-0.0852, -0.0363,  0.0601,  ..., -0.0393, -0.1288,  0.0903],\n",
       "                       ...,\n",
       "                       [-0.0006, -0.0018, -0.1405,  ...,  0.1781, -0.0743, -0.0781],\n",
       "                       [ 0.0825, -0.0421,  0.1233,  ..., -0.0537, -0.0082, -0.1393],\n",
       "                       [ 0.0480, -0.0702,  0.0017,  ..., -0.0062, -0.0038, -0.0268]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.3.self_attn.q_proj.bias',\n",
       "               tensor([-0.0135, -0.2371, -0.0035,  ...,  0.0390,  0.1788, -0.0634])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.3.self_attn.out_proj.weight',\n",
       "               tensor([[-0.0235, -0.0677,  0.0031,  ...,  0.0361, -0.0423, -0.0555],\n",
       "                       [ 0.0746, -0.0724, -0.2267,  ..., -0.0539, -0.0429,  0.0602],\n",
       "                       [-0.0215,  0.0493,  0.0458,  ...,  0.0572, -0.0225, -0.0175],\n",
       "                       ...,\n",
       "                       [ 0.0316,  0.1318, -0.0069,  ...,  0.0289,  0.0483, -0.0302],\n",
       "                       [ 0.0200, -0.0130, -0.0355,  ..., -0.0096, -0.0468,  0.0041],\n",
       "                       [-0.0107,  0.0156,  0.1049,  ...,  0.0031, -0.0153, -0.0279]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.3.self_attn.out_proj.bias',\n",
       "               tensor([-0.1604,  0.1555,  0.0710,  ..., -0.0781,  0.0162,  0.0830])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.3.self_attn_layer_norm.weight',\n",
       "               tensor([0.1332, 0.1062, 0.2228,  ..., 0.4041, 0.4683, 0.1150])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.3.self_attn_layer_norm.bias',\n",
       "               tensor([-0.2988,  0.2136,  0.1312,  ..., -0.3137, -0.0556,  0.2350])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.3.fc1.weight',\n",
       "               tensor([[-0.0366, -0.0601,  0.0793,  ..., -0.0768,  0.1251, -0.0243],\n",
       "                       [ 0.0242, -0.0367,  0.1515,  ..., -0.0785, -0.0688, -0.0236],\n",
       "                       [ 0.0550, -0.1240, -0.0865,  ..., -0.0257,  0.1688,  0.0039],\n",
       "                       ...,\n",
       "                       [ 0.0252,  0.1047,  0.0107,  ...,  0.0341,  0.0590,  0.0436],\n",
       "                       [ 0.0138,  0.0162, -0.0571,  ...,  0.0454, -0.0130, -0.0457],\n",
       "                       [ 0.0150,  0.0194,  0.0599,  ...,  0.0790,  0.0221,  0.0251]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.3.fc1.bias',\n",
       "               tensor([-0.0468, -0.0130, -0.0258,  ..., -0.0229, -0.0072, -0.0611])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.3.fc2.weight',\n",
       "               tensor([[-0.0467,  0.0681, -0.0204,  ..., -0.0476,  0.0140, -0.0729],\n",
       "                       [ 0.0807, -0.0864, -0.0555,  ...,  0.0152, -0.0042,  0.0422],\n",
       "                       [ 0.0079, -0.1219,  0.0174,  ...,  0.0721,  0.0147, -0.0202],\n",
       "                       ...,\n",
       "                       [-0.0558, -0.1249,  0.0543,  ...,  0.0184, -0.0484, -0.0063],\n",
       "                       [ 0.0183, -0.0011,  0.0034,  ...,  0.0664, -0.0155, -0.0007],\n",
       "                       [ 0.0129,  0.0422,  0.0486,  ...,  0.1108,  0.0290, -0.0457]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.3.fc2.bias',\n",
       "               tensor([ 0.0131,  0.0106,  0.0111,  ..., -0.0500, -0.0228, -0.0194])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.3.final_layer_norm.weight',\n",
       "               tensor([0.0464, 0.0525, 0.1672,  ..., 0.3135, 0.5791, 0.0829])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.3.final_layer_norm.bias',\n",
       "               tensor([ 0.0034,  0.0156, -0.0091,  ...,  0.1328,  0.0239, -0.0430])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.4.self_attn.k_proj.weight',\n",
       "               tensor([[ 0.0574,  0.0011, -0.1018,  ...,  0.0715, -0.0427, -0.1519],\n",
       "                       [-0.0400, -0.1357, -0.1903,  ...,  0.0350, -0.0032,  0.1923],\n",
       "                       [-0.0724,  0.0966,  0.0932,  ..., -0.0324, -0.1119,  0.0453],\n",
       "                       ...,\n",
       "                       [ 0.0637,  0.0171, -0.0394,  ...,  0.0109, -0.0838,  0.1378],\n",
       "                       [-0.0388,  0.1186,  0.1015,  ...,  0.0035, -0.0421, -0.1335],\n",
       "                       [ 0.0335,  0.0030, -0.0838,  ..., -0.0856,  0.0077, -0.1725]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.4.self_attn.k_proj.bias',\n",
       "               tensor([-6.5689e-03,  9.8343e-03, -9.6817e-03,  ...,  7.3671e-05,\n",
       "                       -6.0616e-03, -1.0042e-03])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.4.self_attn.v_proj.weight',\n",
       "               tensor([[-1.8951e-02,  1.6388e-02, -6.4758e-02,  ..., -1.8219e-02,\n",
       "                         3.8300e-02,  8.0872e-02],\n",
       "                       [-6.5308e-02,  3.4302e-02,  1.0046e-01,  ..., -3.8757e-02,\n",
       "                        -7.0419e-03, -1.0046e-01],\n",
       "                       [-4.2236e-02,  1.2280e-01,  6.7673e-03,  ...,  2.4765e-02,\n",
       "                         1.9073e-03, -3.0029e-02],\n",
       "                       ...,\n",
       "                       [ 2.1835e-02,  6.5369e-02,  4.5700e-03,  ...,  8.9264e-03,\n",
       "                         9.6130e-03, -1.3367e-01],\n",
       "                       [ 1.2192e-02, -1.1490e-02, -6.6872e-03,  ..., -3.0327e-03,\n",
       "                        -4.1351e-02, -6.6895e-02],\n",
       "                       [ 1.7288e-02, -4.1321e-02, -1.0199e-01,  ..., -6.5565e-06,\n",
       "                         1.7426e-02,  4.1199e-03]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.4.self_attn.v_proj.bias',\n",
       "               tensor([ 0.0106,  0.0101, -0.0015,  ..., -0.0165,  0.0139, -0.0072])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.4.self_attn.q_proj.weight',\n",
       "               tensor([[ 0.0258, -0.1910, -0.1327,  ...,  0.0028, -0.0493,  0.1884],\n",
       "                       [-0.0070,  0.1676,  0.0178,  ..., -0.1274,  0.0179,  0.0946],\n",
       "                       [ 0.0424,  0.0646,  0.1017,  ...,  0.0454, -0.0311,  0.1066],\n",
       "                       ...,\n",
       "                       [-0.0800,  0.0414,  0.0722,  ...,  0.0530, -0.0036, -0.0255],\n",
       "                       [-0.1591,  0.0778,  0.1385,  ..., -0.0228, -0.0274,  0.0147],\n",
       "                       [-0.0265, -0.0359, -0.0427,  ..., -0.1111, -0.0912, -0.0205]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.4.self_attn.q_proj.bias',\n",
       "               tensor([-0.0699, -0.1469, -0.0402,  ...,  0.1307, -0.0466, -0.0750])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.4.self_attn.out_proj.weight',\n",
       "               tensor([[ 0.0481, -0.1083,  0.0038,  ..., -0.0471,  0.0843, -0.0902],\n",
       "                       [-0.0344,  0.0049, -0.0714,  ..., -0.0891, -0.0019,  0.1150],\n",
       "                       [-0.0249, -0.0142,  0.0570,  ..., -0.0493,  0.0186, -0.0103],\n",
       "                       ...,\n",
       "                       [ 0.0142, -0.0627,  0.0560,  ...,  0.0152, -0.0003, -0.0226],\n",
       "                       [ 0.0080, -0.0018,  0.0474,  ..., -0.0110,  0.0076,  0.0056],\n",
       "                       [-0.0204, -0.0720,  0.0032,  ...,  0.0407,  0.0017,  0.0353]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.4.self_attn.out_proj.bias',\n",
       "               tensor([ 0.0671,  0.1356, -0.0528,  ..., -0.0719, -0.0046, -0.2379])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.4.self_attn_layer_norm.weight',\n",
       "               tensor([0.1088, 0.1251, 0.2335,  ..., 0.4626, 0.4783, 0.1366])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.4.self_attn_layer_norm.bias',\n",
       "               tensor([ 0.3413,  0.2939, -0.1077,  ..., -0.2715, -0.3638, -0.2581])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.4.fc1.weight',\n",
       "               tensor([[-0.0252, -0.0021, -0.0281,  ...,  0.0251,  0.0048,  0.0474],\n",
       "                       [-0.0408,  0.0094,  0.0561,  ...,  0.0158, -0.0512,  0.0522],\n",
       "                       [-0.0450, -0.0097,  0.0517,  ...,  0.0249, -0.0667, -0.0390],\n",
       "                       ...,\n",
       "                       [-0.0335,  0.0170, -0.0553,  ..., -0.0873,  0.0013, -0.0233],\n",
       "                       [-0.0176, -0.0183,  0.0112,  ...,  0.0054, -0.0296,  0.0740],\n",
       "                       [-0.0104,  0.0061,  0.0037,  ..., -0.0304, -0.1444, -0.0012]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.4.fc1.bias',\n",
       "               tensor([0.0073, 0.0208, 0.0055,  ..., 0.0175, 0.0089, 0.0283])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.4.fc2.weight',\n",
       "               tensor([[-0.0131, -0.0601,  0.0253,  ...,  0.0131, -0.0384, -0.0180],\n",
       "                       [-0.0338, -0.0039,  0.0894,  ..., -0.0197,  0.0030, -0.0102],\n",
       "                       [-0.0158, -0.0840,  0.0164,  ...,  0.0880, -0.0172,  0.0348],\n",
       "                       ...,\n",
       "                       [-0.0432,  0.0460,  0.0756,  ...,  0.0731, -0.0958,  0.0195],\n",
       "                       [-0.0308, -0.0352, -0.0345,  ..., -0.0524, -0.0195,  0.0415],\n",
       "                       [ 0.0111,  0.1060,  0.0036,  ..., -0.0298,  0.0062, -0.0408]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.4.fc2.bias',\n",
       "               tensor([-0.0344, -0.0071,  0.0407,  ..., -0.0151, -0.0207,  0.0069])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.4.final_layer_norm.weight',\n",
       "               tensor([0.0707, 0.0807, 0.1617,  ..., 0.3503, 0.5474, 0.0667])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.4.final_layer_norm.bias',\n",
       "               tensor([-0.0330, -0.0148,  0.0384,  ...,  0.1672,  0.2898,  0.0133])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.5.self_attn.k_proj.weight',\n",
       "               tensor([[ 0.1067,  0.0258, -0.0616,  ..., -0.0159,  0.0328,  0.0704],\n",
       "                       [ 0.0346, -0.1094, -0.1122,  ..., -0.2419, -0.0060,  0.0365],\n",
       "                       [ 0.0108, -0.0095, -0.1411,  ..., -0.0972,  0.0535,  0.0544],\n",
       "                       ...,\n",
       "                       [-0.0853, -0.0891, -0.0319,  ...,  0.0741,  0.0284,  0.0224],\n",
       "                       [ 0.0607,  0.0263,  0.1279,  ...,  0.1708, -0.0719,  0.0341],\n",
       "                       [-0.0938, -0.0635,  0.0050,  ..., -0.0263, -0.0822,  0.0416]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.5.self_attn.k_proj.bias',\n",
       "               tensor([ 0.0133, -0.0065, -0.0130,  ...,  0.0071,  0.0179,  0.0185])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.5.self_attn.v_proj.weight',\n",
       "               tensor([[-0.0548, -0.1873,  0.0542,  ...,  0.0054,  0.0719,  0.0546],\n",
       "                       [ 0.0180, -0.0746,  0.0564,  ...,  0.0196, -0.1166, -0.0008],\n",
       "                       [-0.1335,  0.0425, -0.0641,  ...,  0.0881,  0.0226,  0.0524],\n",
       "                       ...,\n",
       "                       [ 0.0532, -0.0007,  0.0764,  ...,  0.0763,  0.0439, -0.0432],\n",
       "                       [-0.0183, -0.0575, -0.0101,  ...,  0.0197,  0.0309,  0.0806],\n",
       "                       [-0.1171,  0.1450, -0.0452,  ..., -0.0653,  0.0492, -0.0635]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.5.self_attn.v_proj.bias',\n",
       "               tensor([-0.0245, -0.0033, -0.0013,  ...,  0.0260, -0.0257,  0.0326])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.5.self_attn.q_proj.weight',\n",
       "               tensor([[-0.0150,  0.1211, -0.1379,  ..., -0.2668, -0.0101, -0.0166],\n",
       "                       [-0.0527,  0.0583, -0.1417,  ...,  0.0531, -0.0231, -0.0189],\n",
       "                       [ 0.0677, -0.0077,  0.0676,  ...,  0.0575, -0.0529, -0.0500],\n",
       "                       ...,\n",
       "                       [-0.0072, -0.0714, -0.0369,  ...,  0.0075,  0.0461, -0.1307],\n",
       "                       [-0.0928, -0.1381,  0.0926,  ...,  0.0248, -0.1035,  0.0945],\n",
       "                       [-0.0698,  0.0634,  0.0307,  ..., -0.0166, -0.1044, -0.0079]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.5.self_attn.q_proj.bias',\n",
       "               tensor([-0.0235, -0.0113,  0.1586,  ..., -0.1685, -0.1306, -0.2180])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.5.self_attn.out_proj.weight',\n",
       "               tensor([[ 0.0206,  0.0885, -0.0359,  ..., -0.0079, -0.0183, -0.0340],\n",
       "                       [ 0.0596,  0.0602,  0.0427,  ...,  0.0016, -0.1061, -0.0302],\n",
       "                       [ 0.0015, -0.0312, -0.0450,  ..., -0.0343, -0.0621, -0.0320],\n",
       "                       ...,\n",
       "                       [-0.0921,  0.0499, -0.0275,  ..., -0.0448,  0.0207, -0.0178],\n",
       "                       [ 0.0239,  0.0375, -0.0161,  ..., -0.0620, -0.0257, -0.0118],\n",
       "                       [-0.1976, -0.0416,  0.1381,  ..., -0.1207,  0.1555,  0.0114]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.5.self_attn.out_proj.bias',\n",
       "               tensor([ 0.0204,  0.0597, -0.0695,  ..., -0.0733, -0.0295,  0.0995])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.5.self_attn_layer_norm.weight',\n",
       "               tensor([0.1227, 0.1196, 0.2180,  ..., 0.4800, 0.5327, 0.1266])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.5.self_attn_layer_norm.bias',\n",
       "               tensor([ 0.2585,  0.3645, -0.1555,  ..., -0.2668, -0.3154,  0.2729])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.5.fc1.weight',\n",
       "               tensor([[-0.1144, -0.0113,  0.0100,  ..., -0.0059,  0.0733, -0.0961],\n",
       "                       [ 0.0043, -0.0417,  0.0365,  ..., -0.0369, -0.0606, -0.0487],\n",
       "                       [ 0.0408,  0.0295,  0.0055,  ...,  0.0149, -0.0207, -0.0413],\n",
       "                       ...,\n",
       "                       [ 0.0014, -0.0745,  0.0150,  ..., -0.0051,  0.0747,  0.0060],\n",
       "                       [-0.0401,  0.0015,  0.0465,  ...,  0.1146,  0.2413, -0.0981],\n",
       "                       [-0.0246, -0.0291,  0.0609,  ...,  0.0528, -0.0225, -0.0067]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.5.fc1.bias',\n",
       "               tensor([-0.0015,  0.0123,  0.0182,  ..., -0.0133, -0.0143, -0.0317])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.5.fc2.weight',\n",
       "               tensor([[ 0.0142, -0.0154,  0.0575,  ...,  0.0093,  0.0132,  0.0100],\n",
       "                       [-0.1555,  0.0371,  0.0394,  ...,  0.2106,  0.0953, -0.0091],\n",
       "                       [-0.0806, -0.0750, -0.0539,  ...,  0.1261, -0.0718, -0.0072],\n",
       "                       ...,\n",
       "                       [-0.0250,  0.1119, -0.0046,  ..., -0.1245, -0.0040, -0.0065],\n",
       "                       [-0.0039, -0.0333,  0.0036,  ...,  0.0135, -0.0063,  0.0360],\n",
       "                       [-0.0047, -0.0445, -0.1233,  ...,  0.0341, -0.0487,  0.0054]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.5.fc2.bias',\n",
       "               tensor([-0.0110, -0.0289, -0.0158,  ...,  0.0110, -0.0047, -0.0147])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.5.final_layer_norm.weight',\n",
       "               tensor([0.1071, 0.0980, 0.1859,  ..., 0.3325, 0.5254, 0.0954])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.5.final_layer_norm.bias',\n",
       "               tensor([-0.0180, -0.0161,  0.0361,  ...,  0.1362,  0.2322, -0.0117])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.6.self_attn.k_proj.weight',\n",
       "               tensor([[ 0.0201,  0.1074,  0.0012,  ..., -0.0416,  0.0767, -0.0247],\n",
       "                       [-0.0172, -0.0952, -0.0067,  ..., -0.0638,  0.0172, -0.0259],\n",
       "                       [ 0.0296,  0.0061,  0.1016,  ...,  0.1396,  0.3105,  0.0532],\n",
       "                       ...,\n",
       "                       [-0.1188,  0.0657,  0.0259,  ...,  0.0604,  0.0100,  0.1135],\n",
       "                       [ 0.0940,  0.0790, -0.0699,  ..., -0.0027,  0.0111,  0.0282],\n",
       "                       [ 0.0542,  0.0054, -0.0205,  ..., -0.0619,  0.0068,  0.0045]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.6.self_attn.k_proj.bias',\n",
       "               tensor([-0.0559, -0.0276, -0.0147,  ..., -0.0034, -0.0152,  0.0164])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.6.self_attn.v_proj.weight',\n",
       "               tensor([[-0.0085, -0.0646,  0.0357,  ..., -0.0142, -0.0177,  0.0246],\n",
       "                       [ 0.0003, -0.0977,  0.0118,  ...,  0.0227,  0.0112, -0.0056],\n",
       "                       [-0.0122, -0.0117, -0.0047,  ..., -0.0072, -0.0083, -0.0914],\n",
       "                       ...,\n",
       "                       [ 0.0323, -0.0361,  0.0364,  ...,  0.0948, -0.1080,  0.0526],\n",
       "                       [-0.0749, -0.0886, -0.0343,  ..., -0.0036, -0.0596, -0.0060],\n",
       "                       [ 0.0074,  0.0179, -0.0072,  ..., -0.0077,  0.0595, -0.0230]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.6.self_attn.v_proj.bias',\n",
       "               tensor([ 0.0210,  0.0061,  0.0174,  ..., -0.0163,  0.0164,  0.0035])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.6.self_attn.q_proj.weight',\n",
       "               tensor([[-0.0991,  0.0645,  0.0526,  ..., -0.2512,  0.0813, -0.0615],\n",
       "                       [-0.0506, -0.0797, -0.0469,  ..., -0.0410,  0.0066, -0.0109],\n",
       "                       [-0.0664, -0.0354, -0.0378,  ...,  0.1002,  0.2871,  0.0853],\n",
       "                       ...,\n",
       "                       [-0.0379, -0.0803, -0.0860,  ..., -0.2081, -0.0834, -0.0270],\n",
       "                       [ 0.1194,  0.0023,  0.0359,  ..., -0.0676,  0.0445, -0.1309],\n",
       "                       [-0.0534,  0.0259,  0.0295,  ..., -0.1421, -0.1870,  0.0603]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.6.self_attn.q_proj.bias',\n",
       "               tensor([-0.2671, -0.0856,  0.2333,  ..., -0.0638, -0.2357,  0.2678])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.6.self_attn.out_proj.weight',\n",
       "               tensor([[-0.0059,  0.0467, -0.0528,  ...,  0.0806, -0.0101, -0.0307],\n",
       "                       [-0.0333,  0.0757, -0.0097,  ...,  0.0441, -0.0500,  0.0729],\n",
       "                       [-0.0160, -0.0058, -0.0878,  ..., -0.0320, -0.0432, -0.0697],\n",
       "                       ...,\n",
       "                       [-0.0198,  0.0518, -0.0671,  ..., -0.1064,  0.0958,  0.0102],\n",
       "                       [ 0.0042, -0.0274,  0.0300,  ...,  0.0298, -0.0302, -0.0328],\n",
       "                       [-0.0193,  0.0258, -0.0740,  ...,  0.0103,  0.0833, -0.0433]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.6.self_attn.out_proj.bias',\n",
       "               tensor([ 0.0648, -0.1268, -0.0500,  ..., -0.0626, -0.0067, -0.0237])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.6.self_attn_layer_norm.weight',\n",
       "               tensor([0.1410, 0.1501, 0.2664,  ..., 0.3728, 0.4988, 0.1271])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.6.self_attn_layer_norm.bias',\n",
       "               tensor([ 0.0991, -0.2307, -0.1832,  ..., -0.1813, -0.2421,  0.0519])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.6.fc1.weight',\n",
       "               tensor([[ 0.0651,  0.0324,  0.0820,  ..., -0.0619,  0.0432,  0.0897],\n",
       "                       [-0.0936,  0.0720,  0.0523,  ..., -0.0225, -0.1359,  0.0336],\n",
       "                       [ 0.0516, -0.0076, -0.0548,  ...,  0.0148, -0.0092,  0.0301],\n",
       "                       ...,\n",
       "                       [-0.0535,  0.0449, -0.1215,  ...,  0.0193, -0.0893,  0.0018],\n",
       "                       [-0.0211, -0.0401,  0.0353,  ...,  0.0047,  0.0228,  0.0775],\n",
       "                       [-0.0502, -0.1057, -0.0461,  ...,  0.0339, -0.0513,  0.0286]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.6.fc1.bias',\n",
       "               tensor([-0.0059, -0.0130, -0.0220,  ...,  0.0059, -0.0301, -0.0206])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.6.fc2.weight',\n",
       "               tensor([[-0.0317, -0.0905, -0.0276,  ...,  0.1265,  0.0941, -0.0671],\n",
       "                       [-0.0565,  0.1438,  0.0864,  ...,  0.0756, -0.0444, -0.1355],\n",
       "                       [ 0.0669,  0.0464,  0.0335,  ..., -0.0403,  0.1192, -0.0261],\n",
       "                       ...,\n",
       "                       [ 0.0801, -0.0031, -0.1411,  ...,  0.0264,  0.0766,  0.1137],\n",
       "                       [ 0.0314, -0.0172, -0.0014,  ..., -0.0215,  0.0209, -0.0012],\n",
       "                       [ 0.1122, -0.0787, -0.0538,  ...,  0.0924, -0.0034, -0.0537]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.6.fc2.bias',\n",
       "               tensor([ 0.0284,  0.0134,  0.0114,  ..., -0.0286, -0.0227,  0.0158])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.6.final_layer_norm.weight',\n",
       "               tensor([0.1119, 0.0978, 0.1660,  ..., 0.3958, 0.6353, 0.1103])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.6.final_layer_norm.bias',\n",
       "               tensor([-0.0112,  0.0174,  0.0380,  ...,  0.0832,  0.1715, -0.0170])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.7.self_attn.k_proj.weight',\n",
       "               tensor([[ 0.0772, -0.0501,  0.0195,  ..., -0.1714,  0.1278,  0.1316],\n",
       "                       [-0.1236, -0.1578,  0.1505,  ...,  0.0151, -0.1500, -0.0756],\n",
       "                       [ 0.1039,  0.0740,  0.0015,  ...,  0.1300,  0.0336, -0.1068],\n",
       "                       ...,\n",
       "                       [-0.0132,  0.0480, -0.0091,  ...,  0.0844, -0.0072,  0.1606],\n",
       "                       [-0.0847,  0.0035, -0.1323,  ...,  0.1473, -0.1749,  0.0745],\n",
       "                       [ 0.2255,  0.0561,  0.0729,  ..., -0.1864, -0.0291,  0.0007]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.7.self_attn.k_proj.bias',\n",
       "               tensor([-0.0117, -0.0120,  0.0088,  ..., -0.0284, -0.1027, -0.0745])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.7.self_attn.v_proj.weight',\n",
       "               tensor([[-0.0892, -0.0759,  0.0181,  ..., -0.0304, -0.0502,  0.0351],\n",
       "                       [ 0.0100, -0.0349,  0.0038,  ...,  0.0789,  0.0495, -0.0576],\n",
       "                       [-0.0847, -0.0490, -0.0814,  ...,  0.0212, -0.0334, -0.0023],\n",
       "                       ...,\n",
       "                       [-0.0305, -0.0662, -0.0789,  ...,  0.0216, -0.0174, -0.0309],\n",
       "                       [-0.0415, -0.0117,  0.0219,  ..., -0.0782, -0.0468,  0.0565],\n",
       "                       [ 0.0520,  0.0588, -0.0482,  ..., -0.0117,  0.0128, -0.0571]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.7.self_attn.v_proj.bias',\n",
       "               tensor([0.0348, 0.0365, 0.0062,  ..., 0.0195, 0.0325, 0.0343])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.7.self_attn.q_proj.weight',\n",
       "               tensor([[ 0.1231,  0.0886, -0.0774,  ..., -0.0191, -0.0625,  0.1084],\n",
       "                       [ 0.1504,  0.0467, -0.2664,  ..., -0.0127,  0.1395, -0.2161],\n",
       "                       [ 0.0248,  0.0827,  0.0038,  ..., -0.0357, -0.0269, -0.0023],\n",
       "                       ...,\n",
       "                       [-0.0257,  0.0266,  0.0321,  ..., -0.1033, -0.1038,  0.0710],\n",
       "                       [-0.2426, -0.0026, -0.0664,  ..., -0.0279,  0.0734, -0.0751],\n",
       "                       [-0.0851, -0.0363, -0.1318,  ..., -0.0872, -0.2195,  0.1068]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.7.self_attn.q_proj.bias',\n",
       "               tensor([ 0.1471, -0.1072,  0.0177,  ...,  0.0847, -0.2224,  0.1971])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.7.self_attn.out_proj.weight',\n",
       "               tensor([[-0.0322,  0.0519,  0.0468,  ..., -0.0271, -0.0094,  0.1000],\n",
       "                       [-0.0281,  0.1266,  0.1356,  ...,  0.0110,  0.0618, -0.0718],\n",
       "                       [-0.0063, -0.1039, -0.0594,  ..., -0.0394,  0.0782, -0.0195],\n",
       "                       ...,\n",
       "                       [ 0.0387, -0.0085,  0.0509,  ...,  0.0161,  0.0019,  0.1062],\n",
       "                       [-0.0168, -0.0018,  0.0555,  ..., -0.0018, -0.0723,  0.0471],\n",
       "                       [-0.0032,  0.0015,  0.0394,  ..., -0.0101, -0.0576,  0.0081]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.7.self_attn.out_proj.bias',\n",
       "               tensor([ 0.0732,  0.0052, -0.0836,  ..., -0.0483, -0.0595, -0.0693])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.7.self_attn_layer_norm.weight',\n",
       "               tensor([0.1506, 0.0873, 0.1965,  ..., 0.4519, 0.5698, 0.1298])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.7.self_attn_layer_norm.bias',\n",
       "               tensor([ 0.1931, -0.0753, -0.1595,  ..., -0.0601, -0.2971, -0.1388])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.7.fc1.weight',\n",
       "               tensor([[-0.0710,  0.0176, -0.0544,  ..., -0.0402, -0.0461, -0.0043],\n",
       "                       [-0.1298,  0.0215, -0.0154,  ...,  0.0608, -0.0562,  0.0005],\n",
       "                       [ 0.0986,  0.0596,  0.0637,  ..., -0.0184, -0.1151, -0.1566],\n",
       "                       ...,\n",
       "                       [ 0.1973, -0.0988, -0.0023,  ..., -0.0981, -0.1176, -0.0110],\n",
       "                       [-0.0609, -0.0163,  0.0230,  ..., -0.1256,  0.1649, -0.0576],\n",
       "                       [-0.0046,  0.0515, -0.1595,  ...,  0.0947, -0.0259, -0.0699]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.7.fc1.bias',\n",
       "               tensor([-0.0121, -0.0260, -0.0119,  ..., -0.0076, -0.0138, -0.0095])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.7.fc2.weight',\n",
       "               tensor([[ 8.6243e-02,  2.1802e-01,  1.3306e-01,  ..., -2.2308e-02,\n",
       "                        -2.0920e-02,  1.0691e-03],\n",
       "                       [ 3.2349e-03, -3.7598e-02,  2.3376e-02,  ..., -1.7554e-01,\n",
       "                        -3.4241e-02,  2.5375e-02],\n",
       "                       [ 1.4526e-02,  4.7394e-02,  2.2424e-01,  ..., -2.8473e-02,\n",
       "                         2.9495e-02,  3.1372e-02],\n",
       "                       ...,\n",
       "                       [-5.0171e-02, -1.4706e-03,  1.6724e-02,  ...,  3.9291e-03,\n",
       "                        -1.2337e-02, -1.7822e-04],\n",
       "                       [ 1.7609e-02, -1.0785e-01,  5.9906e-02,  ..., -7.6660e-02,\n",
       "                        -3.7811e-02, -4.1046e-02],\n",
       "                       [ 1.1176e-01,  4.6600e-02,  8.7280e-02,  ..., -2.1375e-01,\n",
       "                         2.6993e-02, -9.3201e-02]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.7.fc2.bias',\n",
       "               tensor([ 0.0160, -0.0247,  0.0142,  ..., -0.0169, -0.0249,  0.0110])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.7.final_layer_norm.weight',\n",
       "               tensor([0.1738, 0.0828, 0.1868,  ..., 0.3760, 0.4963, 0.1459])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.7.final_layer_norm.bias',\n",
       "               tensor([-0.0284,  0.0241,  0.0268,  ...,  0.0322,  0.1833,  0.0069])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.8.self_attn.k_proj.weight',\n",
       "               tensor([[ 1.7838e-02,  8.0566e-02,  1.0391e-02,  ...,  1.1877e-01,\n",
       "                         4.0192e-02, -9.4055e-02],\n",
       "                       [ 6.4392e-02, -1.3867e-01, -7.8613e-02,  ..., -5.8990e-02,\n",
       "                        -9.4604e-03,  1.3550e-01],\n",
       "                       [ 1.2964e-01,  1.3435e-02, -2.1317e-02,  ...,  3.8300e-02,\n",
       "                        -3.3936e-02,  8.4717e-02],\n",
       "                       ...,\n",
       "                       [ 1.5820e-01,  1.0138e-01, -1.0292e-02,  ..., -1.2302e-04,\n",
       "                         8.5876e-02,  3.9490e-02],\n",
       "                       [ 2.3300e-02, -6.6345e-02,  6.8848e-02,  ..., -1.8701e-01,\n",
       "                        -8.4900e-02, -1.7798e-01],\n",
       "                       [-1.1157e-01,  1.1591e-01, -1.1481e-01,  ..., -1.0815e-01,\n",
       "                         4.0131e-02, -2.0301e-04]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.8.self_attn.k_proj.bias',\n",
       "               tensor([ 0.0066,  0.0057,  0.0157,  ...,  0.0280, -0.0082, -0.0234])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.8.self_attn.v_proj.weight',\n",
       "               tensor([[-0.0094,  0.0326, -0.0584,  ..., -0.0228, -0.0014, -0.0610],\n",
       "                       [ 0.0167,  0.0182,  0.0729,  ..., -0.0014,  0.0373,  0.1013],\n",
       "                       [-0.0391, -0.0035, -0.0025,  ...,  0.0434,  0.0103, -0.0900],\n",
       "                       ...,\n",
       "                       [-0.0481,  0.0442,  0.0331,  ...,  0.0421,  0.0953, -0.0207],\n",
       "                       [-0.0320, -0.0519, -0.0376,  ..., -0.1559, -0.0502,  0.0519],\n",
       "                       [-0.0369,  0.0416, -0.0729,  ...,  0.0335, -0.0175,  0.0240]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.8.self_attn.v_proj.bias',\n",
       "               tensor([-0.0007, -0.0003, -0.0014,  ..., -0.0103,  0.0241,  0.0104])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.8.self_attn.q_proj.weight',\n",
       "               tensor([[-0.1416,  0.1476, -0.0952,  ...,  0.1370, -0.0443, -0.0964],\n",
       "                       [-0.1285,  0.1333, -0.0460,  ..., -0.0416, -0.1752, -0.0900],\n",
       "                       [ 0.0148, -0.0103,  0.0164,  ...,  0.0428, -0.1118, -0.0981],\n",
       "                       ...,\n",
       "                       [-0.1532, -0.1626, -0.0520,  ...,  0.0053, -0.0012, -0.1104],\n",
       "                       [-0.0668, -0.0309,  0.0938,  ..., -0.0377, -0.0659,  0.1616],\n",
       "                       [-0.0529,  0.1403, -0.1029,  ..., -0.0178, -0.0958, -0.0508]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.8.self_attn.q_proj.bias',\n",
       "               tensor([ 0.2227, -0.0980,  0.0837,  ..., -0.1194,  0.1426, -0.1064])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.8.self_attn.out_proj.weight',\n",
       "               tensor([[-0.1101, -0.0945,  0.0006,  ...,  0.0565, -0.0464,  0.0358],\n",
       "                       [ 0.0711, -0.0856, -0.0586,  ...,  0.0566,  0.0622, -0.0365],\n",
       "                       [-0.0098, -0.0775,  0.0459,  ..., -0.1185, -0.0717,  0.0820],\n",
       "                       ...,\n",
       "                       [-0.0017,  0.0404,  0.0467,  ..., -0.0421,  0.0629,  0.0130],\n",
       "                       [ 0.0039, -0.0340,  0.0078,  ...,  0.0121,  0.0427, -0.0504],\n",
       "                       [ 0.0083,  0.0358,  0.1124,  ..., -0.0017,  0.0473,  0.0723]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.8.self_attn.out_proj.bias',\n",
       "               tensor([ 0.0201, -0.0115, -0.0323,  ..., -0.0065, -0.0061, -0.0146])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.8.self_attn_layer_norm.weight',\n",
       "               tensor([0.2130, 0.0832, 0.2141,  ..., 0.3901, 0.4546, 0.1687])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.8.self_attn_layer_norm.bias',\n",
       "               tensor([ 0.1320, -0.0599, -0.0726,  ..., -0.0330, -0.1442, -0.0508])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.8.fc1.weight',\n",
       "               tensor([[-0.0207,  0.0616, -0.1021,  ..., -0.0256, -0.1011, -0.0440],\n",
       "                       [ 0.0669,  0.0803,  0.1322,  ...,  0.1895, -0.0379,  0.2839],\n",
       "                       [ 0.1345, -0.0022, -0.0017,  ...,  0.1140, -0.1637,  0.1174],\n",
       "                       ...,\n",
       "                       [-0.0980,  0.0777,  0.0543,  ...,  0.2773,  0.0066, -0.0220],\n",
       "                       [-0.1637, -0.1422,  0.1018,  ...,  0.1089,  0.0272,  0.0434],\n",
       "                       [ 0.0137,  0.0577,  0.0798,  ...,  0.0329,  0.0116, -0.0360]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.8.fc1.bias',\n",
       "               tensor([ 0.0054, -0.0278, -0.0410,  ..., -0.0326, -0.0265, -0.0065])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.8.fc2.weight',\n",
       "               tensor([[ 0.0222, -0.1598, -0.0024,  ...,  0.0531, -0.0262, -0.0453],\n",
       "                       [ 0.0149,  0.0951, -0.0281,  ...,  0.0803, -0.0486, -0.0739],\n",
       "                       [-0.1052,  0.1318,  0.0130,  ..., -0.0143, -0.0366, -0.0250],\n",
       "                       ...,\n",
       "                       [ 0.0457,  0.1604,  0.0300,  ...,  0.0602, -0.0563,  0.0336],\n",
       "                       [-0.0414, -0.0808, -0.0265,  ...,  0.0112, -0.0003,  0.0693],\n",
       "                       [ 0.0925,  0.0216, -0.1456,  ..., -0.0219,  0.0376, -0.1138]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.8.fc2.bias',\n",
       "               tensor([ 0.0545, -0.0037,  0.0122,  ..., -0.0147, -0.0055, -0.0147])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.8.final_layer_norm.weight',\n",
       "               tensor([0.1317, 0.0867, 0.1516,  ..., 0.5024, 0.5806, 0.1058])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.8.final_layer_norm.bias',\n",
       "               tensor([-0.0282, -0.0025,  0.0107,  ...,  0.0170,  0.1089, -0.0029])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.9.self_attn.k_proj.weight',\n",
       "               tensor([[ 0.0469,  0.1237,  0.0681,  ...,  0.0504, -0.1042, -0.0355],\n",
       "                       [-0.0972,  0.0178, -0.0304,  ..., -0.2659,  0.2913, -0.1225],\n",
       "                       [ 0.0617, -0.0136,  0.0489,  ...,  0.0263, -0.0215,  0.1027],\n",
       "                       ...,\n",
       "                       [-0.0419,  0.1040, -0.1362,  ...,  0.0419,  0.0553, -0.0687],\n",
       "                       [ 0.0068, -0.1284, -0.0787,  ...,  0.0211, -0.1597, -0.1512],\n",
       "                       [ 0.2389,  0.0680, -0.0913,  ...,  0.1270,  0.0799,  0.0315]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.9.self_attn.k_proj.bias',\n",
       "               tensor([ 0.0182,  0.0581, -0.0935,  ...,  0.2426, -0.4248,  0.0482])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.9.self_attn.v_proj.weight',\n",
       "               tensor([[-0.0404,  0.0508, -0.0709,  ...,  0.0062, -0.1188,  0.0016],\n",
       "                       [ 0.0481,  0.0058, -0.0354,  ..., -0.0098, -0.0253,  0.0067],\n",
       "                       [-0.0952,  0.0049,  0.0605,  ..., -0.0117,  0.0266, -0.0027],\n",
       "                       ...,\n",
       "                       [-0.0135,  0.0040,  0.0955,  ...,  0.0225, -0.0203,  0.1225],\n",
       "                       [-0.0339,  0.1311, -0.1044,  ...,  0.0378,  0.0724,  0.0670],\n",
       "                       [ 0.0568,  0.0256,  0.0287,  ..., -0.0286, -0.0096,  0.0290]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.9.self_attn.v_proj.bias',\n",
       "               tensor([ 0.0373,  0.0064, -0.0828,  ...,  0.0654, -0.0227,  0.0205])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.9.self_attn.q_proj.weight',\n",
       "               tensor([[ 0.1317,  0.1123,  0.0108,  ...,  0.0778, -0.0591, -0.0681],\n",
       "                       [-0.0316, -0.1198,  0.0354,  ..., -0.0975,  0.0881, -0.1354],\n",
       "                       [-0.0291, -0.0059, -0.0475,  ..., -0.1852,  0.0039,  0.0502],\n",
       "                       ...,\n",
       "                       [ 0.0367, -0.0886,  0.0851,  ...,  0.1840,  0.1334,  0.0061],\n",
       "                       [-0.0239,  0.1567, -0.0627,  ...,  0.0850, -0.0680, -0.1061],\n",
       "                       [-0.1053, -0.0847,  0.0918,  ...,  0.1338,  0.0969,  0.0338]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.9.self_attn.q_proj.bias',\n",
       "               tensor([-0.0594, -0.0920, -0.2930,  ...,  0.1594, -0.4746,  0.2140])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.9.self_attn.out_proj.weight',\n",
       "               tensor([[ 0.0432,  0.0709,  0.0772,  ..., -0.0144, -0.1153, -0.0661],\n",
       "                       [ 0.0059, -0.1074, -0.0840,  ...,  0.0846,  0.0370,  0.0832],\n",
       "                       [-0.0200, -0.0440,  0.0453,  ..., -0.0112, -0.1595, -0.0458],\n",
       "                       ...,\n",
       "                       [ 0.0214, -0.0373, -0.0170,  ..., -0.0101, -0.0093,  0.1041],\n",
       "                       [-0.0066, -0.0074,  0.0535,  ..., -0.0035,  0.0175, -0.0165],\n",
       "                       [-0.0685,  0.0408,  0.0353,  ..., -0.0612, -0.0129, -0.0208]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.9.self_attn.out_proj.bias',\n",
       "               tensor([ 0.0869, -0.1794,  0.0613,  ..., -0.0426, -0.0280, -0.0707])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.9.self_attn_layer_norm.weight',\n",
       "               tensor([0.1643, 0.1768, 0.2346,  ..., 0.4956, 0.4966, 0.1583])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.9.self_attn_layer_norm.bias',\n",
       "               tensor([ 0.2191, -0.2727,  0.2095,  ...,  0.0409, -0.1566, -0.1946])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.9.fc1.weight',\n",
       "               tensor([[-0.1013, -0.0381, -0.0224,  ...,  0.0801,  0.0435,  0.0632],\n",
       "                       [-0.1537,  0.1072,  0.1647,  ...,  0.0587,  0.1151,  0.0024],\n",
       "                       [-0.1621,  0.0401,  0.0230,  ..., -0.1016,  0.0254, -0.0161],\n",
       "                       ...,\n",
       "                       [-0.0192,  0.0020, -0.0689,  ...,  0.0399,  0.0084, -0.0239],\n",
       "                       [-0.0224, -0.0153,  0.1154,  ..., -0.0857,  0.0490, -0.0162],\n",
       "                       [-0.0594,  0.0263, -0.0036,  ...,  0.1492, -0.0435, -0.0167]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.9.fc1.bias',\n",
       "               tensor([-0.0177, -0.0243, -0.0041,  ..., -0.0388, -0.0045, -0.0279])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.9.fc2.weight',\n",
       "               tensor([[-0.0472, -0.0812, -0.0374,  ...,  0.0342, -0.0640,  0.0908],\n",
       "                       [ 0.0109, -0.0682, -0.0501,  ...,  0.0267,  0.0298,  0.0626],\n",
       "                       [-0.0286, -0.0477, -0.0616,  ..., -0.0670, -0.0461, -0.2382],\n",
       "                       ...,\n",
       "                       [ 0.0318,  0.0148, -0.0434,  ..., -0.0082, -0.0391,  0.0529],\n",
       "                       [ 0.0021,  0.0223,  0.0477,  ...,  0.0516, -0.1130,  0.0097],\n",
       "                       [-0.0095, -0.0377,  0.0053,  ...,  0.0512,  0.0499, -0.0642]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.9.fc2.bias',\n",
       "               tensor([ 0.0288, -0.0282, -0.0014,  ...,  0.0198, -0.0442, -0.0203])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.9.final_layer_norm.weight',\n",
       "               tensor([0.1383, 0.1179, 0.1783,  ..., 0.5391, 0.4109, 0.1083])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.9.final_layer_norm.bias',\n",
       "               tensor([-0.0253,  0.0453, -0.0449,  ..., -0.0044,  0.0905,  0.0252])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.10.self_attn.k_proj.weight',\n",
       "               tensor([[ 0.0821, -0.0621,  0.0079,  ...,  0.0817,  0.1333,  0.0944],\n",
       "                       [ 0.0708, -0.2195, -0.0017,  ...,  0.0431,  0.0116,  0.0654],\n",
       "                       [-0.0412, -0.0632,  0.0082,  ..., -0.1066, -0.0190,  0.1768],\n",
       "                       ...,\n",
       "                       [-0.0251, -0.0643, -0.0851,  ..., -0.0191, -0.0232,  0.0468],\n",
       "                       [ 0.0289,  0.0403,  0.0042,  ...,  0.0394,  0.1049, -0.0004],\n",
       "                       [ 0.0494,  0.1255, -0.0878,  ...,  0.0486, -0.0251,  0.0713]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.10.self_attn.k_proj.bias',\n",
       "               tensor([-0.0104, -0.0092, -0.0165,  ..., -0.0086,  0.0119,  0.0363])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.10.self_attn.v_proj.weight',\n",
       "               tensor([[-0.0350, -0.0226, -0.0717,  ...,  0.0062, -0.0265,  0.0876],\n",
       "                       [ 0.0398,  0.0179,  0.0551,  ...,  0.0418, -0.0598, -0.0541],\n",
       "                       [ 0.0508,  0.0257,  0.0575,  ..., -0.0545, -0.0244,  0.0520],\n",
       "                       ...,\n",
       "                       [-0.0640, -0.0134, -0.0168,  ..., -0.0981, -0.0598, -0.0383],\n",
       "                       [ 0.0554, -0.0731, -0.0873,  ..., -0.0520,  0.0653,  0.0303],\n",
       "                       [ 0.0586, -0.1310, -0.0782,  ...,  0.0505, -0.1294, -0.0399]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.10.self_attn.v_proj.bias',\n",
       "               tensor([-0.0638,  0.0509, -0.0143,  ..., -0.0199,  0.0102, -0.0055])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.10.self_attn.q_proj.weight',\n",
       "               tensor([[ 0.0758, -0.0523, -0.0646,  ..., -0.0649, -0.0175,  0.1505],\n",
       "                       [-0.0088, -0.1244,  0.0562,  ..., -0.0987, -0.0285,  0.0127],\n",
       "                       [ 0.0356, -0.0218,  0.0045,  ...,  0.0132,  0.0236, -0.0266],\n",
       "                       ...,\n",
       "                       [-0.1392, -0.0604,  0.0055,  ...,  0.0708, -0.0210, -0.0711],\n",
       "                       [-0.0145,  0.0187,  0.1221,  ...,  0.0651,  0.1234, -0.0044],\n",
       "                       [ 0.0681, -0.0072, -0.1360,  ..., -0.0035, -0.1282, -0.1505]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.10.self_attn.q_proj.bias',\n",
       "               tensor([ 0.0140,  0.3386, -0.0786,  ...,  0.1517, -0.0152, -0.1050])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.10.self_attn.out_proj.weight',\n",
       "               tensor([[ 0.0251,  0.0075,  0.1138,  ...,  0.0488, -0.0394,  0.0598],\n",
       "                       [-0.0470,  0.0072, -0.0223,  ..., -0.0723, -0.0800,  0.0749],\n",
       "                       [-0.0760,  0.0349, -0.0218,  ...,  0.0017,  0.1014,  0.0057],\n",
       "                       ...,\n",
       "                       [-0.0536, -0.0255, -0.0091,  ..., -0.0239, -0.0030, -0.0359],\n",
       "                       [ 0.0508,  0.0821,  0.0414,  ..., -0.0595, -0.0143,  0.0242],\n",
       "                       [-0.0950,  0.0836, -0.0199,  ...,  0.0243, -0.0325,  0.0836]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.10.self_attn.out_proj.bias',\n",
       "               tensor([ 0.0559, -0.2218, -0.0227,  ..., -0.0285, -0.0831,  0.0448])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.10.self_attn_layer_norm.weight',\n",
       "               tensor([0.2019, 0.2136, 0.3455,  ..., 0.4998, 0.4609, 0.1774])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.10.self_attn_layer_norm.bias',\n",
       "               tensor([ 0.1069, -0.3025,  0.3418,  ...,  0.0530, -0.2871, -0.2749])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.10.fc1.weight',\n",
       "               tensor([[ 0.0636,  0.1146,  0.0703,  ...,  0.1421,  0.0934, -0.1240],\n",
       "                       [-0.0763,  0.0072,  0.0061,  ..., -0.0349,  0.0491, -0.0306],\n",
       "                       [ 0.0017,  0.0623,  0.0283,  ..., -0.0459,  0.0127, -0.0126],\n",
       "                       ...,\n",
       "                       [-0.0336, -0.1124,  0.0575,  ..., -0.0809,  0.0807, -0.1360],\n",
       "                       [-0.0057,  0.0943, -0.0134,  ...,  0.0485, -0.0344,  0.0825],\n",
       "                       [-0.0133,  0.0048, -0.0441,  ..., -0.0410,  0.0942,  0.0211]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.10.fc1.bias',\n",
       "               tensor([-0.0118,  0.0149, -0.0066,  ..., -0.0234, -0.0181, -0.0197])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.10.fc2.weight',\n",
       "               tensor([[-0.0235,  0.0834, -0.0058,  ...,  0.0177,  0.0130, -0.0348],\n",
       "                       [-0.1139,  0.0017, -0.0555,  ..., -0.4272,  0.1130, -0.0441],\n",
       "                       [ 0.0287,  0.0822, -0.0254,  ..., -0.0260, -0.0053, -0.0050],\n",
       "                       ...,\n",
       "                       [ 0.0873,  0.0236, -0.0285,  ...,  0.0192, -0.0233,  0.0282],\n",
       "                       [-0.0594, -0.0455, -0.0323,  ..., -0.0944, -0.0769, -0.0154],\n",
       "                       [ 0.0121, -0.0554,  0.0541,  ...,  0.0620,  0.1373, -0.0931]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.10.fc2.bias',\n",
       "               tensor([ 0.0200, -0.0047, -0.0042,  ..., -0.0031, -0.0286, -0.0155])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.10.final_layer_norm.weight',\n",
       "               tensor([0.2323, 0.1359, 0.2140,  ..., 0.5410, 0.2817, 0.1240])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.10.final_layer_norm.bias',\n",
       "               tensor([-0.0184,  0.0437, -0.0994,  ..., -0.0160,  0.1215,  0.0481])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.11.self_attn.k_proj.weight',\n",
       "               tensor([[ 0.0742,  0.0166, -0.1953,  ..., -0.0078,  0.0880,  0.0757],\n",
       "                       [ 0.0176,  0.0485, -0.0707,  ...,  0.0062,  0.1075, -0.0969],\n",
       "                       [ 0.1111, -0.0565,  0.0756,  ...,  0.0349, -0.0374, -0.1704],\n",
       "                       ...,\n",
       "                       [-0.0006,  0.1644, -0.0081,  ..., -0.0425,  0.0880,  0.0787],\n",
       "                       [ 0.0692,  0.0881,  0.0298,  ...,  0.0519,  0.0557,  0.0975],\n",
       "                       [ 0.0299, -0.0769,  0.0812,  ..., -0.0616,  0.0344,  0.1042]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.11.self_attn.k_proj.bias',\n",
       "               tensor([-0.1225,  0.0247,  0.0009,  ...,  0.0283,  0.0062, -0.0231])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.11.self_attn.v_proj.weight',\n",
       "               tensor([[ 5.6839e-03, -2.5894e-02, -4.3915e-02,  ..., -5.8228e-02,\n",
       "                        -3.0975e-02, -5.3955e-02],\n",
       "                       [-7.6843e-02, -4.3030e-02,  1.3206e-02,  ..., -3.9101e-03,\n",
       "                         2.6764e-02,  9.4727e-02],\n",
       "                       [-1.7929e-02,  3.5553e-02,  1.1780e-01,  ...,  4.6253e-05,\n",
       "                         6.0577e-02, -1.2047e-02],\n",
       "                       ...,\n",
       "                       [ 1.6541e-02,  6.4941e-02,  4.6906e-02,  ...,  6.1302e-03,\n",
       "                         6.7444e-02, -4.7333e-02],\n",
       "                       [-3.5156e-02, -3.4088e-02, -5.9891e-03,  ...,  1.7929e-04,\n",
       "                        -1.0201e-02, -8.1909e-02],\n",
       "                       [-2.2598e-02,  3.5156e-02,  7.9163e-02,  ...,  9.1553e-03,\n",
       "                         1.3374e-02, -8.5266e-02]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.11.self_attn.v_proj.bias',\n",
       "               tensor([-0.0017,  0.0018, -0.0004,  ..., -0.0225, -0.0014,  0.0069])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.11.self_attn.q_proj.weight',\n",
       "               tensor([[ 0.0262, -0.0970, -0.0966,  ...,  0.0954,  0.0670,  0.1920],\n",
       "                       [ 0.0039, -0.0888, -0.1228,  ..., -0.0223, -0.0505, -0.1294],\n",
       "                       [-0.0028, -0.0139, -0.0770,  ..., -0.0345, -0.1611, -0.1464],\n",
       "                       ...,\n",
       "                       [ 0.0776,  0.1793,  0.1221,  ..., -0.0537,  0.0242, -0.0073],\n",
       "                       [ 0.0851, -0.1442,  0.2103,  ..., -0.1121, -0.0679, -0.1431],\n",
       "                       [ 0.0997, -0.0884,  0.1553,  ..., -0.0885, -0.1003, -0.2085]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.11.self_attn.q_proj.bias',\n",
       "               tensor([ 0.4199,  0.0921,  0.0797,  ...,  0.1492,  0.0140, -0.0547])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.11.self_attn.out_proj.weight',\n",
       "               tensor([[ 1.2108e-02,  2.6459e-02, -9.8755e-02,  ..., -3.8666e-02,\n",
       "                        -9.0515e-02,  6.3049e-02],\n",
       "                       [-2.7100e-02, -4.7302e-02,  1.1015e-03,  ...,  8.4412e-02,\n",
       "                         2.4090e-03, -5.4810e-02],\n",
       "                       [-1.0651e-02, -2.6230e-02, -1.8021e-02,  ..., -2.1343e-03,\n",
       "                         3.6224e-02,  3.4027e-02],\n",
       "                       ...,\n",
       "                       [-1.3437e-03, -3.4580e-03, -1.7609e-02,  ..., -5.3497e-02,\n",
       "                        -2.5330e-02, -3.1799e-02],\n",
       "                       [ 8.2779e-03, -9.9640e-03,  3.7201e-02,  ...,  3.9577e-05,\n",
       "                        -6.5460e-03, -1.3914e-03],\n",
       "                       [-9.6619e-02,  1.9821e-02,  7.0679e-02,  ..., -7.5317e-02,\n",
       "                         1.8845e-02,  6.6162e-02]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.11.self_attn.out_proj.bias',\n",
       "               tensor([ 0.1204, -0.0648, -0.0006,  ..., -0.0473, -0.1198,  0.0610])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.11.self_attn_layer_norm.weight',\n",
       "               tensor([0.4165, 0.2264, 0.3677,  ..., 0.5825, 0.3867, 0.1649])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.11.self_attn_layer_norm.bias',\n",
       "               tensor([ 2.9272e-01, -1.7493e-01,  2.0996e-01,  ..., -1.7881e-04,\n",
       "                       -2.8564e-01,  1.4636e-01])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.11.fc1.weight',\n",
       "               tensor([[ 0.1022, -0.0107, -0.0324,  ..., -0.0529, -0.0346,  0.0015],\n",
       "                       [-0.0142, -0.0852, -0.1059,  ...,  0.0220,  0.0573,  0.0327],\n",
       "                       [ 0.0232, -0.0242, -0.1014,  ..., -0.0704,  0.1270, -0.0729],\n",
       "                       ...,\n",
       "                       [-0.0091, -0.0496, -0.1891,  ...,  0.0363, -0.0402, -0.0062],\n",
       "                       [ 0.0004,  0.0734,  0.0370,  ...,  0.0948, -0.0055, -0.1975],\n",
       "                       [-0.0942,  0.0429,  0.0327,  ..., -0.0836,  0.0892,  0.1151]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.11.fc1.bias',\n",
       "               tensor([-0.0126, -0.0013, -0.0086,  ..., -0.0154, -0.0314, -0.0388])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.11.fc2.weight',\n",
       "               tensor([[ 0.1074,  0.0253,  0.0640,  ...,  0.0012, -0.1086,  0.0392],\n",
       "                       [-0.0479, -0.0831, -0.0607,  ..., -0.0309, -0.0873, -0.1914],\n",
       "                       [ 0.0298,  0.0611, -0.0236,  ...,  0.0051,  0.0040,  0.0999],\n",
       "                       ...,\n",
       "                       [ 0.0182,  0.0340,  0.0337,  ...,  0.0757,  0.0462, -0.0307],\n",
       "                       [-0.0873, -0.0746, -0.0057,  ..., -0.0545, -0.0992,  0.1076],\n",
       "                       [ 0.0287,  0.0906, -0.0683,  ..., -0.0847,  0.0589,  0.0172]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.11.fc2.bias',\n",
       "               tensor([ 0.0012,  0.0158, -0.0343,  ..., -0.0083,  0.0067, -0.0458])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.11.final_layer_norm.weight',\n",
       "               tensor([0.2639, 0.2507, 0.2642,  ..., 0.4209, 0.2460, 0.2041])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.11.final_layer_norm.bias',\n",
       "               tensor([-0.0963,  0.0360, -0.0585,  ..., -0.0006,  0.0827, -0.0183])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.12.self_attn.k_proj.weight',\n",
       "               tensor([[-0.0945,  0.1011, -0.0531,  ...,  0.0508, -0.0560,  0.1263],\n",
       "                       [ 0.0732, -0.0540,  0.1180,  ...,  0.0826,  0.1238,  0.1543],\n",
       "                       [-0.1100, -0.0053,  0.0041,  ...,  0.0685,  0.0323,  0.0648],\n",
       "                       ...,\n",
       "                       [ 0.0693,  0.0995,  0.0546,  ...,  0.0562,  0.0945,  0.0051],\n",
       "                       [ 0.0067, -0.1600,  0.0122,  ...,  0.0590, -0.0135,  0.1259],\n",
       "                       [-0.0814,  0.0026, -0.0203,  ...,  0.0022, -0.0575, -0.0080]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.12.self_attn.k_proj.bias',\n",
       "               tensor([ 0.0930,  0.1954, -0.2063,  ...,  0.1406, -0.1100, -0.0557])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.12.self_attn.v_proj.weight',\n",
       "               tensor([[-0.0119, -0.0171, -0.0427,  ...,  0.0149,  0.0297,  0.0131],\n",
       "                       [ 0.0576,  0.0207,  0.0180,  ..., -0.0492, -0.0094,  0.0084],\n",
       "                       [ 0.0180, -0.0018, -0.1102,  ...,  0.0134,  0.0390,  0.0166],\n",
       "                       ...,\n",
       "                       [-0.0241, -0.0213,  0.0028,  ..., -0.0281, -0.0127,  0.0098],\n",
       "                       [-0.0166,  0.0171, -0.0529,  ..., -0.0860,  0.0351, -0.0774],\n",
       "                       [ 0.0444,  0.0088, -0.0765,  ...,  0.0140,  0.0529,  0.0318]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.12.self_attn.v_proj.bias',\n",
       "               tensor([ 0.0075,  0.0003,  0.0099,  ..., -0.0029,  0.0235,  0.0158])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.12.self_attn.q_proj.weight',\n",
       "               tensor([[ 0.0930, -0.1757,  0.0103,  ...,  0.0363, -0.0275,  0.0550],\n",
       "                       [ 0.0033,  0.0320, -0.0188,  ..., -0.1199,  0.1125,  0.0383],\n",
       "                       [-0.0610, -0.0148, -0.0089,  ..., -0.0255, -0.0916,  0.1252],\n",
       "                       ...,\n",
       "                       [ 0.0153, -0.0428, -0.0935,  ...,  0.1605, -0.0277, -0.0273],\n",
       "                       [ 0.0154, -0.0135, -0.0077,  ..., -0.0050, -0.0724, -0.0459],\n",
       "                       [ 0.0753,  0.0371,  0.0024,  ..., -0.0128,  0.0591,  0.0618]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.12.self_attn.q_proj.bias',\n",
       "               tensor([-0.1151, -0.1256, -0.0777,  ..., -0.3584,  0.2781,  0.1053])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.12.self_attn.out_proj.weight',\n",
       "               tensor([[-0.0051, -0.0151, -0.0027,  ...,  0.0750, -0.0846, -0.0105],\n",
       "                       [-0.0064, -0.0156, -0.0208,  ...,  0.0755, -0.1140, -0.0046],\n",
       "                       [ 0.0247, -0.0845, -0.0313,  ..., -0.0177,  0.0176, -0.0077],\n",
       "                       ...,\n",
       "                       [-0.0289,  0.0460, -0.0175,  ..., -0.0238,  0.0266,  0.0453],\n",
       "                       [ 0.0145,  0.0341,  0.0270,  ...,  0.0616, -0.1185,  0.0565],\n",
       "                       [-0.0468, -0.1159, -0.0301,  ...,  0.0194,  0.0862, -0.0248]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.12.self_attn.out_proj.bias',\n",
       "               tensor([ 0.0070,  0.0085,  0.0100,  ..., -0.0085,  0.0002,  0.0114])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.12.self_attn_layer_norm.weight',\n",
       "               tensor([0.5181, 0.4465, 0.4514,  ..., 0.5752, 0.4556, 0.3674])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.12.self_attn_layer_norm.bias',\n",
       "               tensor([ 0.2563, -0.1755,  0.1038,  ...,  0.0367, -0.2549,  0.1737])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.12.fc1.weight',\n",
       "               tensor([[ 0.0542,  0.0335, -0.0918,  ...,  0.0541, -0.0373, -0.0114],\n",
       "                       [ 0.0627,  0.1155, -0.1143,  ..., -0.0070, -0.0514, -0.1138],\n",
       "                       [-0.0798, -0.0519, -0.0564,  ...,  0.1055,  0.0061,  0.0720],\n",
       "                       ...,\n",
       "                       [ 0.1055,  0.1572, -0.1736,  ..., -0.0073,  0.0196, -0.2312],\n",
       "                       [-0.0544, -0.0276, -0.0414,  ..., -0.0335,  0.2279,  0.0469],\n",
       "                       [ 0.1388,  0.0057, -0.0791,  ..., -0.0873,  0.1034, -0.0969]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.12.fc1.bias',\n",
       "               tensor([-0.0127, -0.0163, -0.0388,  ..., -0.0330, -0.0764, -0.0035])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.12.fc2.weight',\n",
       "               tensor([[-0.2439, -0.0516,  0.0361,  ..., -0.1056, -0.0030,  0.0838],\n",
       "                       [ 0.1144,  0.0777,  0.0199,  ...,  0.0967, -0.0409, -0.0657],\n",
       "                       [-0.0683, -0.0964, -0.0360,  ..., -0.0411,  0.0530,  0.0208],\n",
       "                       ...,\n",
       "                       [-0.0341, -0.0177, -0.0332,  ..., -0.0073, -0.0594,  0.0392],\n",
       "                       [ 0.0183, -0.0671, -0.1312,  ...,  0.0716,  0.0302, -0.0135],\n",
       "                       [-0.0393, -0.0301, -0.0617,  ...,  0.0132,  0.0547,  0.1553]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.12.fc2.bias',\n",
       "               tensor([ 0.0100,  0.0171, -0.0099,  ..., -0.0055,  0.0169, -0.0205])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.12.final_layer_norm.weight',\n",
       "               tensor([0.2749, 0.2428, 0.3062,  ..., 0.4219, 0.2499, 0.2051])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.12.final_layer_norm.bias',\n",
       "               tensor([-0.1075,  0.0712, -0.0497,  ..., -0.0132,  0.0762, -0.0261])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.13.self_attn.k_proj.weight',\n",
       "               tensor([[ 0.0272,  0.0541, -0.0637,  ..., -0.0551,  0.0475,  0.0749],\n",
       "                       [-0.1196,  0.0277,  0.0083,  ...,  0.0398, -0.2197, -0.0223],\n",
       "                       [-0.0381, -0.0227, -0.0004,  ...,  0.0253,  0.0941, -0.0102],\n",
       "                       ...,\n",
       "                       [ 0.0710,  0.0251, -0.1187,  ..., -0.0402, -0.0501, -0.0597],\n",
       "                       [ 0.0278,  0.0013,  0.1174,  ..., -0.0201,  0.0069, -0.1503],\n",
       "                       [ 0.0443, -0.0667,  0.0604,  ...,  0.0614, -0.0522, -0.1438]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.13.self_attn.k_proj.bias',\n",
       "               tensor([ 0.0791, -0.1981,  0.0173,  ...,  0.0154,  0.1085, -0.0681])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.13.self_attn.v_proj.weight',\n",
       "               tensor([[ 1.5945e-02, -1.2386e-04, -3.2318e-02,  ...,  2.1011e-02,\n",
       "                         6.0852e-02, -6.8130e-03],\n",
       "                       [-2.5177e-03,  2.7649e-02,  5.6366e-02,  ..., -1.7181e-02,\n",
       "                         6.5002e-02, -3.1128e-02],\n",
       "                       [-8.5449e-03,  2.9480e-02, -3.7689e-02,  ..., -1.4862e-02,\n",
       "                        -3.8666e-02,  1.3077e-02],\n",
       "                       ...,\n",
       "                       [-7.2937e-03,  1.5869e-02, -4.4312e-02,  ...,  8.9951e-03,\n",
       "                         7.0679e-02, -2.3518e-03],\n",
       "                       [-6.0913e-02, -2.6688e-02, -2.9874e-04,  ...,  2.2537e-02,\n",
       "                         1.9135e-02,  3.2635e-03],\n",
       "                       [ 2.5452e-02, -1.9760e-02, -2.3682e-02,  ...,  1.9394e-02,\n",
       "                        -1.3676e-03,  1.3708e-01]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.13.self_attn.v_proj.bias',\n",
       "               tensor([-0.0212, -0.0015, -0.0128,  ..., -0.0093,  0.0071,  0.0119])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.13.self_attn.q_proj.weight',\n",
       "               tensor([[-0.1373, -0.1431,  0.0966,  ..., -0.0201, -0.1154,  0.1359],\n",
       "                       [ 0.0136,  0.1968, -0.0212,  ...,  0.0803,  0.0685, -0.0250],\n",
       "                       [ 0.0106,  0.0387, -0.0200,  ...,  0.0080,  0.0901,  0.1998],\n",
       "                       ...,\n",
       "                       [ 0.0444, -0.0406, -0.0173,  ...,  0.0501, -0.0071, -0.0679],\n",
       "                       [-0.0250, -0.0851,  0.0676,  ..., -0.0036,  0.0526,  0.0175],\n",
       "                       [-0.0518,  0.0175,  0.0659,  ...,  0.0192, -0.2040,  0.0542]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.13.self_attn.q_proj.bias',\n",
       "               tensor([-0.2010,  0.2632,  0.1215,  ...,  0.0407,  0.2083, -0.0939])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.13.self_attn.out_proj.weight',\n",
       "               tensor([[-0.0191,  0.1179,  0.0044,  ..., -0.0255, -0.0154, -0.0523],\n",
       "                       [-0.0491,  0.0763,  0.0188,  ..., -0.0473,  0.0594, -0.0943],\n",
       "                       [ 0.0917, -0.0934, -0.0346,  ...,  0.0240, -0.0072, -0.0205],\n",
       "                       ...,\n",
       "                       [-0.0221,  0.0117, -0.0239,  ..., -0.0084, -0.0042, -0.0051],\n",
       "                       [ 0.0125, -0.0629, -0.0192,  ..., -0.0260, -0.0028, -0.0234],\n",
       "                       [ 0.1433,  0.0012, -0.0491,  ..., -0.0869, -0.0719, -0.0287]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.13.self_attn.out_proj.bias',\n",
       "               tensor([-0.0195,  0.0111, -0.0103,  ..., -0.0146, -0.0057, -0.0444])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.13.self_attn_layer_norm.weight',\n",
       "               tensor([0.5718, 0.4968, 0.5845,  ..., 0.7114, 0.4873, 0.4094])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.13.self_attn_layer_norm.bias',\n",
       "               tensor([ 0.0613, -0.2086,  0.2289,  ...,  0.1619, -0.1987,  0.1296])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.13.fc1.weight',\n",
       "               tensor([[ 0.1039,  0.0713,  0.1422,  ..., -0.1182,  0.0665,  0.1006],\n",
       "                       [-0.1332,  0.0629,  0.0116,  ..., -0.0505,  0.2026,  0.0458],\n",
       "                       [ 0.0054,  0.0704,  0.0659,  ..., -0.0274, -0.0456, -0.0016],\n",
       "                       ...,\n",
       "                       [-0.0065,  0.0748,  0.0491,  ...,  0.0332,  0.0733, -0.0177],\n",
       "                       [-0.0573,  0.1783, -0.0850,  ...,  0.0536,  0.0886, -0.0176],\n",
       "                       [ 0.0438,  0.0499, -0.1129,  ...,  0.0038, -0.0252,  0.0210]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.13.fc1.bias',\n",
       "               tensor([-0.0504, -0.0719, -0.0540,  ...,  0.0129, -0.0362, -0.0629])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.13.fc2.weight',\n",
       "               tensor([[-0.0779, -0.0377,  0.0663,  ...,  0.1752,  0.0225,  0.0503],\n",
       "                       [ 0.0543, -0.1581,  0.0498,  ...,  0.0806,  0.0544, -0.0429],\n",
       "                       [ 0.0372,  0.0624, -0.0131,  ...,  0.0028,  0.1434,  0.0598],\n",
       "                       ...,\n",
       "                       [-0.0429,  0.0616, -0.0409,  ...,  0.0224, -0.1100, -0.0005],\n",
       "                       [ 0.0177,  0.1769, -0.0051,  ...,  0.0119,  0.0471, -0.1560],\n",
       "                       [-0.0936,  0.1871,  0.0407,  ...,  0.0192,  0.0513,  0.0613]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.13.fc2.bias',\n",
       "               tensor([ 0.0339, -0.0004, -0.0184,  ..., -0.0154,  0.0403,  0.0105])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.13.final_layer_norm.weight',\n",
       "               tensor([0.2942, 0.2534, 0.3015,  ..., 0.3843, 0.2522, 0.2322])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.13.final_layer_norm.bias',\n",
       "               tensor([-0.0233,  0.0736, -0.0875,  ..., -0.0533,  0.0639, -0.0211])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.14.self_attn.k_proj.weight',\n",
       "               tensor([[ 0.0600, -0.0295, -0.1344,  ..., -0.0421, -0.1351,  0.0787],\n",
       "                       [ 0.0016,  0.1666,  0.0409,  ..., -0.0454, -0.1547,  0.0169],\n",
       "                       [ 0.0388, -0.1169,  0.0592,  ..., -0.0588, -0.1123,  0.0688],\n",
       "                       ...,\n",
       "                       [-0.0816, -0.0063,  0.0891,  ...,  0.0287, -0.0009,  0.1483],\n",
       "                       [ 0.0196,  0.0441,  0.0221,  ...,  0.0575,  0.0930, -0.0763],\n",
       "                       [ 0.0909, -0.1620, -0.0569,  ...,  0.0923, -0.1492, -0.0648]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.14.self_attn.k_proj.bias',\n",
       "               tensor([-0.0625, -0.1697,  0.0167,  ..., -0.0931, -0.1238,  0.1364])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.14.self_attn.v_proj.weight',\n",
       "               tensor([[-0.0073, -0.0388,  0.0450,  ...,  0.0234,  0.0119, -0.1089],\n",
       "                       [ 0.0584,  0.0192,  0.0193,  ..., -0.0587,  0.0210,  0.0256],\n",
       "                       [-0.0141,  0.0186, -0.0690,  ...,  0.0592, -0.0270,  0.0160],\n",
       "                       ...,\n",
       "                       [ 0.0176, -0.0216,  0.0251,  ..., -0.0571,  0.0661,  0.0214],\n",
       "                       [ 0.0447, -0.0941,  0.0428,  ...,  0.0264,  0.0797, -0.0057],\n",
       "                       [-0.0384, -0.0273, -0.0310,  ...,  0.0536,  0.0847,  0.0253]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.14.self_attn.v_proj.bias',\n",
       "               tensor([-0.0151, -0.0133, -0.0063,  ..., -0.0132, -0.0054, -0.0108])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.14.self_attn.q_proj.weight',\n",
       "               tensor([[ 0.0462, -0.0662, -0.1276,  ...,  0.0100,  0.0966, -0.0034],\n",
       "                       [ 0.0433, -0.1219,  0.1207,  ..., -0.0310,  0.0064,  0.1036],\n",
       "                       [ 0.0265,  0.2113,  0.0844,  ...,  0.0008, -0.0566,  0.0368],\n",
       "                       ...,\n",
       "                       [ 0.0784,  0.0169,  0.0314,  ..., -0.0294,  0.1849, -0.0068],\n",
       "                       [ 0.0573,  0.0274, -0.0084,  ...,  0.0123, -0.0859, -0.0291],\n",
       "                       [-0.1282, -0.1536,  0.1592,  ..., -0.0857,  0.1226, -0.0543]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.14.self_attn.q_proj.bias',\n",
       "               tensor([ 0.0787,  0.2656,  0.1614,  ...,  0.0480,  0.2146, -0.0602])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.14.self_attn.out_proj.weight',\n",
       "               tensor([[ 1.6434e-02, -3.6102e-02, -1.0147e-02,  ..., -7.6904e-03,\n",
       "                         3.4760e-02, -7.1960e-02],\n",
       "                       [ 1.5457e-02, -2.2469e-03, -9.0393e-02,  ...,  4.3030e-02,\n",
       "                        -5.8105e-02, -9.6588e-03],\n",
       "                       [ 8.3801e-02,  1.1139e-02,  2.5253e-02,  ..., -5.0392e-03,\n",
       "                         3.4027e-03, -3.5675e-02],\n",
       "                       ...,\n",
       "                       [ 2.1851e-02, -1.5511e-02, -6.9580e-02,  ..., -3.4809e-05,\n",
       "                         1.4801e-02,  3.2959e-02],\n",
       "                       [ 2.9953e-02,  5.3131e-02, -4.8065e-02,  ...,  2.9892e-02,\n",
       "                        -3.4058e-02, -5.3589e-02],\n",
       "                       [ 5.7281e-02, -8.9905e-02, -1.6281e-02,  ...,  1.3626e-02,\n",
       "                        -1.1396e-03,  2.5101e-02]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.14.self_attn.out_proj.bias',\n",
       "               tensor([ 0.0191,  0.0010, -0.0199,  ...,  0.0004,  0.0185, -0.0258])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.14.self_attn_layer_norm.weight',\n",
       "               tensor([0.5322, 0.4683, 0.5239,  ..., 0.6841, 0.4282, 0.3828])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.14.self_attn_layer_norm.bias',\n",
       "               tensor([ 0.1885, -0.2399,  0.1532,  ...,  0.2937, -0.0992, -0.0458])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.14.fc1.weight',\n",
       "               tensor([[-0.0347, -0.1104,  0.0091,  ..., -0.0934,  0.0285,  0.0603],\n",
       "                       [-0.3340, -0.0003,  0.0322,  ...,  0.0140,  0.1245, -0.0382],\n",
       "                       [-0.0021,  0.0572,  0.0718,  ...,  0.1102,  0.0016, -0.0575],\n",
       "                       ...,\n",
       "                       [-0.0215, -0.0160,  0.0017,  ...,  0.0097, -0.0030,  0.0406],\n",
       "                       [-0.2029, -0.1112,  0.0649,  ..., -0.1493,  0.1077, -0.0566],\n",
       "                       [-0.1182, -0.0522, -0.0429,  ...,  0.0494,  0.1234, -0.0284]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.14.fc1.bias',\n",
       "               tensor([-0.0289, -0.0387,  0.0074,  ...,  0.0906, -0.0275, -0.0161])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.14.fc2.weight',\n",
       "               tensor([[-0.1554, -0.0760, -0.0273,  ..., -0.0550, -0.0914,  0.0027],\n",
       "                       [ 0.1026,  0.0420, -0.1813,  ..., -0.0407,  0.0407, -0.0943],\n",
       "                       [-0.0884,  0.0066, -0.0996,  ..., -0.0049, -0.0346, -0.0356],\n",
       "                       ...,\n",
       "                       [-0.0131, -0.0160,  0.1003,  ..., -0.0134, -0.1125,  0.0644],\n",
       "                       [ 0.0633,  0.0490,  0.0321,  ..., -0.0026,  0.1783, -0.0024],\n",
       "                       [ 0.2026,  0.0322,  0.0471,  ...,  0.0154, -0.0192,  0.0099]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.14.fc2.bias',\n",
       "               tensor([0.0177, 0.0348, 0.0399,  ..., 0.0183, 0.0255, 0.0036])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.14.final_layer_norm.weight',\n",
       "               tensor([0.2842, 0.2476, 0.3123,  ..., 0.4053, 0.2542, 0.2271])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.14.final_layer_norm.bias',\n",
       "               tensor([-0.0515,  0.0758, -0.0682,  ..., -0.1267,  0.0200,  0.0122])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.15.self_attn.k_proj.weight',\n",
       "               tensor([[-0.0261, -0.1395, -0.0881,  ...,  0.1528, -0.0583, -0.0874],\n",
       "                       [ 0.0159, -0.0805, -0.0619,  ..., -0.0307, -0.0432,  0.0522],\n",
       "                       [ 0.1003, -0.1141, -0.1054,  ...,  0.1842,  0.0017,  0.0582],\n",
       "                       ...,\n",
       "                       [ 0.0233, -0.0670, -0.0640,  ...,  0.0155, -0.0219,  0.0557],\n",
       "                       [ 0.0748, -0.0543,  0.0833,  ...,  0.0751, -0.0671,  0.0240],\n",
       "                       [-0.0327, -0.0473, -0.2238,  ...,  0.0618,  0.0325, -0.1265]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.15.self_attn.k_proj.bias',\n",
       "               tensor([ 0.0045, -0.1416,  0.0640,  ..., -0.4084, -0.0350,  0.4084])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.15.self_attn.v_proj.weight',\n",
       "               tensor([[-0.0283, -0.0364, -0.0044,  ..., -0.0065, -0.0633,  0.0224],\n",
       "                       [ 0.0514,  0.0568, -0.0121,  ..., -0.0059, -0.0066, -0.0007],\n",
       "                       [ 0.0157, -0.0098,  0.0081,  ...,  0.0127, -0.0453,  0.1233],\n",
       "                       ...,\n",
       "                       [-0.0684,  0.0088, -0.0566,  ...,  0.0201,  0.1025, -0.0398],\n",
       "                       [-0.0416, -0.0461,  0.0233,  ...,  0.0223, -0.1223,  0.0084],\n",
       "                       [-0.0114, -0.0673, -0.0201,  ...,  0.0463, -0.1355, -0.0510]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.15.self_attn.v_proj.bias',\n",
       "               tensor([-0.0322, -0.0633,  0.0264,  ..., -0.0194,  0.0189, -0.0004])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.15.self_attn.q_proj.weight',\n",
       "               tensor([[-0.0956,  0.0563, -0.0615,  ...,  0.1272,  0.0503, -0.0775],\n",
       "                       [-0.0445, -0.0746,  0.0658,  ..., -0.0482,  0.1112, -0.1215],\n",
       "                       [ 0.0007,  0.0753,  0.0661,  ...,  0.2179,  0.0067, -0.0155],\n",
       "                       ...,\n",
       "                       [-0.0304,  0.0066,  0.0464,  ...,  0.0029, -0.0042, -0.0145],\n",
       "                       [-0.0247, -0.0358,  0.0175,  ..., -0.1063, -0.0731, -0.1039],\n",
       "                       [ 0.0232, -0.0803, -0.0309,  ..., -0.0459,  0.0695, -0.0295]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.15.self_attn.q_proj.bias',\n",
       "               tensor([-0.3132,  0.0604, -0.0348,  ...,  0.0583, -0.0136, -0.3921])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.15.self_attn.out_proj.weight',\n",
       "               tensor([[-0.0471, -0.0440,  0.0053,  ...,  0.0798,  0.0265,  0.0804],\n",
       "                       [ 0.0563, -0.0151, -0.0153,  ..., -0.0438, -0.0426, -0.0156],\n",
       "                       [ 0.0071, -0.0257, -0.0024,  ..., -0.0075,  0.0558,  0.0326],\n",
       "                       ...,\n",
       "                       [ 0.0002, -0.0197, -0.0348,  ..., -0.0053, -0.0047,  0.0462],\n",
       "                       [-0.0472,  0.0306, -0.0269,  ...,  0.0733, -0.0032, -0.1447],\n",
       "                       [ 0.0522,  0.0490,  0.0011,  ...,  0.0536, -0.1521,  0.0656]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.15.self_attn.out_proj.bias',\n",
       "               tensor([-0.0063,  0.0068, -0.0013,  ...,  0.0019,  0.0216,  0.0152])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.15.self_attn_layer_norm.weight',\n",
       "               tensor([0.4106, 0.3818, 0.4800,  ..., 0.6011, 0.3545, 0.3284])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.15.self_attn_layer_norm.bias',\n",
       "               tensor([ 0.0507, -0.0970,  0.1080,  ...,  0.0545, -0.1022,  0.1252])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.15.fc1.weight',\n",
       "               tensor([[-8.0261e-02, -2.1790e-01,  6.3721e-02,  ...,  1.0475e-02,\n",
       "                        -8.1665e-02,  8.4152e-03],\n",
       "                       [ 2.4634e-01,  2.0126e-02,  1.4075e-01,  ...,  9.7656e-03,\n",
       "                        -1.5962e-04, -9.8267e-02],\n",
       "                       [-1.8051e-02,  9.1171e-03, -2.0923e-01,  ..., -1.4259e-02,\n",
       "                         2.6962e-02,  9.2590e-02],\n",
       "                       ...,\n",
       "                       [ 5.4901e-02, -1.7664e-01,  2.6550e-02,  ..., -1.0962e-01,\n",
       "                         1.4136e-01,  7.0923e-02],\n",
       "                       [ 1.6699e-01, -3.8422e-02, -3.3081e-02,  ...,  8.7280e-02,\n",
       "                         4.3427e-02, -1.5710e-01],\n",
       "                       [-9.3384e-02,  4.9927e-02, -7.2693e-02,  ..., -6.7627e-02,\n",
       "                        -3.7445e-02,  7.0251e-02]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.15.fc1.bias',\n",
       "               tensor([-0.0143,  0.0069, -0.0419,  ...,  0.0139,  0.0063, -0.0170])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.15.fc2.weight',\n",
       "               tensor([[ 0.0848, -0.0909,  0.0375,  ...,  0.0372,  0.0500,  0.0620],\n",
       "                       [-0.0664, -0.0172, -0.0486,  ..., -0.0646, -0.0270,  0.0171],\n",
       "                       [ 0.0105,  0.0823, -0.1732,  ..., -0.1200, -0.0508,  0.0898],\n",
       "                       ...,\n",
       "                       [-0.0167, -0.0867,  0.0377,  ...,  0.0129,  0.1028, -0.0399],\n",
       "                       [-0.0420, -0.0218, -0.1621,  ...,  0.0724, -0.0924,  0.1576],\n",
       "                       [ 0.0410,  0.0046,  0.1074,  ..., -0.0270,  0.0520,  0.0368]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.15.fc2.bias',\n",
       "               tensor([ 0.0033,  0.0093,  0.0175,  ..., -0.0107, -0.0456, -0.0135])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.15.final_layer_norm.weight',\n",
       "               tensor([0.2615, 0.2371, 0.3049,  ..., 0.3972, 0.2274, 0.2330])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.15.final_layer_norm.bias',\n",
       "               tensor([ 0.0013,  0.0131, -0.0271,  ..., -0.0182,  0.0204, -0.0069])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.16.self_attn.k_proj.weight',\n",
       "               tensor([[-0.0575, -0.0128,  0.0513,  ...,  0.0569, -0.1517, -0.0064],\n",
       "                       [ 0.0053,  0.0905, -0.1418,  ..., -0.0532,  0.0097, -0.0396],\n",
       "                       [-0.0108, -0.0015, -0.1093,  ...,  0.1008, -0.0984,  0.0722],\n",
       "                       ...,\n",
       "                       [ 0.0012, -0.0181, -0.0319,  ..., -0.0030,  0.0336,  0.0710],\n",
       "                       [-0.0302,  0.0442, -0.0617,  ...,  0.0868,  0.1995, -0.1462],\n",
       "                       [-0.0844,  0.0009, -0.0432,  ..., -0.0226, -0.0678,  0.1375]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.16.self_attn.k_proj.bias',\n",
       "               tensor([-1.0234, -0.2070, -0.7944,  ..., -0.1948,  0.0477, -0.1552])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.16.self_attn.v_proj.weight',\n",
       "               tensor([[-1.9699e-02,  1.6983e-02, -7.3730e-02,  ...,  1.3786e-02,\n",
       "                        -2.9297e-02, -3.5522e-02],\n",
       "                       [ 2.6764e-02,  1.0675e-01,  3.1433e-02,  ..., -3.1616e-02,\n",
       "                        -3.1173e-05, -4.0619e-02],\n",
       "                       [ 7.5012e-02,  3.3997e-02, -6.3858e-03,  ...,  1.6499e-03,\n",
       "                         4.0527e-02, -1.7065e-01],\n",
       "                       ...,\n",
       "                       [ 6.4331e-02,  1.4198e-02,  1.0750e-02,  ..., -4.0741e-02,\n",
       "                         3.0106e-02,  1.4488e-02],\n",
       "                       [-7.1045e-02,  6.4507e-03, -6.3904e-02,  ...,  1.4130e-02,\n",
       "                         4.7516e-02, -1.4801e-02],\n",
       "                       [-1.6953e-02,  7.4615e-03,  6.2561e-02,  ...,  5.6519e-02,\n",
       "                        -9.6436e-02, -4.4342e-02]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.16.self_attn.v_proj.bias',\n",
       "               tensor([-0.0011,  0.0077, -0.0058,  ...,  0.0150,  0.0214, -0.0005])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.16.self_attn.q_proj.weight',\n",
       "               tensor([[-0.0108, -0.0700,  0.0012,  ..., -0.0126,  0.0010, -0.0704],\n",
       "                       [-0.0709, -0.0023, -0.0065,  ..., -0.0649, -0.0510,  0.1052],\n",
       "                       [ 0.0599,  0.0300, -0.0988,  ..., -0.0648, -0.0416, -0.0254],\n",
       "                       ...,\n",
       "                       [-0.0124, -0.0049, -0.0336,  ...,  0.0889, -0.0829, -0.1168],\n",
       "                       [-0.0656, -0.0120,  0.0060,  ..., -0.0839,  0.0900, -0.2230],\n",
       "                       [ 0.1147,  0.0758, -0.1669,  ...,  0.0035, -0.0151,  0.1367]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.16.self_attn.q_proj.bias',\n",
       "               tensor([ 0.2211,  0.4031,  0.4004,  ..., -0.2493,  0.0743,  0.4592])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.16.self_attn.out_proj.weight',\n",
       "               tensor([[-0.0179, -0.0505, -0.0122,  ..., -0.0142,  0.0630, -0.0094],\n",
       "                       [ 0.0369,  0.1444,  0.1128,  ..., -0.0391,  0.0587, -0.0230],\n",
       "                       [-0.0350,  0.0395, -0.0079,  ..., -0.0680, -0.0011, -0.0221],\n",
       "                       ...,\n",
       "                       [-0.0209,  0.0377, -0.0166,  ...,  0.0137,  0.0466,  0.0143],\n",
       "                       [-0.1677,  0.0784, -0.0305,  ...,  0.0052, -0.0070,  0.0888],\n",
       "                       [ 0.0790,  0.0049,  0.0410,  ...,  0.0285, -0.0213,  0.0235]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.16.self_attn.out_proj.bias',\n",
       "               tensor([-0.0028,  0.0118,  0.0002,  ..., -0.0060, -0.0104, -0.0261])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.16.self_attn_layer_norm.weight',\n",
       "               tensor([0.4348, 0.4263, 0.5186,  ..., 0.6191, 0.4231, 0.4033])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.16.self_attn_layer_norm.bias',\n",
       "               tensor([-0.0555, -0.1104,  0.1370,  ...,  0.1437, -0.1356,  0.0637])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.16.fc1.weight',\n",
       "               tensor([[ 0.0790, -0.1505,  0.0966,  ...,  0.0939,  0.1044, -0.0006],\n",
       "                       [ 0.0235, -0.0236, -0.0054,  ..., -0.0206,  0.0161,  0.0679],\n",
       "                       [ 0.1116, -0.1411,  0.0701,  ..., -0.0664,  0.0845, -0.0181],\n",
       "                       ...,\n",
       "                       [-0.0043, -0.0687, -0.0020,  ..., -0.0044,  0.0903,  0.0100],\n",
       "                       [-0.1682,  0.0950,  0.0654,  ...,  0.0637,  0.0469,  0.0066],\n",
       "                       [ 0.0258,  0.2296, -0.1541,  ...,  0.0717,  0.0571, -0.0267]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.16.fc1.bias',\n",
       "               tensor([-0.0711, -0.0439, -0.0562,  ..., -0.0780, -0.0018, -0.0577])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.16.fc2.weight',\n",
       "               tensor([[-0.1245, -0.0071, -0.1006,  ...,  0.0214, -0.0754, -0.0901],\n",
       "                       [ 0.0941, -0.0933, -0.1120,  ..., -0.0454,  0.0615,  0.1313],\n",
       "                       [-0.1165,  0.0438,  0.0156,  ..., -0.0092, -0.0553, -0.0183],\n",
       "                       ...,\n",
       "                       [ 0.0058, -0.0072,  0.0042,  ..., -0.0232,  0.0176,  0.0120],\n",
       "                       [ 0.0331, -0.0179,  0.0695,  ...,  0.0188, -0.1359, -0.0212],\n",
       "                       [-0.0919, -0.0306,  0.0279,  ..., -0.0734, -0.1181,  0.0132]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.16.fc2.bias',\n",
       "               tensor([-0.0406,  0.0376,  0.0423,  ..., -0.0471,  0.0451,  0.0679])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.16.final_layer_norm.weight',\n",
       "               tensor([0.2920, 0.3054, 0.3530,  ..., 0.4270, 0.2803, 0.3167])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.16.final_layer_norm.bias',\n",
       "               tensor([ 0.0224,  0.0295, -0.0208,  ..., -0.0334,  0.0441,  0.0061])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.17.self_attn.k_proj.weight',\n",
       "               tensor([[-0.0082, -0.1532,  0.0199,  ...,  0.0085,  0.0934,  0.0302],\n",
       "                       [-0.0891,  0.0473, -0.0019,  ..., -0.0218, -0.0513,  0.0533],\n",
       "                       [ 0.0163, -0.0958, -0.1039,  ..., -0.0768, -0.1004,  0.0842],\n",
       "                       ...,\n",
       "                       [-0.0231,  0.0749,  0.0392,  ...,  0.0352,  0.1643, -0.0122],\n",
       "                       [ 0.0707, -0.2174, -0.0163,  ...,  0.0503, -0.0030, -0.1328],\n",
       "                       [ 0.0939, -0.0381,  0.0407,  ..., -0.0097, -0.1077,  0.1001]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.17.self_attn.k_proj.bias',\n",
       "               tensor([ 0.3232,  0.1724,  0.2260,  ..., -0.0361, -0.0666, -0.0713])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.17.self_attn.v_proj.weight',\n",
       "               tensor([[ 0.0666,  0.0331,  0.0503,  ..., -0.0395,  0.0402,  0.0180],\n",
       "                       [-0.0171, -0.1099,  0.0145,  ...,  0.0097,  0.0877,  0.0312],\n",
       "                       [-0.0528, -0.0690,  0.0225,  ..., -0.0331, -0.0251,  0.0413],\n",
       "                       ...,\n",
       "                       [ 0.0111, -0.0007, -0.0495,  ...,  0.0047, -0.0004,  0.0243],\n",
       "                       [ 0.0255,  0.0728, -0.0282,  ..., -0.0450,  0.0004, -0.0328],\n",
       "                       [-0.0213,  0.0014,  0.0158,  ..., -0.0327, -0.0555,  0.0352]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.17.self_attn.v_proj.bias',\n",
       "               tensor([ 0.0116, -0.0009,  0.0048,  ...,  0.0051,  0.0051,  0.0116])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.17.self_attn.q_proj.weight',\n",
       "               tensor([[ 0.0891,  0.0731, -0.0340,  ..., -0.0798, -0.0573,  0.0665],\n",
       "                       [ 0.0340, -0.1088, -0.0419,  ..., -0.1180,  0.1295, -0.0513],\n",
       "                       [-0.0803, -0.0414,  0.0677,  ..., -0.0487,  0.1261,  0.0629],\n",
       "                       ...,\n",
       "                       [-0.0615,  0.0866, -0.0510,  ...,  0.0003, -0.0318,  0.0247],\n",
       "                       [-0.0363, -0.0247,  0.0453,  ...,  0.0248, -0.0602,  0.0152],\n",
       "                       [ 0.0039,  0.0722, -0.0937,  ..., -0.0347,  0.0574, -0.0186]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.17.self_attn.q_proj.bias',\n",
       "               tensor([ 0.0581, -0.0826, -0.0803,  ...,  0.3164, -0.4761,  0.4756])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.17.self_attn.out_proj.weight',\n",
       "               tensor([[-0.0499, -0.0194, -0.0500,  ..., -0.0555,  0.0082,  0.1032],\n",
       "                       [-0.0048,  0.0363,  0.0249,  ..., -0.0177, -0.0424, -0.0168],\n",
       "                       [-0.0654, -0.0611, -0.0264,  ...,  0.0405,  0.0237, -0.0159],\n",
       "                       ...,\n",
       "                       [ 0.0109,  0.0125, -0.0052,  ..., -0.0187,  0.0165, -0.0022],\n",
       "                       [ 0.0138, -0.0116,  0.0039,  ..., -0.0112,  0.0481,  0.0118],\n",
       "                       [-0.0923, -0.0445,  0.0140,  ...,  0.0116,  0.0239, -0.0455]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.17.self_attn.out_proj.bias',\n",
       "               tensor([ 0.0194,  0.0221, -0.0287,  ..., -0.0188, -0.0219,  0.0085])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.17.self_attn_layer_norm.weight',\n",
       "               tensor([0.4441, 0.4287, 0.5718,  ..., 0.6147, 0.4292, 0.4209])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.17.self_attn_layer_norm.bias',\n",
       "               tensor([ 0.0581, -0.0862,  0.1523,  ...,  0.0770, -0.0684,  0.1064])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.17.fc1.weight',\n",
       "               tensor([[-0.0517,  0.0490,  0.0323,  ...,  0.0688, -0.0344, -0.0211],\n",
       "                       [-0.0325,  0.0287, -0.0131,  ...,  0.0040, -0.0622,  0.1074],\n",
       "                       [ 0.0984, -0.0922, -0.0547,  ..., -0.0593,  0.0078, -0.0433],\n",
       "                       ...,\n",
       "                       [ 0.0174,  0.0128,  0.0038,  ..., -0.0262,  0.0155,  0.0127],\n",
       "                       [-0.0694, -0.0887, -0.0458,  ..., -0.0999,  0.0142,  0.1094],\n",
       "                       [-0.0853, -0.0213, -0.0107,  ..., -0.1591,  0.1204,  0.1276]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.17.fc1.bias',\n",
       "               tensor([-0.0693, -0.0626, -0.0238,  ..., -0.0520, -0.0464, -0.0478])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.17.fc2.weight',\n",
       "               tensor([[ 0.0522,  0.0131,  0.0162,  ...,  0.0086,  0.0120,  0.2125],\n",
       "                       [ 0.0426,  0.0213,  0.0588,  ..., -0.0415, -0.1440, -0.1918],\n",
       "                       [ 0.0237,  0.0956, -0.0461,  ..., -0.0045,  0.1121, -0.0013],\n",
       "                       ...,\n",
       "                       [ 0.0477,  0.0104, -0.0058,  ..., -0.0105, -0.0112, -0.0172],\n",
       "                       [ 0.0194,  0.0560, -0.0089,  ..., -0.0343,  0.1215,  0.1807],\n",
       "                       [-0.0407, -0.0781,  0.0509,  ..., -0.1096, -0.0231, -0.0264]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.17.fc2.bias',\n",
       "               tensor([ 0.0220, -0.0161,  0.0074,  ...,  0.0237, -0.0125,  0.0861])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.17.final_layer_norm.weight',\n",
       "               tensor([0.3081, 0.3235, 0.3564,  ..., 0.4163, 0.2817, 0.3044])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.17.final_layer_norm.bias',\n",
       "               tensor([-0.0031,  0.0332, -0.0209,  ..., -0.0221,  0.0268, -0.0006])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.18.self_attn.k_proj.weight',\n",
       "               tensor([[-0.0442, -0.0299, -0.0215,  ..., -0.0483, -0.0316,  0.0261],\n",
       "                       [-0.0276,  0.0070,  0.0261,  ...,  0.0573, -0.0362, -0.1533],\n",
       "                       [ 0.0720,  0.1113, -0.0740,  ..., -0.1063, -0.0620,  0.0603],\n",
       "                       ...,\n",
       "                       [-0.0044,  0.0362,  0.0335,  ...,  0.0117, -0.0051,  0.0727],\n",
       "                       [-0.1364,  0.0416, -0.0746,  ..., -0.0524, -0.0655,  0.0254],\n",
       "                       [ 0.0733,  0.1171, -0.1175,  ..., -0.0507, -0.0053,  0.0864]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.18.self_attn.k_proj.bias',\n",
       "               tensor([ 0.1172,  0.1543,  0.0331,  ...,  0.2068,  0.1376, -0.0796])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.18.self_attn.v_proj.weight',\n",
       "               tensor([[-0.0506,  0.0262, -0.0120,  ...,  0.0706,  0.0210,  0.0450],\n",
       "                       [-0.0396, -0.0114, -0.0321,  ...,  0.0229, -0.0404, -0.0202],\n",
       "                       [ 0.0389,  0.0082, -0.0276,  ...,  0.0189, -0.0429, -0.0015],\n",
       "                       ...,\n",
       "                       [-0.0220, -0.0469, -0.0511,  ...,  0.0077, -0.0320, -0.0054],\n",
       "                       [ 0.0099, -0.0372, -0.0099,  ...,  0.0424,  0.0170,  0.0031],\n",
       "                       [-0.0100, -0.0331,  0.0352,  ...,  0.0448, -0.0408, -0.0733]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.18.self_attn.v_proj.bias',\n",
       "               tensor([ 0.0171,  0.0155, -0.0052,  ..., -0.0080,  0.0080,  0.0127])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.18.self_attn.q_proj.weight',\n",
       "               tensor([[-0.0653,  0.0063, -0.1558,  ..., -0.0143,  0.0471,  0.0776],\n",
       "                       [-0.0566, -0.0345, -0.1340,  ..., -0.0102, -0.0226, -0.0476],\n",
       "                       [ 0.0609, -0.0265, -0.0860,  ...,  0.0049, -0.0069,  0.0515],\n",
       "                       ...,\n",
       "                       [ 0.0548,  0.0858, -0.1544,  ..., -0.0039, -0.0138, -0.0060],\n",
       "                       [-0.0903,  0.1077,  0.0360,  ..., -0.0762, -0.0061,  0.0969],\n",
       "                       [ 0.0399,  0.0007, -0.1174,  ..., -0.0527,  0.0092,  0.0469]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.18.self_attn.q_proj.bias',\n",
       "               tensor([ 0.0958, -0.1283,  0.4575,  ..., -0.0511,  0.3916,  0.2146])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.18.self_attn.out_proj.weight',\n",
       "               tensor([[ 0.0114,  0.0525, -0.0027,  ..., -0.0299,  0.0006, -0.0515],\n",
       "                       [ 0.0361,  0.0587, -0.0856,  ..., -0.0048,  0.0344,  0.0576],\n",
       "                       [-0.0213, -0.0004,  0.0468,  ...,  0.0228, -0.0474, -0.0243],\n",
       "                       ...,\n",
       "                       [-0.0047,  0.0010, -0.0009,  ...,  0.0362, -0.0300, -0.0381],\n",
       "                       [-0.0160,  0.0830, -0.0133,  ..., -0.0299,  0.0848,  0.0165],\n",
       "                       [-0.0310, -0.0422, -0.0068,  ...,  0.0493, -0.0204, -0.0255]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.18.self_attn.out_proj.bias',\n",
       "               tensor([ 0.0109, -0.0056,  0.0037,  ..., -0.0015, -0.0199, -0.0178])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.18.self_attn_layer_norm.weight',\n",
       "               tensor([0.4290, 0.4807, 0.5508,  ..., 0.5654, 0.4397, 0.4480])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.18.self_attn_layer_norm.bias',\n",
       "               tensor([ 0.0277, -0.3208,  0.0333,  ...,  0.1477, -0.0436,  0.0803])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.18.fc1.weight',\n",
       "               tensor([[-0.2415,  0.1223, -0.0366,  ..., -0.0015, -0.0767, -0.1531],\n",
       "                       [ 0.0332, -0.0093,  0.0111,  ..., -0.1692, -0.1429, -0.0054],\n",
       "                       [ 0.0011, -0.0213, -0.1721,  ..., -0.0793, -0.1230,  0.0443],\n",
       "                       ...,\n",
       "                       [ 0.0036,  0.0198,  0.0076,  ..., -0.0087,  0.0171, -0.0415],\n",
       "                       [ 0.0402,  0.0021, -0.0905,  ...,  0.0450,  0.0423,  0.0094],\n",
       "                       [-0.0403,  0.0215,  0.0816,  ..., -0.0287, -0.0963, -0.1451]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.18.fc1.bias',\n",
       "               tensor([-0.0656, -0.0783, -0.0882,  ...,  0.0101, -0.0630, -0.0595])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.18.fc2.weight',\n",
       "               tensor([[-0.0705, -0.0135, -0.0485,  ..., -0.0209,  0.0685, -0.0934],\n",
       "                       [ 0.0066, -0.0651, -0.0792,  ..., -0.0068,  0.0297,  0.0147],\n",
       "                       [ 0.0119,  0.0366, -0.0242,  ..., -0.0259,  0.0294,  0.0304],\n",
       "                       ...,\n",
       "                       [ 0.0024, -0.0172, -0.0627,  ...,  0.0038,  0.0209, -0.0021],\n",
       "                       [-0.1660, -0.0508, -0.0560,  ..., -0.0182,  0.0102,  0.0916],\n",
       "                       [ 0.0500,  0.0423,  0.0011,  ...,  0.0144,  0.0198, -0.1669]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.18.fc2.bias',\n",
       "               tensor([0.0517, 0.0317, 0.0464,  ..., 0.0339, 0.0526, 0.1033])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.18.final_layer_norm.weight',\n",
       "               tensor([0.3376, 0.3215, 0.3738,  ..., 0.4011, 0.3152, 0.3342])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.18.final_layer_norm.bias',\n",
       "               tensor([ 0.0076,  0.1237, -0.0013,  ..., -0.0569,  0.0312,  0.0081])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.19.self_attn.k_proj.weight',\n",
       "               tensor([[-0.0767,  0.0455,  0.0337,  ...,  0.0417,  0.0304, -0.0138],\n",
       "                       [-0.0273, -0.1406,  0.0384,  ...,  0.0945, -0.0121,  0.1129],\n",
       "                       [-0.1063,  0.0679,  0.1210,  ..., -0.0844,  0.0010,  0.0383],\n",
       "                       ...,\n",
       "                       [-0.1296,  0.1147, -0.0571,  ...,  0.0970, -0.0044,  0.0321],\n",
       "                       [-0.0146, -0.0721, -0.0658,  ...,  0.0432, -0.0345, -0.1460],\n",
       "                       [-0.0119,  0.0085,  0.0204,  ..., -0.0800, -0.0230, -0.0125]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.19.self_attn.k_proj.bias',\n",
       "               tensor([ 0.2118, -0.1766,  0.0415,  ..., -0.3242,  0.4529,  0.1638])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.19.self_attn.v_proj.weight',\n",
       "               tensor([[-0.0345,  0.0384, -0.0073,  ...,  0.0129, -0.0079,  0.0478],\n",
       "                       [-0.0390,  0.0079,  0.0020,  ...,  0.0508,  0.0161, -0.0381],\n",
       "                       [-0.0358, -0.1231, -0.0125,  ...,  0.0015,  0.0634,  0.0237],\n",
       "                       ...,\n",
       "                       [-0.0746,  0.0228, -0.0173,  ...,  0.0234, -0.0252, -0.0386],\n",
       "                       [ 0.0150,  0.0359,  0.0855,  ..., -0.0631,  0.0188,  0.0263],\n",
       "                       [ 0.0974, -0.0325, -0.0263,  ..., -0.0134, -0.0097, -0.0387]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.19.self_attn.v_proj.bias',\n",
       "               tensor([-0.0451,  0.1103,  0.0049,  ..., -0.0017,  0.0044,  0.0060])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.19.self_attn.q_proj.weight',\n",
       "               tensor([[ 0.0090,  0.0806, -0.0443,  ...,  0.0208,  0.0058, -0.0037],\n",
       "                       [ 0.0518,  0.0729, -0.0086,  ...,  0.0269, -0.1707, -0.0466],\n",
       "                       [ 0.0453, -0.0708, -0.0378,  ..., -0.0233,  0.1281,  0.1180],\n",
       "                       ...,\n",
       "                       [-0.0368,  0.0912,  0.0006,  ...,  0.0540,  0.0919,  0.1864],\n",
       "                       [-0.0492,  0.0417, -0.0219,  ...,  0.1108,  0.0262,  0.0123],\n",
       "                       [-0.0500,  0.0282, -0.0727,  ...,  0.0424,  0.1991, -0.0110]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.19.self_attn.q_proj.bias',\n",
       "               tensor([ 0.0609, -0.0359, -0.1074,  ...,  0.2399,  0.2512,  0.1208])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.19.self_attn.out_proj.weight',\n",
       "               tensor([[-0.0003, -0.0065, -0.0304,  ..., -0.0233, -0.0049, -0.0049],\n",
       "                       [ 0.0371, -0.0380, -0.0055,  ..., -0.0444,  0.0044,  0.0856],\n",
       "                       [-0.0014,  0.0047, -0.0126,  ...,  0.0032,  0.0016,  0.0194],\n",
       "                       ...,\n",
       "                       [ 0.0109,  0.0412, -0.0062,  ...,  0.0293, -0.0028,  0.0109],\n",
       "                       [-0.0375,  0.0252,  0.0179,  ..., -0.0028, -0.0220,  0.0642],\n",
       "                       [ 0.0233,  0.0057,  0.0255,  ..., -0.0156,  0.0426, -0.0067]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.19.self_attn.out_proj.bias',\n",
       "               tensor([-0.0191,  0.0345, -0.0072,  ..., -0.0072, -0.0496,  0.0228])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.19.self_attn_layer_norm.weight',\n",
       "               tensor([0.4053, 0.4185, 0.4868,  ..., 0.5171, 0.4138, 0.4255])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.19.self_attn_layer_norm.bias',\n",
       "               tensor([ 0.0730, -0.0287,  0.0276,  ..., -0.0121, -0.0143,  0.1395])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.19.fc1.weight',\n",
       "               tensor([[ 0.1371,  0.1478,  0.0274,  ..., -0.0321,  0.0037,  0.0426],\n",
       "                       [ 0.0653, -0.0335,  0.0553,  ..., -0.0155, -0.0285, -0.0999],\n",
       "                       [-0.0242, -0.0186, -0.0153,  ...,  0.0492, -0.0049,  0.0344],\n",
       "                       ...,\n",
       "                       [ 0.1090, -0.0911,  0.0021,  ..., -0.0046,  0.1100,  0.0386],\n",
       "                       [ 0.0623, -0.0839,  0.0255,  ...,  0.1772,  0.1654, -0.0975],\n",
       "                       [-0.0164, -0.0040,  0.0524,  ...,  0.0128,  0.0662, -0.0392]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.19.fc1.bias',\n",
       "               tensor([-0.1053, -0.0737, -0.0884,  ..., -0.1092, -0.1125, -0.0463])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.19.fc2.weight',\n",
       "               tensor([[ 0.0134,  0.0234,  0.0032,  ...,  0.0531,  0.0069,  0.0660],\n",
       "                       [ 0.0714, -0.0113,  0.0083,  ...,  0.0098,  0.0869,  0.0396],\n",
       "                       [ 0.0043,  0.0046,  0.0151,  ..., -0.0207,  0.0209,  0.0826],\n",
       "                       ...,\n",
       "                       [-0.0039,  0.0035, -0.0308,  ...,  0.0139, -0.0238, -0.0053],\n",
       "                       [ 0.0129,  0.0053,  0.0105,  ...,  0.0361, -0.0067, -0.0474],\n",
       "                       [ 0.0351, -0.0342,  0.0300,  ..., -0.0132, -0.0479,  0.0066]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.19.fc2.bias',\n",
       "               tensor([-0.0032,  0.0701,  0.0970,  ...,  0.0213,  0.0752,  0.0901])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.19.final_layer_norm.weight',\n",
       "               tensor([0.3516, 0.3674, 0.3958,  ..., 0.4419, 0.3540, 0.3564])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.19.final_layer_norm.bias',\n",
       "               tensor([ 0.0016,  0.0559,  0.0121,  ...,  0.0211,  0.0282, -0.0277])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.20.self_attn.k_proj.weight',\n",
       "               tensor([[ 0.0593,  0.0102,  0.0114,  ...,  0.0354, -0.0743, -0.0818],\n",
       "                       [-0.1220, -0.0363, -0.0163,  ...,  0.0297, -0.0677, -0.0258],\n",
       "                       [ 0.0198, -0.0737,  0.0529,  ..., -0.0221,  0.0107,  0.0336],\n",
       "                       ...,\n",
       "                       [ 0.0315,  0.0580,  0.0402,  ..., -0.1251,  0.1237, -0.0226],\n",
       "                       [-0.0304, -0.0052,  0.0242,  ..., -0.2009, -0.0421,  0.0248],\n",
       "                       [ 0.0123,  0.1284, -0.0563,  ..., -0.0717,  0.0378,  0.0494]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.20.self_attn.k_proj.bias',\n",
       "               tensor([ 4.8945, -2.2734,  0.5820,  ...,  0.0608,  0.0984, -2.6426])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.20.self_attn.v_proj.weight',\n",
       "               tensor([[ 4.1656e-02,  3.6133e-02, -3.7476e-02,  ..., -6.7078e-02,\n",
       "                        -7.7667e-03,  1.4702e-02],\n",
       "                       [-8.6832e-04, -1.1246e-02, -3.9612e-02,  ...,  1.9104e-02,\n",
       "                         1.5366e-02, -1.5533e-02],\n",
       "                       [-1.0712e-02, -3.7933e-02,  1.0269e-02,  ..., -1.6556e-02,\n",
       "                        -1.9730e-02, -5.7465e-02],\n",
       "                       ...,\n",
       "                       [ 7.7553e-03,  7.0333e-05,  2.2064e-02,  ...,  2.1606e-02,\n",
       "                         3.7537e-02, -2.1496e-03],\n",
       "                       [ 4.7180e-02, -6.8970e-02,  2.3163e-02,  ..., -3.4241e-02,\n",
       "                        -2.0752e-02,  6.7078e-02],\n",
       "                       [ 4.0344e-02, -8.4045e-02,  3.7659e-02,  ..., -1.2169e-02,\n",
       "                         3.8075e-04,  6.3110e-02]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.20.self_attn.v_proj.bias',\n",
       "               tensor([-5.8222e-04, -8.3237e-03, -6.2168e-05,  ...,  5.5511e-02,\n",
       "                        2.2217e-02, -4.4403e-02])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.20.self_attn.q_proj.weight',\n",
       "               tensor([[-0.0982,  0.0662, -0.0183,  ..., -0.1130,  0.0076, -0.0864],\n",
       "                       [-0.0179,  0.0856, -0.0188,  ...,  0.0674, -0.0007,  0.1270],\n",
       "                       [ 0.0480, -0.0298, -0.0526,  ..., -0.1210, -0.0543,  0.0135],\n",
       "                       ...,\n",
       "                       [ 0.0837, -0.1024,  0.0844,  ..., -0.1638, -0.1226, -0.0299],\n",
       "                       [ 0.1170, -0.0073,  0.1049,  ..., -0.1198, -0.0439, -0.0220],\n",
       "                       [-0.0645,  0.0387, -0.0604,  ..., -0.1635, -0.0176, -0.0191]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.20.self_attn.q_proj.bias',\n",
       "               tensor([-0.2089,  0.0961, -0.2700,  ..., -0.0591,  0.1760, -0.5078])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.20.self_attn.out_proj.weight',\n",
       "               tensor([[ 0.0056, -0.0028, -0.0119,  ..., -0.0103,  0.0107,  0.0237],\n",
       "                       [ 0.0322,  0.0139,  0.0015,  ...,  0.0493,  0.0164, -0.0153],\n",
       "                       [-0.0322, -0.0016,  0.0173,  ...,  0.0303,  0.0391, -0.0569],\n",
       "                       ...,\n",
       "                       [-0.0614,  0.0307, -0.0116,  ..., -0.0019, -0.0097,  0.0270],\n",
       "                       [ 0.0178, -0.0168,  0.0231,  ..., -0.0229, -0.0155,  0.0046],\n",
       "                       [ 0.0519,  0.0398, -0.0410,  ..., -0.0105, -0.0270, -0.0204]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.20.self_attn.out_proj.bias',\n",
       "               tensor([-0.0018, -0.0092, -0.0004,  ..., -0.0094, -0.0102, -0.0109])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.20.self_attn_layer_norm.weight',\n",
       "               tensor([0.3906, 0.4131, 0.4495,  ..., 0.4341, 0.4028, 0.3848])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.20.self_attn_layer_norm.bias',\n",
       "               tensor([ 0.0826,  0.0104,  0.0352,  ..., -0.0031,  0.0692,  0.1259])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.20.fc1.weight',\n",
       "               tensor([[ 0.0196, -0.0725,  0.0041,  ...,  0.0612,  0.0059,  0.0429],\n",
       "                       [-0.0470,  0.0298,  0.0616,  ..., -0.0529,  0.0117, -0.0876],\n",
       "                       [-0.0542,  0.0169,  0.0511,  ...,  0.0244,  0.0262, -0.0205],\n",
       "                       ...,\n",
       "                       [-0.0854, -0.0425,  0.0327,  ..., -0.0130, -0.0175, -0.1124],\n",
       "                       [ 0.0253, -0.0708,  0.0168,  ..., -0.0648, -0.0989,  0.0060],\n",
       "                       [-0.0762,  0.0926, -0.0777,  ...,  0.0889, -0.0135, -0.1653]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.20.fc1.bias',\n",
       "               tensor([-0.0797, -0.0102,  0.0338,  ..., -0.0848, -0.1163, -0.1512])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.20.fc2.weight',\n",
       "               tensor([[-0.0337,  0.0144, -0.0108,  ..., -0.0367, -0.0090, -0.0749],\n",
       "                       [ 0.0470, -0.0230,  0.0097,  ...,  0.0132, -0.0243,  0.0660],\n",
       "                       [ 0.0010,  0.0413,  0.0034,  ...,  0.0047,  0.0165, -0.0467],\n",
       "                       ...,\n",
       "                       [-0.0323, -0.0276,  0.0037,  ...,  0.0082, -0.0266,  0.0536],\n",
       "                       [-0.0178,  0.0117,  0.0118,  ...,  0.0182, -0.0063,  0.0320],\n",
       "                       [-0.0393, -0.0182, -0.0183,  ..., -0.0182,  0.0657, -0.1025]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.20.fc2.bias',\n",
       "               tensor([-0.0649,  0.0381,  0.1208,  ...,  0.0313,  0.0267,  0.0676])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.20.final_layer_norm.weight',\n",
       "               tensor([0.4175, 0.4229, 0.4070,  ..., 0.4453, 0.4153, 0.4338])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.20.final_layer_norm.bias',\n",
       "               tensor([0.0114, 0.0640, 0.0360,  ..., 0.0612, 0.0130, 0.0013])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.21.self_attn.k_proj.weight',\n",
       "               tensor([[ 0.0776,  0.0158,  0.0714,  ..., -0.0690, -0.0374,  0.0129],\n",
       "                       [ 0.0544,  0.1312,  0.0102,  ..., -0.1843,  0.0120,  0.0040],\n",
       "                       [-0.0327, -0.0105, -0.1360,  ..., -0.0737,  0.0696, -0.0958],\n",
       "                       ...,\n",
       "                       [-0.0567, -0.1837, -0.0188,  ...,  0.0110,  0.0352,  0.1051],\n",
       "                       [-0.0368, -0.0141, -0.0319,  ...,  0.0742,  0.1324, -0.0190],\n",
       "                       [ 0.0059,  0.0368,  0.0437,  ..., -0.0371,  0.0381, -0.0057]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.21.self_attn.k_proj.bias',\n",
       "               tensor([-0.3064, -0.5137, -1.0547,  ...,  1.0107,  3.8848, -0.1309])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.21.self_attn.v_proj.weight',\n",
       "               tensor([[ 0.0175,  0.0068,  0.0343,  ..., -0.0095,  0.0052,  0.0021],\n",
       "                       [ 0.0031, -0.0639, -0.0105,  ..., -0.0778, -0.0095,  0.0070],\n",
       "                       [-0.0334,  0.0157,  0.0756,  ...,  0.0828, -0.0225,  0.0097],\n",
       "                       ...,\n",
       "                       [ 0.0543, -0.0767, -0.0489,  ..., -0.0461,  0.0500,  0.0372],\n",
       "                       [-0.0046,  0.0851, -0.0300,  ..., -0.0336, -0.0184,  0.0111],\n",
       "                       [-0.0039, -0.0110,  0.0601,  ...,  0.0212, -0.0116, -0.0040]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.21.self_attn.v_proj.bias',\n",
       "               tensor([-0.0056,  0.0063,  0.0127,  ...,  0.0113, -0.0268,  0.0013])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.21.self_attn.q_proj.weight',\n",
       "               tensor([[ 0.0630, -0.0095,  0.0032,  ...,  0.0086, -0.0208, -0.0089],\n",
       "                       [-0.0152,  0.1070, -0.0452,  ..., -0.0874,  0.1050, -0.1799],\n",
       "                       [-0.0113,  0.0768, -0.0388,  ...,  0.0148,  0.0157,  0.1240],\n",
       "                       ...,\n",
       "                       [-0.0081, -0.0477, -0.0717,  ...,  0.0325,  0.1379, -0.0856],\n",
       "                       [ 0.0491,  0.0011, -0.0810,  ..., -0.0894,  0.1061,  0.0226],\n",
       "                       [ 0.1147,  0.0279, -0.0188,  ...,  0.0153,  0.0274, -0.0982]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.21.self_attn.q_proj.bias',\n",
       "               tensor([ 0.0177,  0.2681, -0.0668,  ...,  0.0053, -0.1711,  0.0109])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.21.self_attn.out_proj.weight',\n",
       "               tensor([[ 0.0185,  0.0213, -0.0163,  ...,  0.0478,  0.0201,  0.0019],\n",
       "                       [ 0.0026, -0.0346,  0.0046,  ..., -0.0593,  0.0288,  0.0162],\n",
       "                       [ 0.0451, -0.0087,  0.0347,  ..., -0.0224, -0.0088,  0.0503],\n",
       "                       ...,\n",
       "                       [-0.0226, -0.0844,  0.0821,  ..., -0.0786, -0.0503,  0.0220],\n",
       "                       [ 0.0143, -0.0163,  0.0094,  ...,  0.0554,  0.0264,  0.0202],\n",
       "                       [ 0.0150,  0.0106, -0.0057,  ..., -0.0776,  0.0159,  0.0657]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.21.self_attn.out_proj.bias',\n",
       "               tensor([ 0.0042, -0.0028, -0.0293,  ..., -0.0070, -0.0171,  0.0156])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.21.self_attn_layer_norm.weight',\n",
       "               tensor([0.3540, 0.3599, 0.3662,  ..., 0.3423, 0.3628, 0.3560])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.21.self_attn_layer_norm.bias',\n",
       "               tensor([0.0428, 0.0743, 0.0478,  ..., 0.0418, 0.0811, 0.0630])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.21.fc1.weight',\n",
       "               tensor([[ 0.0083,  0.0058,  0.0271,  ..., -0.0237, -0.0425,  0.0195],\n",
       "                       [ 0.0899, -0.1431, -0.0247,  ...,  0.0185, -0.0502, -0.0305],\n",
       "                       [ 0.0219, -0.0414, -0.0895,  ...,  0.0443, -0.0118,  0.0908],\n",
       "                       ...,\n",
       "                       [ 0.0005,  0.0098, -0.0075,  ...,  0.0462, -0.0122, -0.0047],\n",
       "                       [-0.0739, -0.0294, -0.0890,  ..., -0.0144, -0.0551, -0.1422],\n",
       "                       [ 0.0263,  0.0061,  0.0102,  ...,  0.0368, -0.0024, -0.0021]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.21.fc1.bias',\n",
       "               tensor([ 0.0365, -0.2025, -0.0989,  ...,  0.0128, -0.1649,  0.0005])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.21.fc2.weight',\n",
       "               tensor([[-0.0068,  0.0288,  0.0103,  ..., -0.0019,  0.0024,  0.0056],\n",
       "                       [ 0.0328, -0.0057,  0.0162,  ..., -0.0287, -0.0053,  0.0531],\n",
       "                       [ 0.0077, -0.0128,  0.0106,  ...,  0.0175, -0.0210,  0.0301],\n",
       "                       ...,\n",
       "                       [-0.0324,  0.0391,  0.0181,  ..., -0.0535, -0.0114, -0.0381],\n",
       "                       [ 0.0272, -0.0745, -0.0005,  ...,  0.0889, -0.0195, -0.0185],\n",
       "                       [-0.0034, -0.0291,  0.0143,  ..., -0.0128, -0.0234,  0.0224]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.21.fc2.bias',\n",
       "               tensor([-0.0085,  0.0169,  0.1167,  ...,  0.0062,  0.0452,  0.0854])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.21.final_layer_norm.weight',\n",
       "               tensor([0.4407, 0.4224, 0.3909,  ..., 0.4124, 0.4170, 0.4724])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.21.final_layer_norm.bias',\n",
       "               tensor([0.0331, 0.0569, 0.0419,  ..., 0.0300, 0.0191, 0.0544])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.22.self_attn.k_proj.weight',\n",
       "               tensor([[ 0.0337,  0.0746,  0.0217,  ...,  0.0285, -0.0589, -0.0389],\n",
       "                       [ 0.0015, -0.1157,  0.1158,  ..., -0.0123, -0.0172, -0.0388],\n",
       "                       [ 0.1053, -0.0888,  0.0449,  ..., -0.0646, -0.0688,  0.0167],\n",
       "                       ...,\n",
       "                       [-0.0102, -0.0198,  0.0249,  ..., -0.0230, -0.0249, -0.0431],\n",
       "                       [ 0.0137,  0.1193, -0.0579,  ...,  0.0810,  0.0718,  0.0729],\n",
       "                       [-0.0792, -0.0153,  0.0144,  ...,  0.0546, -0.0164, -0.1473]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.22.self_attn.k_proj.bias',\n",
       "               tensor([-2.1992, -1.5088,  3.0449,  ...,  3.4492, -0.6445, -3.2246])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.22.self_attn.v_proj.weight',\n",
       "               tensor([[-0.0074,  0.0298, -0.0458,  ...,  0.0858,  0.0437, -0.0278],\n",
       "                       [ 0.0008, -0.0033,  0.0030,  ..., -0.0229,  0.0164, -0.0605],\n",
       "                       [-0.0140,  0.0533, -0.0216,  ..., -0.0251,  0.0252,  0.0191],\n",
       "                       ...,\n",
       "                       [-0.0197,  0.0410, -0.0083,  ...,  0.0135,  0.0143,  0.0009],\n",
       "                       [-0.0181,  0.0052, -0.0265,  ..., -0.0152,  0.0110, -0.0399],\n",
       "                       [ 0.0840, -0.0094,  0.0083,  ..., -0.0280, -0.0370, -0.0421]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.22.self_attn.v_proj.bias',\n",
       "               tensor([ 0.0102,  0.0111, -0.0121,  ...,  0.0053, -0.0138, -0.0076])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.22.self_attn.q_proj.weight',\n",
       "               tensor([[-0.0061,  0.1470,  0.1129,  ...,  0.0588,  0.1121,  0.0511],\n",
       "                       [-0.0115,  0.0125,  0.1223,  ...,  0.0519, -0.0012, -0.0217],\n",
       "                       [-0.0470, -0.0151,  0.0239,  ..., -0.0567, -0.0087, -0.0349],\n",
       "                       ...,\n",
       "                       [ 0.0820,  0.0647, -0.0139,  ...,  0.0575, -0.0258,  0.0045],\n",
       "                       [-0.0541,  0.0356, -0.0375,  ...,  0.0785,  0.0395,  0.1099],\n",
       "                       [-0.1008,  0.0042,  0.0562,  ..., -0.0706, -0.0378, -0.1376]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.22.self_attn.q_proj.bias',\n",
       "               tensor([ 0.1544,  0.2396, -0.1755,  ...,  0.2280, -0.0831, -0.3916])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.22.self_attn.out_proj.weight',\n",
       "               tensor([[-0.0333, -0.0274, -0.0093,  ..., -0.0264, -0.0051,  0.0391],\n",
       "                       [ 0.0163,  0.0042,  0.0267,  ...,  0.0243,  0.0041, -0.0161],\n",
       "                       [-0.0251,  0.0122, -0.0057,  ...,  0.0019,  0.0060, -0.0143],\n",
       "                       ...,\n",
       "                       [ 0.0340, -0.0006,  0.0039,  ...,  0.0374, -0.0134, -0.0359],\n",
       "                       [ 0.0581,  0.0040,  0.0144,  ..., -0.0178,  0.0290, -0.0237],\n",
       "                       [-0.0152, -0.0224,  0.0083,  ...,  0.0164, -0.0345, -0.0338]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.22.self_attn.out_proj.bias',\n",
       "               tensor([-0.0084,  0.0059, -0.0168,  ..., -0.0013,  0.0164, -0.0033])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.22.self_attn_layer_norm.weight',\n",
       "               tensor([0.3750, 0.3579, 0.3420,  ..., 0.3503, 0.3625, 0.3298])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.22.self_attn_layer_norm.bias',\n",
       "               tensor([0.0106, 0.0726, 0.0266,  ..., 0.0742, 0.0410, 0.0546])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.22.fc1.weight',\n",
       "               tensor([[-0.0685, -0.1210, -0.0726,  ...,  0.0133,  0.0125, -0.0154],\n",
       "                       [-0.1495, -0.0412, -0.1248,  ..., -0.0591,  0.0062,  0.0449],\n",
       "                       [-0.0040,  0.0171, -0.0471,  ...,  0.0704, -0.0147, -0.0107],\n",
       "                       ...,\n",
       "                       [-0.0082, -0.0484, -0.0217,  ...,  0.0011, -0.0154,  0.0400],\n",
       "                       [-0.0293, -0.0285, -0.0415,  ...,  0.0512, -0.1161, -0.0199],\n",
       "                       [ 0.0338, -0.0315, -0.0156,  ...,  0.0255,  0.0210,  0.0211]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.22.fc1.bias',\n",
       "               tensor([-0.2252, -0.2284, -0.0168,  ..., -0.0122, -0.0881, -0.0118])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.22.fc2.weight',\n",
       "               tensor([[-0.0201,  0.0639, -0.0117,  ...,  0.0367,  0.0001, -0.0037],\n",
       "                       [ 0.0421,  0.0060,  0.0382,  ...,  0.0107, -0.0399,  0.0071],\n",
       "                       [ 0.0016,  0.0201,  0.0055,  ...,  0.0131,  0.0133, -0.0402],\n",
       "                       ...,\n",
       "                       [-0.0240, -0.0303,  0.0179,  ..., -0.0062,  0.0492,  0.0448],\n",
       "                       [ 0.0144,  0.0038, -0.0278,  ...,  0.0081,  0.0197,  0.0638],\n",
       "                       [ 0.0213,  0.0030,  0.0290,  ...,  0.0056,  0.0140, -0.0091]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.22.fc2.bias',\n",
       "               tensor([-0.0194,  0.0167,  0.0362,  ..., -0.0398, -0.0449,  0.0353])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.22.final_layer_norm.weight',\n",
       "               tensor([0.3621, 0.3799, 0.3450,  ..., 0.3389, 0.3523, 0.3823])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.22.final_layer_norm.bias',\n",
       "               tensor([ 0.0385,  0.0241,  0.0429,  ...,  0.0216, -0.0084,  0.0386])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.23.self_attn.k_proj.weight',\n",
       "               tensor([[-0.1499, -0.0103,  0.0285,  ..., -0.0607, -0.0939,  0.0642],\n",
       "                       [ 0.0120,  0.1307,  0.0408,  ...,  0.0651,  0.0413, -0.0077],\n",
       "                       [-0.0282,  0.0527, -0.1200,  ..., -0.0551,  0.0256,  0.0235],\n",
       "                       ...,\n",
       "                       [-0.0271, -0.0480,  0.0114,  ..., -0.0126, -0.0329,  0.0305],\n",
       "                       [ 0.0197,  0.0098,  0.1473,  ...,  0.0436, -0.0989,  0.1170],\n",
       "                       [-0.1348,  0.0519,  0.0303,  ..., -0.0295,  0.0128, -0.0049]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.23.self_attn.k_proj.bias',\n",
       "               tensor([ 1.5049, -0.7524, -0.9097,  ..., -4.3242, -4.5586,  4.2930])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.23.self_attn.v_proj.weight',\n",
       "               tensor([[ 0.0505, -0.0765,  0.0228,  ..., -0.0330, -0.0215, -0.0090],\n",
       "                       [-0.0010,  0.0596,  0.0100,  ...,  0.0292, -0.0046, -0.0342],\n",
       "                       [ 0.0867,  0.0329,  0.0401,  ...,  0.0447,  0.0597, -0.0801],\n",
       "                       ...,\n",
       "                       [-0.0198, -0.0506,  0.0011,  ..., -0.1036,  0.0041, -0.0120],\n",
       "                       [ 0.0381, -0.0900, -0.0540,  ...,  0.0394, -0.0168,  0.0119],\n",
       "                       [ 0.0538, -0.0039,  0.0259,  ..., -0.0460,  0.0147, -0.0389]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.23.self_attn.v_proj.bias',\n",
       "               tensor([ 0.0020,  0.0010,  0.0147,  ..., -0.0071,  0.0193, -0.0138])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.23.self_attn.q_proj.weight',\n",
       "               tensor([[ 0.1216, -0.0212,  0.0317,  ..., -0.0284,  0.0447, -0.0237],\n",
       "                       [-0.0953, -0.0551, -0.0778,  ..., -0.0671, -0.0586,  0.0437],\n",
       "                       [ 0.0531,  0.0661,  0.1317,  ...,  0.0685,  0.1118,  0.0027],\n",
       "                       ...,\n",
       "                       [ 0.0943, -0.0636,  0.1082,  ..., -0.0321, -0.0271,  0.1097],\n",
       "                       [-0.0522,  0.0854, -0.1508,  ...,  0.1427,  0.0383, -0.1199],\n",
       "                       [ 0.0609,  0.0593, -0.0638,  ...,  0.0087,  0.0194, -0.0395]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.23.self_attn.q_proj.bias',\n",
       "               tensor([-0.0872, -0.1359,  0.2937,  ..., -0.1143, -0.0167,  0.2849])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.23.self_attn.out_proj.weight',\n",
       "               tensor([[-1.5823e-02, -7.0953e-03, -5.1178e-02,  ...,  9.3155e-03,\n",
       "                        -3.4515e-02, -2.2659e-02],\n",
       "                       [ 3.7415e-02, -3.1372e-02, -6.1340e-03,  ...,  6.1279e-02,\n",
       "                         8.9172e-02,  3.9101e-03],\n",
       "                       [-4.7760e-02, -7.8011e-03, -6.3049e-02,  ...,  2.1240e-02,\n",
       "                        -4.4060e-03,  4.2839e-03],\n",
       "                       ...,\n",
       "                       [-2.7218e-03,  3.0780e-04, -3.2898e-02,  ...,  9.4666e-02,\n",
       "                        -1.0544e-02,  5.4169e-02],\n",
       "                       [ 6.3241e-05, -5.9013e-03, -4.2175e-02,  ...,  3.7994e-02,\n",
       "                        -3.8986e-03, -3.3417e-02],\n",
       "                       [ 9.3613e-03,  1.5213e-02,  6.1340e-02,  ...,  2.9343e-02,\n",
       "                         7.7057e-03, -7.8812e-03]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.23.self_attn.out_proj.bias',\n",
       "               tensor([ 2.0638e-03,  4.5717e-05, -6.7520e-03,  ...,  1.9287e-02,\n",
       "                       -9.2087e-03,  1.5747e-02])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.23.self_attn_layer_norm.weight',\n",
       "               tensor([0.7061, 0.6841, 0.6680,  ..., 0.6914, 0.7031, 0.6650])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.23.self_attn_layer_norm.bias',\n",
       "               tensor([0.0820, 0.0876, 0.0779,  ..., 0.1022, 0.0701, 0.1016])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.23.fc1.weight',\n",
       "               tensor([[-0.0653,  0.0541,  0.0035,  ...,  0.0023, -0.0248, -0.1061],\n",
       "                       [ 0.0380, -0.0463,  0.0239,  ...,  0.0688, -0.0211,  0.0854],\n",
       "                       [-0.0117,  0.0533, -0.0368,  ..., -0.0106,  0.0426, -0.0452],\n",
       "                       ...,\n",
       "                       [-0.0040, -0.0159, -0.0075,  ...,  0.0464,  0.0543,  0.0394],\n",
       "                       [ 0.0035, -0.1054,  0.0379,  ..., -0.0077, -0.0129, -0.0208],\n",
       "                       [ 0.0886, -0.1033,  0.0755,  ..., -0.0011,  0.0211,  0.0325]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.23.fc1.bias',\n",
       "               tensor([-0.0331, -0.0326, -0.0871,  ..., -0.0620, -0.0474, -0.0231])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.23.fc2.weight',\n",
       "               tensor([[-0.0023, -0.0019, -0.0005,  ...,  0.0244, -0.0046, -0.0126],\n",
       "                       [ 0.0023, -0.0138, -0.0021,  ..., -0.0114, -0.0047, -0.0063],\n",
       "                       [-0.0082, -0.0306,  0.0164,  ..., -0.0359, -0.0176, -0.0091],\n",
       "                       ...,\n",
       "                       [-0.0113, -0.0092, -0.0392,  ...,  0.0051,  0.0097, -0.0051],\n",
       "                       [ 0.0132,  0.0153, -0.0274,  ..., -0.0066,  0.0121,  0.0140],\n",
       "                       [ 0.0135, -0.0092, -0.0105,  ..., -0.0260, -0.0105, -0.0038]])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.23.fc2.bias',\n",
       "               tensor([-0.0206,  0.0496, -0.0207,  ...,  0.0255,  0.0013,  0.0611])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.23.final_layer_norm.weight',\n",
       "               tensor([0.4653, 0.4888, 0.3330,  ..., 0.3064, 0.3516, 0.3735])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layers.23.final_layer_norm.bias',\n",
       "               tensor([ 0.0218,  0.0202,  0.0130,  ...,  0.0275, -0.0072,  0.0556])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layer_norm.weight',\n",
       "               tensor([0.2556, 0.1467, 0.2698,  ..., 0.1744, 0.3418, 0.2837])),\n",
       "              ('w2v_encoder.w2v_model.encoder.layer_norm.bias',\n",
       "               tensor([0.0272, 0.0143, 0.0402,  ..., 0.0168, 0.0283, 0.0461])),\n",
       "              ('w2v_encoder.w2v_model.layer_norm.weight',\n",
       "               tensor([ 0.3032,  0.4919,  0.6553,  0.3936,  0.2949,  0.3857,  0.3613,  0.3796,\n",
       "                        0.4331,  0.3765,  0.5630,  0.4587,  0.3416,  0.3159,  0.3884,  0.4199,\n",
       "                        0.2515,  0.3391,  0.7607,  0.4004,  0.4209,  0.5596,  0.4221,  0.4443,\n",
       "                        0.3381,  0.3416,  0.3906,  0.3752,  0.3489,  0.4373,  0.4419,  0.3367,\n",
       "                        0.4380,  0.3384,  0.4519,  0.3140,  0.2869,  0.2903,  0.3313,  0.3367,\n",
       "                        0.3333,  0.3787,  0.2798,  0.3320,  0.4048,  0.3650,  0.4229,  0.6357,\n",
       "                        0.4521,  0.3567,  0.3118,  0.3384,  0.3027,  0.3652,  0.3335,  0.3130,\n",
       "                        0.2581,  0.3870,  0.2444,  0.4399,  0.3943,  0.5757,  0.4543,  0.4060,\n",
       "                        0.4829,  0.4111,  0.1746,  0.4458,  0.3867,  0.6069,  0.2568,  0.3020,\n",
       "                        0.3003,  0.2864,  0.2153,  0.4229,  0.3328,  0.5381,  0.6138,  0.3801,\n",
       "                        0.4321,  0.3892,  0.1703,  0.3618,  0.3931,  0.3518,  0.4565,  0.3958,\n",
       "                        0.4138,  0.5146,  0.3030,  0.3550,  0.5000,  0.3069,  0.2620,  0.4365,\n",
       "                        0.4153,  0.4390,  0.3694,  0.4358,  0.4260,  0.3843,  0.4365,  0.2671,\n",
       "                        0.3218,  0.3928,  0.4119,  0.3857,  0.3381,  0.3367,  0.4709,  0.3491,\n",
       "                        0.5376,  0.3757,  0.2952,  0.4983,  0.3850,  0.5024,  0.4238,  0.3125,\n",
       "                        0.4128,  0.3315,  0.6050,  0.4429,  0.3643,  0.3586,  0.4128,  0.4192,\n",
       "                        0.4773,  0.4001,  0.4614,  0.3389,  0.3813,  0.4158,  0.3938,  0.2913,\n",
       "                        0.2856,  0.5723,  0.4343,  0.3171,  0.2893,  0.2786,  0.3796,  0.4436,\n",
       "                        0.3386,  0.3657,  0.3887,  0.4189,  0.4255,  0.3005,  0.5361,  0.1814,\n",
       "                        0.4036,  0.4619,  0.4551,  0.3267,  0.4922,  0.1648,  0.3320,  0.3855,\n",
       "                        0.5469,  0.3130,  0.3728,  0.3364,  0.3052,  0.4021,  0.3555,  0.3806,\n",
       "                        0.4355,  0.3215,  0.3953,  0.4739,  0.3660,  0.2908,  0.3845,  0.5103,\n",
       "                        0.4080,  0.4194,  0.2583,  0.3713,  0.5083,  0.3640,  0.5835,  0.4814,\n",
       "                        0.4529,  0.4365,  0.4927,  0.2479,  0.3733,  0.4539,  0.6450,  0.3657,\n",
       "                        0.3118,  0.5933,  0.4507,  0.4182,  0.3186,  0.2537,  0.2441,  0.3755,\n",
       "                        0.4885,  0.4089,  0.3025,  0.3843,  0.3708,  0.3237,  0.3330,  0.4817,\n",
       "                        0.2408,  0.3640,  0.6230,  0.4287,  0.2996,  0.3733,  0.4456,  0.3772,\n",
       "                        0.3833,  0.2708, -1.0996,  0.4714,  0.4233,  0.4829,  0.3447,  0.4807,\n",
       "                        0.5278,  0.3662,  0.4985,  0.4331,  0.5396,  0.3921,  0.3926,  0.3027,\n",
       "                        0.4678,  0.2068,  0.5039,  0.3472,  0.3489,  0.4700,  0.3000,  0.3542,\n",
       "                        0.3535,  0.3977,  0.3513,  0.3857,  0.4175,  0.3696,  0.4084,  0.4126,\n",
       "                        0.4946,  0.4346,  0.4180,  0.4006,  0.3848,  0.3442,  0.3618,  0.4109,\n",
       "                        0.3816,  0.3591,  0.4338,  0.4265,  0.3806,  0.5303,  0.5039,  0.5786,\n",
       "                        0.3127,  0.3008,  0.7251,  0.3960,  0.4124,  0.4424,  0.3621,  0.4126,\n",
       "                        0.4299,  0.3599,  0.5674,  0.4802,  0.6733,  0.3855,  0.3755,  0.2588,\n",
       "                        0.5381,  0.2433,  0.1444,  0.3315,  0.3799,  0.3586,  0.2573,  0.5073,\n",
       "                        0.4714,  0.3511,  0.5415,  0.4231,  0.4207,  0.4597,  0.4377,  0.4062,\n",
       "                        0.4956,  0.4248,  0.1761,  0.4927,  0.3840,  0.3442,  0.3887,  0.3245,\n",
       "                        0.5791,  0.4597,  0.4546,  0.4929,  0.5029,  0.3706,  0.4636,  0.1631,\n",
       "                        0.4512,  0.2954,  0.3523,  0.1671,  0.6411,  0.5083,  0.3450,  0.3057,\n",
       "                        0.5562,  0.3767,  0.3782,  0.3098,  0.4165,  0.3787,  0.4028,  0.4453,\n",
       "                        0.3630,  0.4749,  0.1860,  0.3640,  0.5645,  0.3501,  0.4763,  0.4302,\n",
       "                        0.3557,  0.3762,  0.3318,  0.5601,  0.3975,  0.3862,  0.4421,  0.3672,\n",
       "                        0.4319,  0.4163,  0.3845,  0.5225,  0.4158,  0.7026,  0.3723,  0.2969,\n",
       "                        0.3674,  0.3242,  0.3655,  0.3816,  0.1324,  0.4141,  0.3242,  0.4373,\n",
       "                        0.3342,  0.3816,  0.4485,  0.2991,  0.5137,  0.3269,  0.2095,  0.3975,\n",
       "                        0.3044,  0.5615,  0.7241,  0.7666,  0.3540,  0.5142,  0.4626,  0.3232,\n",
       "                        0.3223,  0.5522,  0.3220,  0.3164,  0.4124,  0.3650,  0.3728,  0.3567,\n",
       "                        0.4973,  0.3748,  0.4121,  0.3630,  0.3594,  0.3420,  0.3833,  0.5029,\n",
       "                        0.4492,  0.5786,  0.5767,  0.4268,  0.2454,  0.4404,  0.4692,  0.3289,\n",
       "                        0.3799,  0.2786,  0.5132,  0.4656,  0.3738,  0.3523,  0.3003,  0.4429,\n",
       "                        0.2212,  0.5508,  0.4568,  0.4290,  0.3525,  0.3979,  0.3345,  0.4846,\n",
       "                        0.3083,  0.3818,  0.3721,  0.2427,  0.4023,  0.3521,  0.3962,  0.3088,\n",
       "                        0.0643,  0.4468,  0.5698,  0.3662,  0.5483,  0.4661,  0.4290,  0.5996,\n",
       "                        0.3745,  0.2729,  0.2220,  0.3811,  0.5737,  0.5708,  0.3633,  0.6729,\n",
       "                        0.3721,  0.4119,  0.3418,  0.4736,  0.3105,  0.3350,  0.2883,  0.8550,\n",
       "                        0.3096,  0.3601,  0.2227,  0.4763,  0.4429,  0.3662,  0.4795,  0.6147,\n",
       "                        0.3391,  0.3623,  0.3142,  0.4031,  0.4495,  0.4285,  0.2869,  0.3921,\n",
       "                        0.3640,  0.2192,  0.4199,  0.5693,  0.3394,  0.4468,  0.3796,  0.5981,\n",
       "                        0.3213,  0.3816,  0.3191,  0.3987,  0.3992,  0.2883,  0.2905,  0.2500,\n",
       "                        0.5205,  0.3943,  0.4880,  0.4495,  0.5454,  0.5425,  0.4629,  0.6357,\n",
       "                        0.4385,  0.4644,  0.4031,  0.4885,  0.3621,  0.3691,  0.3840,  0.3767,\n",
       "                        0.3958,  0.4500,  0.4648,  0.4026,  0.3281,  0.4729,  0.3904,  0.4463,\n",
       "                        0.3152,  0.3704,  0.3362,  0.2871,  0.4253,  0.4116,  1.3369,  0.2969])),\n",
       "              ('w2v_encoder.w2v_model.layer_norm.bias',\n",
       "               tensor([ 0.0224, -0.3599, -0.2412, -0.0059, -0.0232, -0.0050,  0.1118, -0.1719,\n",
       "                        0.0709,  0.0928,  0.0803,  0.1692,  0.1026, -0.0051,  0.0229, -0.1360,\n",
       "                        0.1205,  0.1049, -0.0739,  0.0258, -0.2717, -0.2793,  0.3113, -0.0489,\n",
       "                        0.0886,  0.3447,  0.3169,  0.1213,  0.1144,  0.2502, -0.1085, -0.1498,\n",
       "                       -0.1245, -0.0208, -0.1826,  0.1641,  0.0264,  0.1511,  0.1146, -0.1843,\n",
       "                        0.1995, -0.0508,  0.1429,  0.2079,  0.2666, -0.0854, -0.1976, -0.2211,\n",
       "                       -0.0183, -0.3064,  0.1512,  0.2266,  0.0893, -0.0865,  0.1575,  0.1390,\n",
       "                       -0.0914, -0.0042, -0.0057,  0.2123,  0.0417, -0.1683,  0.0922, -0.1993,\n",
       "                       -0.1078,  0.0170, -0.0014,  0.2515, -0.2198,  0.0078, -0.0035, -0.0883,\n",
       "                       -0.1379,  0.0741,  0.0256, -0.0145,  0.0681, -0.2354, -0.0801,  0.2756,\n",
       "                       -0.1742,  0.1242,  0.0437,  0.0942, -0.1302, -0.1182, -0.0714, -0.1346,\n",
       "                       -0.1610,  0.0264, -0.1602, -0.1561, -0.0534,  0.1287, -0.0107, -0.0670,\n",
       "                        0.0997, -0.2878, -0.0897,  0.0549, -0.1323, -0.0665,  0.1710,  0.0554,\n",
       "                       -0.0993,  0.1487, -0.0854,  0.0464,  0.1289,  0.0322, -0.2222,  0.0217,\n",
       "                        0.2179,  0.0812,  0.1144, -0.0576, -0.1764, -0.0168,  0.2278,  0.0286,\n",
       "                       -0.1451,  0.0525,  0.1338,  0.2786,  0.0936,  0.1310,  0.0077,  0.1263,\n",
       "                       -0.4114, -0.1735, -0.2365, -0.0247,  0.2554,  0.3110, -0.0981,  0.0052,\n",
       "                        0.3296, -0.1442,  0.2014,  0.0655,  0.0069, -0.1283, -0.2432,  0.0337,\n",
       "                        0.1028, -0.0671, -0.0528, -0.0042,  0.0654,  0.1041,  0.4509,  0.0596,\n",
       "                       -0.0083, -0.1807,  0.1769, -0.0370, -0.1047,  0.2939,  0.1931,  0.0614,\n",
       "                       -0.1890,  0.0587, -0.1571, -0.3013,  0.0983, -0.0685, -0.0600,  0.1113,\n",
       "                       -0.0259,  0.2864,  0.0107, -0.1296,  0.0186,  0.0169, -0.1974, -0.2927,\n",
       "                        0.0125, -0.1846, -0.1554,  0.1624, -0.1063,  0.0759,  0.3389,  0.4211,\n",
       "                       -0.1279,  0.2888,  0.4080,  0.2505, -0.1348, -0.1021, -0.4482,  0.2656,\n",
       "                       -0.0100, -0.2189,  0.0463,  0.0557,  0.0854,  0.1361,  0.1536, -0.0063,\n",
       "                       -0.2593,  0.2318, -0.0858, -0.1274,  0.0322,  0.2158, -0.0541,  0.1931,\n",
       "                        0.2163,  0.2842,  0.1279, -0.0447,  0.0390, -0.0492, -0.2551,  0.1091,\n",
       "                       -0.0168, -0.0389,  0.1677,  0.0795,  0.2130,  0.5947,  0.1324, -0.0091,\n",
       "                        0.4741,  0.2012, -0.1340,  0.0853, -0.4119,  0.0472, -0.0129,  0.0098,\n",
       "                       -0.0205,  0.0363,  0.0551, -0.0133, -0.1041, -0.1809, -0.1235, -0.0280,\n",
       "                        0.0546,  0.0837,  0.0380,  0.0318,  0.2859,  0.0948,  0.1846, -0.0092,\n",
       "                        0.2881, -0.1245, -0.0402,  0.0195,  0.0148, -0.0032,  0.0782,  0.0487,\n",
       "                       -0.0359, -0.2327, -0.1959,  0.0815,  0.3745, -0.1278, -0.3596,  0.3118,\n",
       "                       -0.0222,  0.0048, -0.5469, -0.2444,  0.0079,  0.0584, -0.1759,  0.0575,\n",
       "                       -0.0591, -0.1099, -0.1140, -0.1436, -0.2379,  0.1554,  0.0778, -0.0055,\n",
       "                        0.1832,  0.0895,  0.1486,  0.0650,  0.0501,  0.0581,  0.1407,  0.0724,\n",
       "                       -0.1980,  0.0075,  0.0898,  0.1449, -0.1465,  0.1842,  0.0535,  0.1536,\n",
       "                       -0.2183,  0.0148,  0.0584, -0.1313,  0.1775, -0.0283,  0.0357,  0.2008,\n",
       "                        0.5684,  0.1132,  0.0948, -0.2942,  0.1647, -0.0705, -0.0196,  0.1072,\n",
       "                        0.3037, -0.0682, -0.1263, -0.0710,  0.0130, -0.3955,  0.0857,  0.1226,\n",
       "                       -0.0825,  0.0715,  0.0724, -0.1292, -0.2439, -0.0225,  0.1971, -0.2115,\n",
       "                       -0.0304, -0.2739,  0.1404,  0.0927,  0.1218, -0.0238, -0.1616, -0.1166,\n",
       "                        0.0176,  0.0101, -0.1162,  0.3435, -0.1133,  0.0399,  0.0255,  0.0156,\n",
       "                        0.1360,  0.2264,  0.0795, -0.2610, -0.0264,  0.3601,  0.2854,  0.0726,\n",
       "                        0.2654,  0.1858, -0.2734,  0.0007, -0.2502, -0.1154, -0.1666,  0.0072,\n",
       "                        0.0745,  0.0054,  0.1421, -0.0160, -0.0704,  0.0029, -0.0935, -0.1421,\n",
       "                        0.1065,  0.2886,  0.1198, -0.0300,  0.0927,  0.2274,  0.0327,  0.1307,\n",
       "                        0.0584, -0.3147,  0.1210,  0.0071, -0.3118,  0.0798,  0.0507, -0.0090,\n",
       "                       -0.1365,  0.1442, -0.0731, -0.0620, -0.2573, -0.0336,  0.2114, -0.1942,\n",
       "                        0.0503, -0.3452, -0.1963, -0.2917,  0.1373, -0.1081, -0.2700, -0.0048,\n",
       "                       -0.0434, -0.0091, -0.0766,  0.0542,  0.1545, -0.1144,  0.0895,  0.0786,\n",
       "                        0.2186, -0.2864,  0.2339, -0.0701,  0.0573, -0.0270, -0.0386,  0.2037,\n",
       "                        0.0339, -0.0760,  0.2708,  0.0079,  0.1538,  0.0356,  0.0409,  0.0157,\n",
       "                       -0.0155, -0.1158, -0.0998,  0.0750, -0.0900,  0.2991, -0.1976, -0.0640,\n",
       "                        0.3489,  0.1184, -0.0616,  0.0616, -0.0962, -0.1214,  0.1538, -0.3367,\n",
       "                        0.0319,  0.0911,  0.0279,  0.5586, -0.0673,  0.1151, -0.0293, -0.1227,\n",
       "                        0.0892, -0.1122,  0.0813,  0.0249, -0.0710, -0.0312, -0.1006,  0.0876,\n",
       "                       -0.0513, -0.1923, -0.0324, -0.2156, -0.3469,  0.1157, -0.1086, -0.1241,\n",
       "                       -0.1121,  0.1011, -0.0781,  0.0756, -0.0871,  0.0721,  0.0244,  0.0659,\n",
       "                       -0.1647, -0.2316,  0.1783, -0.1104,  0.2666,  0.0965,  0.0123,  0.0024,\n",
       "                       -0.0041, -0.2229, -0.3142,  0.2947, -0.2128, -0.0168, -0.1997, -0.0884,\n",
       "                        0.2052, -0.1228,  0.1888, -0.0222,  0.0245,  0.1262,  0.0127,  0.0998,\n",
       "                        0.1677, -0.3450, -0.3108, -0.2520, -0.0463,  0.2705,  0.0442,  0.2839,\n",
       "                        0.1548, -0.0040,  0.0394, -0.0703, -0.3120, -0.0601, -0.1417, -0.1204])),\n",
       "              ('w2v_encoder.w2v_model.contr_proj.weight',\n",
       "               tensor([[-4.3335e-03, -9.7351e-02,  7.7271e-02,  ..., -1.0040e-02,\n",
       "                         3.3936e-02, -1.3771e-02],\n",
       "                       [ 1.3107e-02,  1.3501e-01, -1.0193e-01,  ...,  5.1849e-02,\n",
       "                         2.1790e-02, -1.2337e-02],\n",
       "                       [ 8.7595e-04,  5.2414e-03,  2.6108e-02,  ..., -1.0962e-01,\n",
       "                        -1.0204e-03, -1.0941e-02],\n",
       "                       ...,\n",
       "                       [ 5.5046e-03, -8.8501e-02, -2.7344e-02,  ..., -1.0040e-01,\n",
       "                         2.4597e-02, -4.8920e-02],\n",
       "                       [ 5.0842e-02, -1.6785e-01, -1.1075e-04,  ...,  3.8086e-02,\n",
       "                        -2.3956e-02, -2.8362e-03],\n",
       "                       [-5.7159e-02,  1.9951e-03,  3.2532e-02,  ...,  2.8671e-02,\n",
       "                        -3.0014e-02, -9.4910e-03]])),\n",
       "              ('w2v_encoder.w2v_model.contr_proj.bias',\n",
       "               tensor([ 1.5198e-01,  1.2402e-01, -2.2034e-02,  2.4414e-01,  1.4185e-01,\n",
       "                       -1.4819e-01,  1.3391e-01, -2.0874e-01,  1.6492e-01, -1.3879e-01,\n",
       "                       -2.3584e-01, -9.9182e-02,  1.4404e-01,  2.4170e-01,  1.8713e-01,\n",
       "                       -4.6600e-02,  8.0078e-02, -2.6978e-01, -1.7456e-01,  2.8439e-03,\n",
       "                       -5.2734e-02,  1.5588e-01,  1.3245e-01,  1.4844e-01,  6.7078e-02,\n",
       "                        1.2672e-02,  1.4551e-01, -2.2388e-01,  1.6577e-01,  2.9443e-01,\n",
       "                        1.0486e-01, -1.8448e-02, -1.9153e-01, -1.4473e-02,  2.2595e-01,\n",
       "                        2.9297e-01,  3.7183e-01,  1.3147e-01, -3.5431e-02, -3.5583e-02,\n",
       "                        9.3689e-02, -2.9236e-02, -3.5083e-01,  3.1055e-01,  1.4259e-02,\n",
       "                       -5.0140e-02, -1.5942e-01, -1.2585e-01, -3.1494e-01,  8.9264e-03,\n",
       "                        8.4595e-02,  2.0361e-01, -1.2250e-01, -2.4918e-02, -1.2140e-01,\n",
       "                        2.9077e-01, -1.3696e-01,  4.0131e-02,  7.1716e-02, -1.5063e-01,\n",
       "                       -1.5491e-01, -2.0691e-01,  1.8250e-01,  1.7126e-01,  1.7249e-01,\n",
       "                       -1.0022e-01,  7.2205e-02,  1.5576e-01, -8.9417e-02,  5.8098e-03,\n",
       "                        8.5297e-03,  7.0557e-02,  1.4587e-01, -4.7882e-02, -1.5637e-01,\n",
       "                       -3.6255e-02,  1.4844e-01, -1.3208e-01,  1.5234e-01,  2.6855e-01,\n",
       "                        6.1615e-02, -2.2693e-01,  1.0181e-01,  1.7847e-01,  1.3989e-01,\n",
       "                        5.6915e-02, -5.3131e-02,  7.0618e-02, -4.7821e-02,  1.1133e-01,\n",
       "                        6.3416e-02,  1.3145e-02,  1.1340e-01, -1.6101e-01,  1.2512e-01,\n",
       "                        6.8298e-02,  1.2573e-01,  2.7115e-02,  4.6143e-02,  6.2904e-03,\n",
       "                       -3.4814e-01, -2.5195e-01, -1.6064e-01,  4.5898e-02,  6.5660e-04,\n",
       "                        2.0508e-01, -1.2067e-01, -5.1514e-02,  3.6835e-02, -7.2815e-02,\n",
       "                       -2.5314e-02, -5.9235e-02,  2.0764e-01, -1.4783e-01,  2.1179e-02,\n",
       "                       -6.9275e-02, -3.2495e-01,  2.0789e-01, -6.6345e-02,  1.7224e-01,\n",
       "                       -2.4316e-01, -3.8940e-02,  1.4069e-02,  2.5757e-01,  1.0529e-01,\n",
       "                        4.2877e-02, -3.1021e-02, -1.8701e-01,  5.4840e-02,  2.2263e-02,\n",
       "                       -2.1948e-01,  1.0706e-01, -7.7881e-02, -2.4268e-01, -2.4255e-01,\n",
       "                        2.1814e-01,  2.5928e-01, -8.4457e-03,  1.7532e-02, -8.3984e-02,\n",
       "                        1.2012e-01, -2.9492e-01, -2.5604e-02, -6.5857e-02,  3.2898e-02,\n",
       "                        2.1680e-01, -4.2041e-01,  8.2764e-02, -4.3091e-02,  3.8544e-02,\n",
       "                       -2.5317e-01,  2.7563e-01, -1.7139e-01, -7.6843e-02, -2.2302e-01,\n",
       "                       -1.2292e-01, -1.5686e-01, -7.9590e-02,  4.6326e-02,  1.5045e-02,\n",
       "                       -1.2018e-01, -9.7900e-02,  8.0811e-02,  1.1108e-02, -1.7395e-01,\n",
       "                        1.2720e-01,  7.2327e-02, -2.3413e-01,  6.1005e-02, -5.1575e-02,\n",
       "                        4.3610e-02, -1.2384e-01,  2.9126e-01, -8.8043e-03,  2.1704e-01,\n",
       "                       -3.7445e-02, -7.1411e-02,  1.0944e-01, -3.2666e-01,  2.9541e-01,\n",
       "                        2.2021e-01, -1.1243e-01, -1.3399e-03,  1.6403e-02, -8.6670e-02,\n",
       "                       -3.0420e-01, -1.0583e-01,  8.3191e-02,  1.0620e-01, -6.3782e-02,\n",
       "                        4.3701e-02,  6.7322e-02, -1.5259e-02,  1.4233e-01,  5.2147e-03,\n",
       "                        5.7434e-02,  2.6978e-01,  5.8472e-02,  1.2042e-01,  4.0100e-02,\n",
       "                        9.9945e-03,  6.5063e-02, -3.1834e-03,  7.9224e-02, -5.9998e-02,\n",
       "                        1.2744e-01, -2.3511e-01, -7.7209e-02,  4.2432e-01,  6.6040e-02,\n",
       "                       -2.6807e-01, -1.8445e-01, -3.4973e-02, -8.6670e-02,  1.2585e-01,\n",
       "                        1.8921e-01, -3.0469e-01,  3.0762e-01,  1.7371e-01,  8.7891e-02,\n",
       "                        3.3607e-03,  6.0455e-02, -3.9124e-02, -4.4098e-02,  7.8552e-02,\n",
       "                        9.5764e-02, -1.9882e-02, -5.7831e-02,  1.5479e-01, -2.0764e-01,\n",
       "                        1.9913e-02,  6.7322e-02,  8.3008e-02, -1.0657e-01,  3.4277e-01,\n",
       "                        2.6978e-01,  1.2329e-01,  2.0203e-01,  7.0923e-02,  1.5833e-01,\n",
       "                        1.0785e-01, -2.1521e-01,  1.8970e-01,  1.4868e-01,  3.2440e-02,\n",
       "                        2.1851e-01, -1.4368e-01,  1.2170e-01,  3.8239e-02, -1.3489e-01,\n",
       "                        2.8488e-02,  2.1509e-01, -2.2363e-01,  3.5205e-01,  6.4163e-03,\n",
       "                       -9.9792e-03,  1.5027e-01,  2.1423e-01, -2.1997e-01, -1.0303e-01,\n",
       "                        1.6895e-01, -6.7261e-02,  1.6980e-01, -1.0876e-01, -1.7212e-01,\n",
       "                       -2.0020e-01, -5.5923e-03,  1.2891e-01,  7.7759e-02, -1.8079e-01,\n",
       "                        6.8436e-03,  7.2784e-03, -2.3560e-01,  1.8152e-01, -3.7109e-01,\n",
       "                       -8.2886e-02, -1.0120e-01,  1.1401e-01, -1.1499e-01, -1.1096e-01,\n",
       "                       -1.6953e-02, -6.9824e-02, -1.7371e-01,  7.7553e-03, -2.4390e-01,\n",
       "                        3.2324e-01,  1.6931e-01, -7.9773e-02,  2.0279e-02, -2.9739e-02,\n",
       "                       -1.1609e-01, -3.1128e-01,  2.9785e-01, -4.1077e-02, -3.3301e-01,\n",
       "                        8.0383e-02, -3.0914e-02,  9.1980e-02,  7.1594e-02, -3.4882e-02,\n",
       "                       -2.1118e-01,  8.9539e-02,  4.3365e-02,  5.3009e-02, -4.4708e-02,\n",
       "                       -1.3367e-01,  2.9980e-01,  2.5830e-01,  7.2212e-03,  3.8135e-01,\n",
       "                        3.7885e-04,  3.0746e-02,  1.1584e-01,  5.3192e-02,  1.5808e-02,\n",
       "                       -4.6570e-02,  1.3135e-01, -9.5093e-02,  7.7942e-02, -1.6858e-01,\n",
       "                       -3.4546e-02,  2.0172e-02, -8.1543e-02, -2.5513e-01, -4.1357e-01,\n",
       "                       -2.9068e-02, -3.4119e-02, -1.1865e-01, -5.0537e-02,  1.4023e-02,\n",
       "                       -2.0361e-01, -5.4688e-02,  1.2183e-01, -2.5314e-02, -1.4587e-01,\n",
       "                        2.7298e-02,  2.7393e-01,  1.1005e-01, -1.6138e-01, -1.7102e-01,\n",
       "                        2.6807e-01, -3.4515e-02, -5.0934e-02,  3.7476e-01, -1.2140e-01,\n",
       "                        1.4319e-01, -5.7953e-02, -2.4460e-02,  1.1597e-01,  1.2274e-03,\n",
       "                        2.7405e-02, -1.1938e-01,  1.9788e-01, -9.1064e-02, -2.4573e-01,\n",
       "                        1.6187e-01,  2.0981e-02, -3.3594e-01, -2.2437e-01,  6.0028e-02,\n",
       "                        2.2839e-01,  2.2217e-01,  7.6172e-02, -7.5317e-02, -1.7053e-01,\n",
       "                       -7.5134e-02, -6.6101e-02,  1.0864e-01,  8.9233e-02,  2.4365e-01,\n",
       "                       -1.4758e-01, -1.1102e-01,  1.1139e-01, -2.4902e-02, -1.0468e-01,\n",
       "                       -8.2336e-02, -5.1819e-02,  1.9702e-01, -1.1249e-01,  1.0818e-02,\n",
       "                       -1.4807e-01,  2.1069e-01, -6.8787e-02,  6.2683e-02,  1.8042e-01,\n",
       "                       -1.4905e-01,  1.8036e-02, -2.2144e-01,  4.8187e-02,  8.6975e-02,\n",
       "                        9.0027e-02,  9.4666e-02,  1.1780e-01,  2.0435e-01, -9.0332e-02,\n",
       "                       -1.2535e-02, -2.3267e-01,  1.8896e-01, -1.6052e-02, -1.7471e-02,\n",
       "                        3.8586e-03, -1.4343e-01, -5.4718e-02, -1.8140e-01, -8.7891e-02,\n",
       "                       -2.8247e-01, -4.3671e-02,  9.0393e-02, -9.0698e-02,  1.5173e-01,\n",
       "                       -2.9343e-02, -1.0681e-01,  1.8152e-01,  6.3372e-04,  1.4868e-01,\n",
       "                        7.7148e-02,  2.0630e-01, -8.7891e-02,  1.1902e-01, -1.8140e-01,\n",
       "                       -3.0566e-01, -2.1774e-02, -2.3010e-02,  2.1411e-01,  2.9248e-01,\n",
       "                        9.8206e-02,  9.0881e-02, -4.4250e-02, -3.4332e-02, -8.6914e-02,\n",
       "                        1.8616e-01,  1.5283e-01, -8.6365e-02, -2.9419e-01, -6.2103e-02,\n",
       "                       -3.8257e-01, -5.7709e-02,  1.9128e-01,  1.8774e-01, -1.4778e-02,\n",
       "                        1.8225e-01, -3.0713e-01,  2.6318e-01,  1.3542e-03, -1.4429e-03,\n",
       "                       -1.2846e-03, -1.8225e-01,  2.0520e-01, -2.1313e-01, -1.6785e-01,\n",
       "                       -7.4341e-02, -5.6839e-03, -3.3325e-02, -1.4917e-01, -1.0950e-01,\n",
       "                        9.6069e-02,  9.6191e-02, -1.3562e-01,  1.4307e-01, -1.8005e-01,\n",
       "                       -3.0273e-01, -2.8030e-02, -4.9305e-04,  1.1462e-01,  9.6558e-02,\n",
       "                       -4.2480e-02, -3.0029e-01,  1.7944e-01,  8.7830e-02,  1.4233e-01,\n",
       "                        1.3428e-01,  9.8694e-02, -1.8933e-01,  6.4575e-02,  3.3276e-01,\n",
       "                       -1.5649e-01,  4.9683e-02,  1.6870e-01, -3.5938e-01, -3.7354e-02,\n",
       "                        3.1592e-01,  1.5210e-01, -3.6438e-02, -2.5513e-01,  1.4966e-01,\n",
       "                       -4.0405e-01,  1.8103e-01, -9.8572e-02, -8.6670e-02,  3.8062e-01,\n",
       "                       -1.9885e-01,  9.4604e-02, -2.2232e-02,  6.9153e-02,  1.9974e-02,\n",
       "                       -4.3304e-02, -2.3608e-01, -3.7018e-02, -3.6682e-02, -1.0162e-02,\n",
       "                        1.0443e-01,  8.6731e-02, -2.6318e-01,  1.6937e-02,  9.0332e-02,\n",
       "                       -1.7041e-01, -1.1871e-01,  8.9722e-03, -2.1399e-01, -1.7322e-01,\n",
       "                       -5.1819e-02, -1.0643e-02, -1.2952e-01, -1.1780e-01, -6.7993e-02,\n",
       "                        1.5686e-01, -4.1016e-02, -1.6821e-01,  2.5391e-01, -2.7295e-01,\n",
       "                        9.4177e-02, -2.7271e-01, -7.6904e-02, -2.4261e-02, -2.1229e-03,\n",
       "                        1.7853e-02, -6.8808e-04, -3.4814e-01,  2.1347e-02, -6.1890e-02,\n",
       "                        1.6614e-01,  2.9468e-01, -1.8677e-01, -1.1163e-01, -2.7661e-01,\n",
       "                        1.2549e-01, -2.5806e-01, -2.3828e-01, -6.5735e-02,  2.3975e-01,\n",
       "                       -1.2199e-02,  2.2925e-01, -9.6802e-02,  4.2358e-02,  1.6125e-01,\n",
       "                       -1.8884e-01,  1.6003e-01,  1.0277e-02, -1.8420e-01,  3.8110e-01,\n",
       "                       -3.3142e-02,  4.3750e-01, -1.4050e-01, -1.7847e-01,  4.1992e-02,\n",
       "                        1.2856e-03, -2.7490e-01, -9.1187e-02, -2.4756e-01,  6.6406e-02,\n",
       "                        7.8796e-02,  1.9897e-01,  7.2388e-02, -5.2399e-02,  2.3853e-01,\n",
       "                       -1.4050e-01,  2.3242e-01,  2.4866e-01,  1.8909e-01,  1.6858e-01,\n",
       "                       -1.7773e-01, -4.0497e-02, -5.3558e-02, -2.1985e-01, -4.1229e-02,\n",
       "                       -2.4072e-01, -6.0608e-02, -3.2446e-01, -7.9651e-02, -2.6587e-01,\n",
       "                        4.1821e-01,  4.7974e-02,  3.9642e-02, -1.2817e-01,  1.0445e-02,\n",
       "                       -1.2903e-01, -2.6099e-01, -2.3155e-03, -6.4636e-02,  1.5601e-01,\n",
       "                       -2.3376e-02,  1.7319e-02, -8.2886e-02, -9.5978e-03, -8.9722e-02,\n",
       "                        3.8666e-02,  3.7964e-02,  1.2152e-01, -8.4900e-02,  2.9956e-01,\n",
       "                       -2.9077e-01,  3.5767e-02,  5.6793e-02,  1.0870e-01,  1.6382e-01,\n",
       "                       -1.4246e-01, -1.6266e-02, -2.1582e-01, -1.8640e-01,  2.7435e-02,\n",
       "                        2.3047e-01,  1.2183e-01, -2.7686e-01, -6.8298e-02,  3.2300e-01,\n",
       "                       -2.6978e-01, -3.9551e-02, -1.9128e-01, -2.5040e-02, -4.1718e-02,\n",
       "                        1.4244e-02, -1.5332e-01,  1.0178e-02,  7.3486e-02, -5.6915e-02,\n",
       "                       -5.0774e-03, -2.1942e-02,  3.1445e-01,  9.0027e-03,  1.6769e-02,\n",
       "                       -2.0239e-01, -2.3157e-01,  4.0131e-02, -1.4270e-01, -2.3120e-01,\n",
       "                       -1.3293e-01, -1.6870e-01,  6.7627e-02, -8.0719e-03,  2.7563e-01,\n",
       "                        4.1779e-02,  2.0422e-01,  2.1777e-01,  3.2642e-01,  2.9126e-01,\n",
       "                       -1.6556e-02,  4.8523e-02,  1.8311e-01,  1.3086e-01,  1.2537e-01,\n",
       "                       -2.9102e-01, -5.5695e-03, -6.7444e-02,  1.0553e-01,  1.6205e-02,\n",
       "                       -1.5881e-01,  2.4979e-02, -1.8958e-01, -1.1806e-03, -8.2031e-02,\n",
       "                        2.3157e-01, -1.8652e-01, -1.1395e-01, -1.7847e-01,  2.0410e-01,\n",
       "                       -1.3684e-01, -3.4937e-01, -1.0492e-01, -5.0201e-03, -1.1542e-01,\n",
       "                       -3.0518e-01, -5.1086e-02,  2.7588e-01,  2.0776e-01, -3.0591e-01,\n",
       "                        2.2961e-01, -4.3274e-02, -1.0742e-01, -3.0640e-01, -2.9150e-01,\n",
       "                        1.6006e-02,  7.7087e-02,  1.2413e-02,  3.0838e-02, -1.9141e-01,\n",
       "                        3.4088e-02,  3.2642e-01, -7.8735e-02,  6.6284e-02,  1.5344e-01,\n",
       "                       -5.2734e-02, -1.0674e-02, -2.1545e-01,  2.0044e-01,  4.5197e-02,\n",
       "                       -2.0630e-02,  3.8403e-01,  1.1301e-03, -4.6661e-02,  1.0681e-01,\n",
       "                       -1.7456e-02,  2.2266e-01,  2.2998e-01, -1.4551e-01,  9.0698e-02,\n",
       "                       -2.2839e-01,  2.7832e-01,  1.1182e-01, -1.0950e-01,  2.8833e-01,\n",
       "                       -3.5278e-01, -1.0876e-01,  1.1523e-01, -4.4769e-02,  4.4403e-02,\n",
       "                       -3.0762e-02,  3.2812e-01,  1.4075e-01,  1.6449e-02,  1.0017e-02,\n",
       "                       -6.3049e-02,  2.3730e-01,  2.9395e-01, -1.8774e-01, -9.9304e-02,\n",
       "                       -1.8567e-01, -7.0801e-02,  1.9666e-01,  7.3364e-02,  2.0483e-01,\n",
       "                       -1.2671e-01,  8.7769e-02,  1.6895e-01, -6.7871e-02, -1.3466e-02,\n",
       "                        1.5991e-01,  1.7651e-01,  1.3049e-01, -2.4561e-01, -6.8665e-02,\n",
       "                       -2.4780e-01, -1.7822e-01,  1.4905e-01,  1.4270e-01,  1.1926e-01,\n",
       "                        3.5950e-02,  4.0558e-02,  4.6265e-02,  2.6727e-04,  2.2754e-01,\n",
       "                       -1.6309e-01, -2.2229e-01, -2.6758e-01,  4.0015e-01, -6.3293e-02,\n",
       "                        2.0340e-02, -2.6587e-01, -2.2168e-01,  2.0767e-02, -3.9337e-02,\n",
       "                        5.5237e-02, -3.2886e-01, -1.6953e-02,  3.4033e-01, -2.3819e-02,\n",
       "                       -1.5137e-01,  7.1777e-02,  3.7445e-02])),\n",
       "              ('w2v_encoder.proj.weight',\n",
       "               tensor([[ 0.0227,  0.0144,  0.0311,  ...,  0.0653, -0.0787,  0.0809],\n",
       "                       [-0.0316, -0.2515, -0.1591,  ..., -0.1703,  0.2561, -0.2822],\n",
       "                       [ 0.0029, -0.2654, -0.1639,  ..., -0.1538,  0.2037, -0.3057],\n",
       "                       ...,\n",
       "                       [ 0.0398, -0.2585, -0.0404,  ..., -0.1680,  0.2041, -0.2268],\n",
       "                       [-0.0058, -0.2661, -0.1356,  ..., -0.1310,  0.2188, -0.2118],\n",
       "                       [-0.0116, -0.2216, -0.0543,  ..., -0.1444,  0.2446, -0.3313]])),\n",
       "              ('w2v_encoder.proj.bias',\n",
       "               tensor([ 1.1133e-01, -6.5137e-01, -6.4502e-01, -6.4697e-01,  2.0523e-02,\n",
       "                       -5.2979e-02,  9.4986e-03, -9.5901e-03, -1.1604e-02, -1.3557e-02,\n",
       "                        2.9981e-05, -1.9440e-02, -7.5951e-03, -9.2163e-02, -3.5305e-03,\n",
       "                       -7.3303e-02, -5.5420e-02,  1.2245e-02,  1.3409e-03, -1.4587e-02,\n",
       "                       -5.8594e-02,  1.0544e-02, -1.6266e-02, -2.4734e-02, -2.3865e-02,\n",
       "                       -1.3580e-02, -5.0781e-02, -6.1035e-02, -4.7863e-05, -1.1993e-02,\n",
       "                       -1.5160e-02, -7.8125e-02,  1.0918e-02, -4.5967e-03, -7.5073e-02,\n",
       "                       -6.7993e-02, -5.6946e-02, -1.2589e-02, -8.3618e-02, -8.2092e-02,\n",
       "                       -6.0486e-02, -5.9570e-02, -1.1749e-01, -7.9529e-02, -6.3843e-02,\n",
       "                       -1.9928e-02, -6.5979e-02, -5.8929e-02, -7.2937e-02, -9.0332e-02,\n",
       "                       -6.5979e-02, -7.0312e-02, -7.3914e-02, -9.2529e-02, -1.0571e-01,\n",
       "                       -8.5144e-02, -9.6130e-02, -8.3313e-02, -1.0107e-01, -1.0120e-01,\n",
       "                       -7.5317e-02, -1.1053e-01, -8.1116e-02, -1.4465e-01, -1.0962e-01,\n",
       "                       -7.4585e-02, -1.0327e-01, -1.3000e-01, -1.3342e-01, -9.5947e-02,\n",
       "                       -7.5989e-02, -8.0261e-02, -1.0815e-01, -1.4453e-01, -1.2622e-01,\n",
       "                       -1.3086e-01, -8.3008e-02, -1.3782e-01, -1.1761e-01, -1.1444e-01,\n",
       "                       -1.1127e-01, -1.0168e-01, -1.3623e-01, -9.5886e-02, -1.2262e-01,\n",
       "                       -1.3745e-01, -8.9783e-02, -1.3098e-01, -9.2346e-02, -1.1957e-01,\n",
       "                       -1.2854e-01, -1.3672e-01, -1.1768e-01, -9.6558e-02, -9.5276e-02,\n",
       "                       -1.4160e-01, -1.4197e-01, -1.7419e-01, -1.3135e-01, -1.4490e-01,\n",
       "                       -1.0516e-01, -1.4551e-01, -1.1139e-01, -1.0291e-01, -1.1536e-01,\n",
       "                       -9.1858e-02, -2.4792e-01, -4.9658e-01, -1.1749e-01, -5.3516e-01,\n",
       "                       -3.9160e-01, -9.8083e-02, -5.9131e-01, -5.8203e-01, -6.0449e-01,\n",
       "                       -6.3477e-01, -6.1914e-01, -1.0620e-01, -1.1761e-01, -1.1963e-01,\n",
       "                       -1.2103e-01, -9.8572e-02, -3.2251e-01, -1.0590e-01, -1.0364e-01,\n",
       "                       -4.5752e-01, -9.1553e-02, -5.9521e-01, -1.5015e-01, -5.7715e-01,\n",
       "                       -1.2134e-01, -1.0156e-01, -6.2939e-01, -1.2744e-01, -1.4709e-01,\n",
       "                       -1.2177e-01, -1.5625e-01, -1.2561e-01, -1.1572e-01, -1.1871e-01,\n",
       "                       -1.1041e-01, -1.3965e-01, -1.3245e-01, -1.3782e-01, -4.4922e-01,\n",
       "                       -6.2939e-01, -5.3906e-01, -1.5759e-01, -5.9961e-01, -6.3965e-01,\n",
       "                       -6.3867e-01, -1.1523e-01, -6.0400e-01, -6.2158e-01, -1.4307e-01,\n",
       "                       -6.1084e-01, -5.8740e-01, -1.4148e-01, -2.5122e-01, -6.2012e-01,\n",
       "                       -6.2549e-01]))]),\n",
       " 'criterion': None,\n",
       " 'optimizer_history': [{'criterion_name': 'CtcCriterion',\n",
       "   'optimizer_name': 'FP16Optimizer',\n",
       "   'lr_scheduler_state': {'best': 16.188},\n",
       "   'num_updates': 320000}],\n",
       " 'task_state': {'target_dictionary': <fairseq.data.dictionary.Dictionary at 0x30fa64a60>},\n",
       " 'extra_state': {'metrics': OrderedDict([('default',\n",
       "                [(10,\n",
       "                  'loss',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 53.70560540789788,\n",
       "                   'sum': 7249072427.616015,\n",
       "                   'count': 80369826.0,\n",
       "                   'round': 3}),\n",
       "                 (10,\n",
       "                  'ntokens',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 17786.0,\n",
       "                   'sum': 5848596286.0,\n",
       "                   'count': 320000,\n",
       "                   'round': None}),\n",
       "                 (10,\n",
       "                  'nsentences',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 193.0,\n",
       "                   'sum': 80369826.0,\n",
       "                   'count': 320000,\n",
       "                   'round': None}),\n",
       "                 (10,\n",
       "                  'nll_loss',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 0.5827719466841499,\n",
       "                   'sum': 7249072427.616016,\n",
       "                   'count': 5848596286.0,\n",
       "                   'round': 3}),\n",
       "                 (10,\n",
       "                  '_c_errors',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 0, 'sum': 0, 'count': 320000, 'round': None}),\n",
       "                 (10,\n",
       "                  '_c_total',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 0, 'sum': 0, 'count': 320000, 'round': None}),\n",
       "                 (10,\n",
       "                  '_w_errors',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 0, 'sum': 0, 'count': 320000, 'round': None}),\n",
       "                 (10,\n",
       "                  '_wv_errors',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 0, 'sum': 0, 'count': 320000, 'round': None}),\n",
       "                 (10,\n",
       "                  '_w_total',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 0, 'sum': 0, 'count': 320000, 'round': None}),\n",
       "                 (90,\n",
       "                  'wps',\n",
       "                  'TimeMeter',\n",
       "                  {'init': 402320.92052345537,\n",
       "                   'n': tensor(5.8486e+09, dtype=torch.float64),\n",
       "                   'round': 1}),\n",
       "                 (100,\n",
       "                  'ups',\n",
       "                  'TimeMeter',\n",
       "                  {'init': 402320.9211136326, 'n': 319999.0, 'round': 2}),\n",
       "                 (180,\n",
       "                  'wpb',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(17786., dtype=torch.float64),\n",
       "                   'sum': tensor(5.8486e+09, dtype=torch.float64),\n",
       "                   'count': 320000,\n",
       "                   'round': 1}),\n",
       "                 (190,\n",
       "                  'bsz',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(193., dtype=torch.float64),\n",
       "                   'sum': tensor(80369826., dtype=torch.float64),\n",
       "                   'count': 320000,\n",
       "                   'round': 1}),\n",
       "                 (200,\n",
       "                  'num_updates',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 320000, 'sum': 0, 'count': 0, 'round': None}),\n",
       "                 (300,\n",
       "                  'lr',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 1.5000000000000002e-06,\n",
       "                   'sum': 0,\n",
       "                   'count': 0,\n",
       "                   'round': None}),\n",
       "                 (400,\n",
       "                  'gnorm',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(131.9128, dtype=torch.float64),\n",
       "                   'sum': tensor(33376515.5492, dtype=torch.float64),\n",
       "                   'count': 320000,\n",
       "                   'round': 3}),\n",
       "                 (700,\n",
       "                  'loss_scale',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 1.0, 'sum': 0, 'count': 0, 'round': 4}),\n",
       "                 (790,\n",
       "                  'wall',\n",
       "                  'StopwatchMeter',\n",
       "                  {'sum': 0, 'n': 0, 'round': 0}),\n",
       "                 (800,\n",
       "                  'train_wall',\n",
       "                  'StopwatchMeter',\n",
       "                  {'sum': 345961.48051511496, 'n': 0.0, 'round': 0}),\n",
       "                 (1500,\n",
       "                  'gb_free',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 27.23440980911255,\n",
       "                   'sum': 0,\n",
       "                   'count': 0,\n",
       "                   'round': 1})]),\n",
       "               ('train',\n",
       "                [(10,\n",
       "                  'loss',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 53.70560540789788,\n",
       "                   'sum': 83197761.11230403,\n",
       "                   'count': 2568618.0,\n",
       "                   'round': 3}),\n",
       "                 (10,\n",
       "                  'ntokens',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 17786.0,\n",
       "                   'sum': 186901851.0,\n",
       "                   'count': 10226,\n",
       "                   'round': None}),\n",
       "                 (10,\n",
       "                  'nsentences',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 193.0,\n",
       "                   'sum': 2568618.0,\n",
       "                   'count': 10226,\n",
       "                   'round': None}),\n",
       "                 (10,\n",
       "                  'nll_loss',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 0.5827719466841499,\n",
       "                   'sum': 83197761.11230403,\n",
       "                   'count': 186901851.0,\n",
       "                   'round': 3}),\n",
       "                 (10,\n",
       "                  '_c_errors',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 0, 'sum': 0, 'count': 10226, 'round': None}),\n",
       "                 (10,\n",
       "                  '_c_total',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 0, 'sum': 0, 'count': 10226, 'round': None}),\n",
       "                 (10,\n",
       "                  '_w_errors',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 0, 'sum': 0, 'count': 10226, 'round': None}),\n",
       "                 (10,\n",
       "                  '_wv_errors',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 0, 'sum': 0, 'count': 10226, 'round': None}),\n",
       "                 (10,\n",
       "                  '_w_total',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 0, 'sum': 0, 'count': 10226, 'round': None}),\n",
       "                 (90,\n",
       "                  'wps',\n",
       "                  'TimeMeter',\n",
       "                  {'init': 12828.663317095488,\n",
       "                   'n': tensor(1.8690e+08, dtype=torch.float64),\n",
       "                   'round': 1}),\n",
       "                 (100,\n",
       "                  'ups',\n",
       "                  'TimeMeter',\n",
       "                  {'init': 12828.663311792538, 'n': 10226.0, 'round': 2}),\n",
       "                 (180,\n",
       "                  'wpb',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(17786., dtype=torch.float64),\n",
       "                   'sum': tensor(1.8690e+08, dtype=torch.float64),\n",
       "                   'count': 10226,\n",
       "                   'round': 1}),\n",
       "                 (190,\n",
       "                  'bsz',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(193., dtype=torch.float64),\n",
       "                   'sum': tensor(2568618., dtype=torch.float64),\n",
       "                   'count': 10226,\n",
       "                   'round': 1}),\n",
       "                 (200,\n",
       "                  'num_updates',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 320000, 'sum': 0, 'count': 0, 'round': None}),\n",
       "                 (300,\n",
       "                  'lr',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 1.5000000000000002e-06,\n",
       "                   'sum': 0,\n",
       "                   'count': 0,\n",
       "                   'round': None}),\n",
       "                 (400,\n",
       "                  'gnorm',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(131.9128, dtype=torch.float64),\n",
       "                   'sum': tensor(1090438.3862, dtype=torch.float64),\n",
       "                   'count': 10226,\n",
       "                   'round': 3}),\n",
       "                 (700,\n",
       "                  'loss_scale',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 1.0, 'sum': 0, 'count': 0, 'round': 4}),\n",
       "                 (800,\n",
       "                  'train_wall',\n",
       "                  'StopwatchMeter',\n",
       "                  {'sum': 10921.647917218506, 'n': 0.0, 'round': 0}),\n",
       "                 (1500,\n",
       "                  'gb_free',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 27.23440980911255,\n",
       "                   'sum': 0,\n",
       "                   'count': 0,\n",
       "                   'round': 1})]),\n",
       "               ('train_inner',\n",
       "                [(10,\n",
       "                  'loss',\n",
       "                  'AverageMeter',\n",
       "                  {'val': None, 'sum': 0, 'count': 0, 'round': 3}),\n",
       "                 (10,\n",
       "                  'ntokens',\n",
       "                  'AverageMeter',\n",
       "                  {'val': None, 'sum': 0, 'count': 0, 'round': None}),\n",
       "                 (10,\n",
       "                  'nsentences',\n",
       "                  'AverageMeter',\n",
       "                  {'val': None, 'sum': 0, 'count': 0, 'round': None}),\n",
       "                 (10,\n",
       "                  'nll_loss',\n",
       "                  'AverageMeter',\n",
       "                  {'val': None, 'sum': 0, 'count': 0, 'round': 3}),\n",
       "                 (10,\n",
       "                  '_c_errors',\n",
       "                  'AverageMeter',\n",
       "                  {'val': None, 'sum': 0, 'count': 0, 'round': None}),\n",
       "                 (10,\n",
       "                  '_c_total',\n",
       "                  'AverageMeter',\n",
       "                  {'val': None, 'sum': 0, 'count': 0, 'round': None}),\n",
       "                 (10,\n",
       "                  '_w_errors',\n",
       "                  'AverageMeter',\n",
       "                  {'val': None, 'sum': 0, 'count': 0, 'round': None}),\n",
       "                 (10,\n",
       "                  '_wv_errors',\n",
       "                  'AverageMeter',\n",
       "                  {'val': None, 'sum': 0, 'count': 0, 'round': None}),\n",
       "                 (10,\n",
       "                  '_w_total',\n",
       "                  'AverageMeter',\n",
       "                  {'val': None, 'sum': 0, 'count': 0, 'round': None}),\n",
       "                 (90,\n",
       "                  'wps',\n",
       "                  'TimeMeter',\n",
       "                  {'init': 1867.3002319931984, 'n': 0, 'round': 1}),\n",
       "                 (100,\n",
       "                  'ups',\n",
       "                  'TimeMeter',\n",
       "                  {'init': 1867.3002297077328, 'n': 0, 'round': 2}),\n",
       "                 (180,\n",
       "                  'wpb',\n",
       "                  'AverageMeter',\n",
       "                  {'val': None, 'sum': 0, 'count': 0, 'round': 1}),\n",
       "                 (190,\n",
       "                  'bsz',\n",
       "                  'AverageMeter',\n",
       "                  {'val': None, 'sum': 0, 'count': 0, 'round': 1}),\n",
       "                 (200,\n",
       "                  'num_updates',\n",
       "                  'AverageMeter',\n",
       "                  {'val': None, 'sum': 0, 'count': 0, 'round': None}),\n",
       "                 (300,\n",
       "                  'lr',\n",
       "                  'AverageMeter',\n",
       "                  {'val': None, 'sum': 0, 'count': 0, 'round': None}),\n",
       "                 (400,\n",
       "                  'gnorm',\n",
       "                  'AverageMeter',\n",
       "                  {'val': None, 'sum': 0, 'count': 0, 'round': 3}),\n",
       "                 (700,\n",
       "                  'loss_scale',\n",
       "                  'AverageMeter',\n",
       "                  {'val': None, 'sum': 0, 'count': 0, 'round': 4}),\n",
       "                 (800,\n",
       "                  'train_wall',\n",
       "                  'StopwatchMeter',\n",
       "                  {'sum': 0, 'n': 0, 'round': 0}),\n",
       "                 (1500,\n",
       "                  'gb_free',\n",
       "                  'AverageMeter',\n",
       "                  {'val': None, 'sum': 0, 'count': 0, 'round': 1})]),\n",
       "               ('valid',\n",
       "                [(10,\n",
       "                  'loss',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 4.040251360244959,\n",
       "                   'sum': 145984050.5777734,\n",
       "                   'count': 5385296.0,\n",
       "                   'round': 3}),\n",
       "                 (10,\n",
       "                  'ntokens',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 907.0,\n",
       "                   'sum': 359046912.0,\n",
       "                   'count': 120568,\n",
       "                   'round': None}),\n",
       "                 (10,\n",
       "                  'nsentences',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 113.0,\n",
       "                   'sum': 5385296.0,\n",
       "                   'count': 120568,\n",
       "                   'round': None}),\n",
       "                 (10,\n",
       "                  'nll_loss',\n",
       "                  'AverageMeter',\n",
       "                  {'val': 0.503360974319383,\n",
       "                   'sum': 145984050.57777342,\n",
       "                   'count': 359046912.0,\n",
       "                   'round': 3}),\n",
       "                 (10,\n",
       "                  '_c_errors',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(79., dtype=torch.float64),\n",
       "                   'sum': tensor(31806164., dtype=torch.float64),\n",
       "                   'count': 120568,\n",
       "                   'round': None}),\n",
       "                 (10,\n",
       "                  '_c_total',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(907., dtype=torch.float64),\n",
       "                   'sum': tensor(3.5905e+08, dtype=torch.float64),\n",
       "                   'count': 120568,\n",
       "                   'round': None}),\n",
       "                 (10,\n",
       "                  '_w_errors',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(36., dtype=torch.float64),\n",
       "                   'sum': tensor(12846168., dtype=torch.float64),\n",
       "                   'count': 120568,\n",
       "                   'round': None}),\n",
       "                 (10,\n",
       "                  '_wv_errors',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(36., dtype=torch.float64),\n",
       "                   'sum': tensor(12846168., dtype=torch.float64),\n",
       "                   'count': 120568,\n",
       "                   'round': None}),\n",
       "                 (10,\n",
       "                  '_w_total',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(174., dtype=torch.float64),\n",
       "                   'sum': tensor(71568840., dtype=torch.float64),\n",
       "                   'count': 120568,\n",
       "                   'round': None}),\n",
       "                 (90,\n",
       "                  'wps',\n",
       "                  'TimeMeter',\n",
       "                  {'init': 391966.094654534,\n",
       "                   'n': tensor(3.5904e+08, dtype=torch.float64),\n",
       "                   'round': 1}),\n",
       "                 (180,\n",
       "                  'wpb',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(907., dtype=torch.float64),\n",
       "                   'sum': tensor(3.5905e+08, dtype=torch.float64),\n",
       "                   'count': 120568,\n",
       "                   'round': 1}),\n",
       "                 (190,\n",
       "                  'bsz',\n",
       "                  'AverageMeter',\n",
       "                  {'val': tensor(113., dtype=torch.float64),\n",
       "                   'sum': tensor(5385296., dtype=torch.float64),\n",
       "                   'count': 120568,\n",
       "                   'round': 1})])]),\n",
       "  'previous_training_time': tensor(400575.4106, dtype=torch.float64),\n",
       "  'train_iterator': {'version': 2,\n",
       "   'epoch': 28,\n",
       "   'iterations_in_epoch': 61422,\n",
       "   'shuffle': True},\n",
       "  'val_loss': 16.165,\n",
       "  'best': 16.165},\n",
       " 'last_optimizer_state': {'state': {0: {'step': 320000,\n",
       "    'exp_avg': tensor([-2.2731e-03, -3.4914e-02,  2.2248e-02,  ...,  4.6336e-07,\n",
       "             2.3822e-09,  2.3596e-09]),\n",
       "    'exp_avg_sq': tensor([1.7913e-02, 4.9554e-03, 4.1026e-03,  ..., 7.8023e-10, 1.2836e-15,\n",
       "            1.1700e-15])}},\n",
       "  'param_groups': [{'lr': 1.5000000000000002e-06,\n",
       "    'betas': (0.9, 0.98),\n",
       "    'eps': 1e-08,\n",
       "    'weight_decay': 0.0,\n",
       "    'amsgrad': False,\n",
       "    'params': [0]}],\n",
       "  'loss_scale': 1.0}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m task \u001b[38;5;241m=\u001b[39m fairseq\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39maudio_pretraining\u001b[38;5;241m.\u001b[39mAudioPretrainingTask\u001b[38;5;241m.\u001b[39msetup_task(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Build the model\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Load the model parameters\u001b[39;00m\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/aipy39/lib/python3.9/site-packages/fairseq/tasks/audio_pretraining.py:197\u001b[0m, in \u001b[0;36mAudioPretrainingTask.build_model\u001b[0;34m(self, model_cfg, from_checkpoint)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_cfg: FairseqDataclass, from_checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 197\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_cfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_checkpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m     actualized_cfg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcfg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m actualized_cfg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;66;03m# if \"w2v_args\" in actualized_cfg:\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/aipy39/lib/python3.9/site-packages/fairseq/tasks/fairseq_task.py:340\u001b[0m, in \u001b[0;36mFairseqTask.build_model\u001b[0;34m(self, cfg, from_checkpoint)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;124;03mBuild the :class:`~fairseq.models.BaseFairseqModel` instance for this\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;124;03mtask.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    a :class:`~fairseq.models.BaseFairseqModel` instance\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models, quantization_utils\n\u001b[0;32m--> 340\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_checkpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m model \u001b[38;5;241m=\u001b[39m quantization_utils\u001b[38;5;241m.\u001b[39mquantize_model_scalar(model, cfg)\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/envs/aipy39/lib/python3.9/site-packages/fairseq/models/__init__.py:61\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(cfg, task, from_checkpoint)\u001b[0m\n\u001b[1;32m     58\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     59\u001b[0m model_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(cfg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(cfg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124march\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_type \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# this is hit if config object is nested in directory that is named after model type\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     model_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(cfg))\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;129;01min\u001b[39;00m MODEL_DATACLASS_REGISTRY:\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize the task\n",
    "task = fairseq.tasks.audio_pretraining.AudioPretrainingTask.setup_task(checkpoint['args'])\n",
    "\n",
    "# Build the model\n",
    "model = task.build_model(checkpoint['args'])\n",
    "\n",
    "# Load the model parameters\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "# model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to process audio (you'll need to implement this based on your specific needs)\n",
    "def process_audio(audio_path):\n",
    "    # Implement audio preprocessing here\n",
    "    # This should return a tensor of the right shape for your model\n",
    "    pass\n",
    "\n",
    "# Example usage (you'll need to adjust this based on your specific model and task)\n",
    "def transcribe(audio_path):\n",
    "    audio = process_audio(audio_path)\n",
    "    with torch.no_grad():\n",
    "        result = model(audio)\n",
    "    # Process the result (this will depend on the exact model output)\n",
    "    # You might need to use task.target_dictionary to convert indices to text\n",
    "    return result\n",
    "\n",
    "# Example:\n",
    "# transcript = transcribe('path/to/your/audio.wav')\n",
    "# print(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"../testing/modi_speech.wav\"\n",
    "# audio, rate = torchaudio.load(audio_path)\n",
    "audio, rate = soundfile.read(audio_path, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'audio' is your input audio tensor and 'rate' is the sample rate\n",
    "audio_tensor = torch.tensor(audio).unsqueeze(0).float()\n",
    "\n",
    "# Normalize audio\n",
    "normalized_audio = audio_tensor / torch.max(torch.abs(audio_tensor))\n",
    "\n",
    "# Move to device\n",
    "input_sample = normalized_audio.to(device)\n",
    "\n",
    "input_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sample, input_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aipy39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
